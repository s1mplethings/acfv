import os
import json
import warnings
import subprocess
import tempfile
import shutil
from pathlib import Path

# é…ç½®GPUå†…å­˜ä½¿ç”¨ï¼ˆå…¼å®¹æ€§è®¾ç½®ï¼‰
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
os.environ['CUDA_MEMORY_FRACTION'] = '0.9'  # ä½¿ç”¨90%çš„GPUå†…å­˜

# è¿‡æ»¤è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="librosa")
warnings.filterwarnings("ignore", category=FutureWarning, module="librosa")

try:
    import librosa
    import numpy as np
    LIBROSA_AVAILABLE = True
except ImportError:
    LIBROSA_AVAILABLE = False

try:
    import soundfile as sf
    SOUNDFILE_AVAILABLE = True
except ImportError:
    SOUNDFILE_AVAILABLE = False

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False

from acfv.main_logging import log_info, log_error, log_debug
from acfv.runtime.storage import processing_path

def check_ffmpeg_availability():
    """æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨"""
    try:
        result = subprocess.run(['ffmpeg', '-version'], 
                              capture_output=True, text=True, 
                              encoding='utf-8', errors='ignore', timeout=10)
        if result.returncode == 0:
            return True
    except Exception:
        pass
    return False

def get_audio_info_ffprobe(audio_path):
    """ä½¿ç”¨ffprobeè·å–éŸ³é¢‘ä¿¡æ¯"""
    try:
        cmd = [
            "ffprobe", "-v", "quiet", "-print_format", "json", 
            "-show_format", "-show_streams", str(audio_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, 
                              encoding='utf-8', errors='ignore', timeout=30)
        
        if result.returncode == 0:
            info = json.loads(result.stdout)
            
            # è·å–éŸ³é¢‘æµä¿¡æ¯
            audio_stream = None
            for stream in info.get('streams', []):
                if stream.get('codec_type') == 'audio':
                    audio_stream = stream
                    break
            
            duration = float(info['format'].get('duration', 0))
            sample_rate = int(audio_stream.get('sample_rate', 16000)) if audio_stream else 16000
            channels = int(audio_stream.get('channels', 1)) if audio_stream else 1
            
            return {
                'duration': duration,
                'sample_rate': sample_rate,
                'channels': channels,
                'format': info['format'].get('format_name', 'unknown')
            }
    except Exception as e:
        log_error(f"ffprobeè·å–éŸ³é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        return None

def get_audio_duration_ffmpeg_only(audio_path):
    """çº¯ffmpegæ–¹å¼è·å–éŸ³é¢‘æ—¶é•¿"""
    info = get_audio_info_ffprobe(audio_path)
    if info:
        duration = info['duration']
        log_info(f"[éŸ³é¢‘æ—¶é•¿] {duration:.1f}ç§’ (é‡‡æ ·ç‡: {info['sample_rate']}Hz, å£°é“: {info['channels']})")
        return duration
    
    # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨librosaï¼ˆä»…å°æ–‡ä»¶ï¼‰
    try:
        file_size_gb = os.path.getsize(audio_path) / (1024**3)
        if file_size_gb <= 1 and LIBROSA_AVAILABLE:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                duration = librosa.get_duration(path=str(audio_path))
                log_info(f"[éŸ³é¢‘æ—¶é•¿] ä½¿ç”¨librosaè·å–: {duration:.1f}ç§’")
                return duration
    except Exception as e:
        log_debug(f"librosaå¤‡ç”¨æ–¹æ³•å¤±è´¥: {e}")
    
    log_error("[éŸ³é¢‘æ—¶é•¿] æ— æ³•è·å–ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    return 3600.0  # é»˜è®¤1å°æ—¶

def extract_audio_segment_ffmpeg(audio_path, start_time, end_time, output_path):
    """ä½¿ç”¨ffmpegæå–éŸ³é¢‘ç‰‡æ®µï¼ˆå°½å¯èƒ½é›¶æ‹·è´ï¼‰"""
    try:
        duration = end_time - start_time
        
        # ä¼˜å…ˆä½¿ç”¨è¾“å…¥å¯»å€å¹¶ç›´æ¥å¤åˆ¶ï¼ˆè‹¥æºæ˜¯pcm_s16le/16k/mono WAVï¼‰
        cmd = [
            "ffmpeg", "-y",
            "-hide_banner", "-loglevel", "error", "-nostdin",
            "-ss", str(start_time),  # è¾“å…¥å¯»å€æ›´å¿«
            "-i", str(audio_path),
            "-t", str(duration),
            # ç›´æ¥è¾“å‡ºä¸ºç›®æ ‡å‚æ•°ï¼›è‹¥è¾“å…¥å·²æ˜¯ç›¸åŒå‚æ•°ï¼Œå†…éƒ¨å°†æ˜¯å¤åˆ¶
            "-acodec", "pcm_s16le",
            "-ar", "16000",
            "-ac", "1",
            "-f", "wav",
            str(output_path)
        ]
        
        # æ‰§è¡Œå‘½ä»¤ - ä¿®å¤ç¼–ç é—®é¢˜
        result = subprocess.run(
            cmd, 
            capture_output=True, 
            text=True,
            encoding='utf-8',
            errors='ignore',  # å¿½ç•¥ç¼–ç é”™è¯¯
            timeout=300,
            check=True
        )
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            log_debug(f"[éŸ³é¢‘æå–] ffmpegæˆåŠŸ: {start_time:.1f}-{end_time:.1f}s")
            return True
        else:
            log_error(f"[éŸ³é¢‘æå–] è¾“å‡ºæ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨")
            return False
            
    except subprocess.TimeoutExpired:
        log_error(f"[éŸ³é¢‘æå–] ffmpegè¶…æ—¶: {start_time}-{end_time}")
        return False
    except subprocess.CalledProcessError as e:
        log_error(f"[éŸ³é¢‘æå–] ffmpegå¤±è´¥: {e.stderr if e.stderr else 'unknown error'}")
        return False
    except Exception as e:
        log_error(f"[éŸ³é¢‘æå–] ffmpegå¼‚å¸¸: {e}")
        return False

def extract_audio_segment_librosa(audio_path, start_time, end_time, output_path):
    """ä½¿ç”¨librosaæå–éŸ³é¢‘ç‰‡æ®µï¼ˆå¤‡ç”¨æ–¹æ³•ï¼Œé€‚åˆå°æ–‡ä»¶ï¼‰"""
    try:
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            
            duration = end_time - start_time
            y, sr = librosa.load(
                str(audio_path), 
                sr=16000, 
                offset=start_time, 
                duration=duration,
                mono=True
            )
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            if SOUNDFILE_AVAILABLE:
                sf.write(str(output_path), y, sr)
            else:
                # ä½¿ç”¨scipy.io.wavfileä½œä¸ºå¤‡é€‰
                try:
                    from scipy.io import wavfile
                    # è½¬æ¢ä¸ºint16æ ¼å¼
                    y_int16 = (y * 32767).astype(np.int16)
                    wavfile.write(str(output_path), sr, y_int16)
                except ImportError:
                    log_error("ç¼ºå°‘soundfileå’Œscipyåº“ï¼Œæ— æ³•ä¿å­˜éŸ³é¢‘")
                    return False
            
            log_debug(f"[éŸ³é¢‘æå–] librosaæˆåŠŸ: {start_time:.1f}-{end_time:.1f}s")
            return True
            
    except Exception as e:
        log_error(f"[éŸ³é¢‘æå–] librosaå¤±è´¥: {e}")
        return False

def extract_audio_segment_safe(audio_path, start_time, end_time, output_path):
    """å®‰å…¨æå–éŸ³é¢‘ç‰‡æ®µï¼ˆä¼˜å…ˆffmpegï¼Œå¤‡é€‰librosaï¼‰"""
    
    # æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨
    if not check_ffmpeg_availability():
        log_error("ffmpegä¸å¯ç”¨ï¼Œè¯·å®‰è£…ffmpeg")
        
        # å°è¯•ä½¿ç”¨librosaï¼ˆä»…é€‚åˆå°æ–‡ä»¶ï¼‰
        file_size_gb = os.path.getsize(audio_path) / (1024**3)
        if file_size_gb <= 1 and LIBROSA_AVAILABLE:
            log_info("å°è¯•ä½¿ç”¨librosaå¤„ç†å°æ–‡ä»¶...")
            return extract_audio_segment_librosa(audio_path, start_time, end_time, output_path)
        else:
            log_error("æ–‡ä»¶è¿‡å¤§ä¸”ffmpegä¸å¯ç”¨ï¼Œæ— æ³•å¤„ç†")
            return False
    
    # ä¼˜å…ˆä½¿ç”¨ffmpeg
    if extract_audio_segment_ffmpeg(audio_path, start_time, end_time, output_path):
        return True
    
    # ffmpegå¤±è´¥æ—¶çš„å¤‡é€‰æ–¹æ¡ˆ
    file_size_gb = os.path.getsize(audio_path) / (1024**3)
    if file_size_gb <= 1 and LIBROSA_AVAILABLE:
        log_info("ffmpegå¤±è´¥ï¼Œå°è¯•librosaå¤‡é€‰æ–¹æ¡ˆ...")
        return extract_audio_segment_librosa(audio_path, start_time, end_time, output_path)
    
    return False

def extract_audio_segment_enhanced(audio_path, start_time, end_time, output_path):
    """å¢å¼ºéŸ³é¢‘ç‰‡æ®µæå–ï¼ˆé’ˆå¯¹ä½è´¨é‡éŸ³é¢‘ï¼‰"""
    try:
        duration = end_time - start_time
        
        # æ„å»ºå¢å¼ºçš„ffmpegå‘½ä»¤
        cmd = [
            "ffmpeg", "-y",  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            "-i", str(audio_path),
            "-ss", str(start_time),  # å¼€å§‹æ—¶é—´
            "-t", str(duration),     # æŒç»­æ—¶é—´
            "-acodec", "pcm_s16le",  # éŸ³é¢‘ç¼–ç 
            "-ar", "16000",          # é‡‡æ ·ç‡
            "-ac", "1",              # å•å£°é“
            "-af", "highpass=f=50,lowpass=f=8000,volume=3.0,compand=0.3|0.3:1|1:-90/-60/-40/-20/-10/0:6:0:-90:0.2",  # å¢å¼ºéŸ³é¢‘å¤„ç†
            "-f", "wav",             # è¾“å‡ºæ ¼å¼
            str(output_path)
        ]
        
        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(
            cmd, 
            capture_output=True, 
            text=True,
            encoding='utf-8',
            errors='ignore',
            timeout=600,
            check=True
        )
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            log_debug(f"[éŸ³é¢‘å¢å¼º] æˆåŠŸ: {start_time:.1f}-{end_time:.1f}s")
            return True
        else:
            log_error(f"[éŸ³é¢‘å¢å¼º] è¾“å‡ºæ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨")
            return False
            
    except subprocess.TimeoutExpired:
        log_error(f"[éŸ³é¢‘å¢å¼º] ffmpegè¶…æ—¶: {start_time}-{end_time}")
        return False
    except subprocess.CalledProcessError as e:
        log_error(f"[éŸ³é¢‘å¢å¼º] ffmpegé”™è¯¯: {e}")
        return False
    except Exception as e:
        log_error(f"[éŸ³é¢‘å¢å¼º] æœªçŸ¥é”™è¯¯: {e}")
        return False

def create_audio_segments(audio_path, segment_length=300):
    """åˆ›å»ºéŸ³é¢‘ç‰‡æ®µåˆ—è¡¨"""
    total_duration = get_audio_duration_ffmpeg_only(audio_path)
    
    if total_duration <= 0:
        log_error("[åˆ†æ®µ] æ— æ³•è·å–æœ‰æ•ˆçš„éŸ³é¢‘æ—¶é•¿")
        return []
    
    segments = []
    current_time = 0
    segment_id = 0
    
    while current_time < total_duration:
        end_time = min(current_time + segment_length, total_duration)
        
        # è·³è¿‡å¤ªçŸ­çš„ç‰‡æ®µ
        if end_time - current_time < 1.0:
            break
        
        segments.append({
            'id': segment_id,
            'start': current_time,
            'end': end_time,
            'duration': end_time - current_time
        })
        
        current_time = end_time
        segment_id += 1
    
    log_info(f"[åˆ†æ®µ] åˆ›å»ºäº† {len(segments)} ä¸ªç‰‡æ®µï¼Œæ€»æ—¶é•¿ {total_duration:.1f}ç§’")
    return segments

def transcribe_audio_segment_safe(audio_path, start_time, end_time, whisper_model):
    """å®‰å…¨è½¬å½•éŸ³é¢‘ç‰‡æ®µ"""
    temp_dir = None
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp(prefix="whisper_")
        temp_audio_path = os.path.join(temp_dir, f"segment_{start_time}_{end_time}.wav")
        
        # æå–éŸ³é¢‘ç‰‡æ®µ
        log_debug(f"[è½¬å½•] å¼€å§‹æå–éŸ³é¢‘ç‰‡æ®µ: {start_time}-{end_time}")
        if not extract_audio_segment_safe(audio_path, start_time, end_time, temp_audio_path):
            log_error(f"[è½¬å½•] éŸ³é¢‘ç‰‡æ®µæå–å¤±è´¥: {start_time}-{end_time}")
            return []
        log_debug(f"[è½¬å½•] éŸ³é¢‘ç‰‡æ®µæå–æˆåŠŸ: {temp_audio_path}")
        
        # ç®€å•çš„éŸ³é¢‘è´¨é‡æ£€æŸ¥ï¼ˆå¯é€‰ï¼‰
        try:
            import librosa
            audio_data, sr = librosa.load(temp_audio_path, sr=None)
            rms_energy = np.sqrt(np.mean(audio_data**2))
            log_debug(f"[éŸ³é¢‘è´¨é‡] RMSèƒ½é‡: {rms_energy:.4f}, éŸ³é¢‘é•¿åº¦: {len(audio_data)} é‡‡æ ·ç‚¹")
            
            # æ£€æŸ¥éŸ³é¢‘æ˜¯å¦å¤ªå®‰é™
            if rms_energy < 0.001:
                log_warning(f"[éŸ³é¢‘è´¨é‡] éŸ³é¢‘å¤ªå®‰é™ï¼Œå¯èƒ½æ²¡æœ‰è¯­éŸ³å†…å®¹ï¼Œè·³è¿‡è¯¥ç‰‡æ®µ {start_time}-{end_time}s")
                return []
        except Exception as e:
            log_debug(f"[éŸ³é¢‘è´¨é‡] éŸ³é¢‘è´¨é‡æ£€æµ‹å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
        if not os.path.exists(temp_audio_path):
            log_error(f"[è½¬å½•] ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {temp_audio_path}")
            return []
        
        file_size = os.path.getsize(temp_audio_path)
        if file_size == 0:
            log_error(f"[è½¬å½•] ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {temp_audio_path}")
            return []
        
        log_debug(f"[è½¬å½•] éŸ³é¢‘ç‰‡æ®µæ–‡ä»¶å¤§å°: {file_size} bytes")
        
        # è¯»å–è½¬å½•é…ç½®
        try:
            with settings_path("config.json").open("r", encoding="utf-8") as f:
                config_data = json.load(f)
            transcription_language = str(config_data.get("TRANSCRIPTION_LANGUAGE", "auto")).strip()
            no_speech_threshold = config_data.get("NO_SPEECH_THRESHOLD", 0.6)
            logprob_threshold = config_data.get("LOGPROB_THRESHOLD", -1.0)
        except Exception as e:
            log_debug(f"[è½¬å½•] æ— æ³•è¯»å–é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            transcription_language = "auto"
            no_speech_threshold = 0.6
            logprob_threshold = -1.0

        # ä½¿ç”¨Whisperè½¬å½•
        if not WHISPER_AVAILABLE:
            log_error("[è½¬å½•] Whisperä¸å¯ç”¨")
            return []

        # éªŒè¯GPUä½¿ç”¨
        import torch
        if torch.cuda.is_available():
            log_debug(f"[è½¬å½•] GPUå†…å­˜ä½¿ç”¨å‰: {torch.cuda.memory_allocated() / 1024**2:.1f}MB")

        language_arg = None
        if transcription_language and str(transcription_language).strip().lower() not in {"auto", "default", "detect"}:
            language_arg = transcription_language
        fp16_enabled = torch.cuda.is_available()
        try:
            model_device = str(getattr(whisper_model, "device", "cuda" if torch.cuda.is_available() else "cpu"))
            fp16_enabled = fp16_enabled and model_device.startswith("cuda")
        except Exception:
            fp16_enabled = torch.cuda.is_available()

        # æŒ‰é…ç½®è¯­è¨€æ‰§è¡Œè½¬å½•
        try:
            log_debug(f"[è½¬å½•] å¼€å§‹è½¬å½•ç‰‡æ®µ: {start_time}-{end_time} (language={language_arg or 'auto'})")
            result = whisper_model.transcribe(
                temp_audio_path,
                language=language_arg,
                initial_prompt="",
                no_speech_threshold=no_speech_threshold,
                logprob_threshold=logprob_threshold,
                word_timestamps=True,
                fp16=fp16_enabled,
            )
            log_debug(f"[è½¬å½•] Whisperè½¬å½•å®Œæˆï¼Œç»“æœç±»å‹: {type(result)}")
        except Exception as e:
            log_error(f"[è½¬å½•] Whisperè½¬å½•å¼‚å¸¸: {e}")
            # å°è¯•ä½¿ç”¨æ›´ç®€å•çš„å‚æ•°
            try:
                log_debug(f"[è½¬å½•] å°è¯•ç®€åŒ–å‚æ•°è½¬å½•...")
                result = whisper_model.transcribe(
                    temp_audio_path,
                    language=language_arg,
                    word_timestamps=True,
                    fp16=False,
                )
                log_debug(f"[è½¬å½•] ç®€åŒ–è½¬å½•å®Œæˆ")
            except Exception as e2:
                log_error(f"[è½¬å½•] ç®€åŒ–è½¬å½•ä¹Ÿå¤±è´¥: {e2}")
                return []
        # éªŒè¯GPUä½¿ç”¨å
        if torch.cuda.is_available():
            log_debug(f"[è½¬å½•] GPUå†…å­˜ä½¿ç”¨å: {torch.cuda.memory_allocated() / 1024**2:.1f}MB")
        
        # å¤„ç†è½¬å½•ç»“æœ
        segments = []
        if 'segments' in result:
            for seg in result['segments']:
                text = seg.get('text', '').strip()
                
                # è¿‡æ»¤æ‰é»˜è®¤æç¤ºæ–‡æœ¬å’Œç©ºæ–‡æœ¬
                if text and text != "This is English transcription content." and len(text) > 1:
                    segments.append({
                        'start': seg.get('start', 0) + start_time,  # è°ƒæ•´æ—¶é—´æˆ³
                        'end': seg.get('end', 0) + start_time,
                        'text': text
                    })
        
        log_debug(f"[è½¬å½•] ç‰‡æ®µè½¬å½•å®Œæˆ: {start_time}-{end_time}, {len(segments)}ä¸ªæœ‰æ•ˆå¥å­")
        return segments
        
    except Exception as e:
        log_error(f"[è½¬å½•] ç‰‡æ®µè½¬å½•å¤±è´¥ {start_time}-{end_time}: {e}")
        return []
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_dir and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
            except Exception as e:
                log_debug(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")

def process_audio_segments(audio_path, output_file=None, 
                         segment_length=300, whisper_model_name="base", host_transcription_file=None):
    """
    å¤„ç†éŸ³é¢‘ç‰‡æ®µï¼ˆæ— pydubç‰ˆæœ¬ï¼‰
    if output_file is None:
        output_file = str(processing_path("transcription.json"))
    """
    log_info("=" * 60)
    log_info("ğŸ¤ å¼€å§‹éŸ³é¢‘è½¬å½•å¤„ç†ï¼ˆæ— pydubç‰ˆæœ¬ï¼‰")
    log_info("=" * 60)
    
    def should_stop():
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢å¤„ç†"""
        try:
            stop_flag_file = processing_path("stop_flag.txt")
            return stop_flag_file.exists()
        except Exception:
            return False
    
    # æ·»åŠ åœæ­¢æ£€æŸ¥
    if should_stop():
        log_info("ğŸ›‘ æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼ŒéŸ³é¢‘è½¬å½•è¢«ä¸­æ–­")
        return None
    
    try:
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        file_size_gb = os.path.getsize(audio_path) / (1024**3)
        log_info(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size_gb:.2f}GB")
        
        # åœæ­¢æ£€æŸ¥
        if should_stop():
            log_info("ğŸ›‘ æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼ŒéŸ³é¢‘è½¬å½•åœ¨æ–‡ä»¶æ£€æŸ¥åè¢«ä¸­æ–­")
            return None
        
        # æ£€æŸ¥å¿…è¦å·¥å…·
        if not check_ffmpeg_availability():
            if file_size_gb > 1:
                raise RuntimeError("å¤„ç†å¤§æ–‡ä»¶éœ€è¦ffmpegï¼Œè¯·å®‰è£…ffmpeg")
            elif not LIBROSA_AVAILABLE:
                raise RuntimeError("ç¼ºå°‘ffmpegå’Œlibrosaï¼Œæ— æ³•å¤„ç†éŸ³é¢‘æ–‡ä»¶")
            else:
                log_info("âš ï¸ ffmpegä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨librosaå¤„ç†å°æ–‡ä»¶")
        
        # æ£€æŸ¥è¾“å‡ºç›®å½•
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        # åŠ è½½Whisperæ¨¡å‹
        if not WHISPER_AVAILABLE:
            raise ImportError("Whisperåº“ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install openai-whisper")
        
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        import torch
        device = "cuda:0" if torch.cuda.is_available() else "cpu"
        
        # å°è¯•ä»é…ç½®è¯»å–GPUè®¾ç½®
        try:
            import json
            with settings_path("config.json").open("r", encoding="utf-8") as f:
                config_data = json.load(f)
            gpu_device = config_data.get("GPU_DEVICE", "cuda:0")
            enable_gpu = config_data.get("ENABLE_GPU_ACCELERATION", True)
            
            if enable_gpu and torch.cuda.is_available():
                device = gpu_device
                log_info(f"ğŸ¤– ä½¿ç”¨GPUè®¾å¤‡: {device}")
                log_info(f"ğŸ¤– GPUä¿¡æ¯: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}")
                log_info(f"ğŸ¤– GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB" if torch.cuda.is_available() else 'N/A')
            else:
                device = "cpu"
                log_info(f"ğŸ¤– ä½¿ç”¨CPUè®¾å¤‡ (GPUä¸å¯ç”¨æˆ–å·²ç¦ç”¨)")
        except Exception as e:
            log_info(f"ğŸ¤– æ— æ³•è¯»å–GPUé…ç½®ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®: {device}")
        
        log_info(f"ğŸ¤– åŠ è½½Whisperæ¨¡å‹: {whisper_model_name} (è®¾å¤‡: {device})")
        
        # ä¿®å¤PyTorchç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜
        try:
            whisper_model = whisper.load_model(whisper_model_name, device=device)
        except Exception as e:
            if "meta tensor" in str(e).lower():
                log_info("ğŸ¤– æ£€æµ‹åˆ°PyTorchç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œä½¿ç”¨to_empty()æ–¹æ³•...")
                # å…ˆåŠ è½½åˆ°CPUï¼Œç„¶åè½¬ç§»åˆ°ç›®æ ‡è®¾å¤‡
                whisper_model = whisper.load_model(whisper_model_name, device="cpu")
                if device != "cpu":
                    try:
                        whisper_model = whisper_model.to_empty(device=device)
                    except AttributeError:
                        # å¦‚æœto_emptyä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                        whisper_model = whisper_model.to(device)
            else:
                raise e
        
        # é…ç½®GPUå†…å­˜ç®¡ç†
        if device.startswith('cuda'):
            import torch
            # è®¾ç½®å†…å­˜åˆ†é…ç­–ç•¥
            torch.cuda.set_per_process_memory_fraction(0.9)  # ä½¿ç”¨90%çš„GPUå†…å­˜
            torch.cuda.empty_cache()  # æ¸…ç©ºç¼“å­˜
            
            # æ˜¾ç¤ºå†…å­˜ä¿¡æ¯
            total_memory = torch.cuda.get_device_properties(0).total_memory
            allocated_memory = torch.cuda.memory_allocated()
            log_info(f"ğŸ¤– GPUå†…å­˜: {total_memory / 1024**3:.1f}GB (å·²ç”¨: {allocated_memory / 1024**3:.1f}GB)")
        
        # éªŒè¯æ¨¡å‹æ˜¯å¦åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        if hasattr(whisper_model, 'encoder'):
            model_device = next(whisper_model.encoder.parameters()).device
            log_info(f"ğŸ¤– æ¨¡å‹å®é™…è®¾å¤‡: {model_device}")
            if str(model_device) != device:
                log_error(f"ğŸ¤– è­¦å‘Š: æ¨¡å‹è®¾å¤‡ä¸åŒ¹é…! æœŸæœ›: {device}, å®é™…: {model_device}")
        
        # åˆ›å»ºéŸ³é¢‘ç‰‡æ®µ
        log_info("ğŸ“Š åˆ†æéŸ³é¢‘æ–‡ä»¶...")
        segments = create_audio_segments(audio_path, segment_length)
        
        if not segments:
            raise ValueError("æ— æ³•åˆ›å»ºéŸ³é¢‘ç‰‡æ®µ")
            
        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆç”±pipeline_backend.pyå·²ç»æå–ï¼‰
        output_dir = os.path.dirname(output_file)
        audio_save_dir = os.path.join(output_dir, "audio")
        audio_save_path = os.path.join(audio_save_dir, "extracted_audio.wav")
        
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(audio_save_path):
            file_size_mb = os.path.getsize(audio_save_path) / (1024 * 1024)
            log_info(f"âœ… ä½¿ç”¨å·²æå–çš„éŸ³é¢‘æ–‡ä»¶: {audio_save_path} ({file_size_mb:.1f}MB)")
        else:
            log_error(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_save_path}ï¼Œè¯·ç¡®ä¿pipeline_backend.pyå·²æ­£ç¡®æå–éŸ³é¢‘")
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_save_path}")
        
        log_info(f"ğŸ”„ å¼€å§‹å¤„ç† {len(segments)} ä¸ªç‰‡æ®µ...")
        
        # å¤„ç†æ‰€æœ‰ç‰‡æ®µ
        all_transcription_results = []
        
        for i, segment in enumerate(segments, 1):
            log_info(f"[{i}/{len(segments)}] å¤„ç†ç‰‡æ®µ {segment['start']:.1f}-{segment['end']:.1f}s")
            
            try:
                segment_results = transcribe_audio_segment_safe(
                    audio_path, 
                    segment['start'], 
                    segment['end'], 
                    whisper_model
                )
                
                all_transcription_results.extend(segment_results)
                
                log_info(f"âœ… ç‰‡æ®µ {i} å®Œæˆï¼Œè·å¾— {len(segment_results)} ä¸ªå¥å­")
                
            except Exception as e:
                log_error(f"âŒ ç‰‡æ®µ {i} å¤„ç†å¤±è´¥: {e}")
                continue
        
        # ä¿å­˜ç»“æœ
        log_info(f"ğŸ’¾ ä¿å­˜è½¬å½•ç»“æœåˆ°: {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_transcription_results, f, ensure_ascii=False, indent=2)
        
        # å¦‚æœæŒ‡å®šäº†ä¸»æ’­è½¬å½•æ–‡ä»¶ï¼Œä¿å­˜ä¸»æ’­ä¸“ç”¨è½¬å½•ç»“æœ
        if host_transcription_file:
            log_info(f"ğŸ’¾ ä¿å­˜ä¸»æ’­è½¬å½•ç»“æœåˆ°: {host_transcription_file}")
            # å¯¹äºä¸»æ’­éŸ³é¢‘ï¼Œè½¬å½•ç»“æœå°±æ˜¯ä¸»æ’­çš„è½¬å½•
            host_transcription_results = all_transcription_results.copy()
            
            # æ·»åŠ ä¸»æ’­æ ‡è¯†ä¿¡æ¯
            for result in host_transcription_results:
                result['speaker'] = 'host'
                result['is_host'] = True
            
            with open(host_transcription_file, 'w', encoding='utf-8') as f:
                json.dump(host_transcription_results, f, ensure_ascii=False, indent=2)
            
            log_info(f"ğŸ“ ä¸»æ’­è½¬å½•ç‰‡æ®µæ•°é‡: {len(host_transcription_results)}")
        
        log_info("=" * 60)
        log_info(f"âœ… éŸ³é¢‘è½¬å½•å®Œæˆï¼")
        log_info(f"ğŸ“ æ€»å…±è·å¾— {len(all_transcription_results)} ä¸ªè½¬å½•ç‰‡æ®µ")
        log_info(f"ğŸ“„ ç»“æœæ–‡ä»¶: {output_file}")
        if host_transcription_file:
            log_info(f"ğŸ“„ ä¸»æ’­è½¬å½•æ–‡ä»¶: {host_transcription_file}")
        log_info("=" * 60)
        
        if not all_transcription_results:
            try:
                audio_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
            except Exception:
                audio_size_mb = -1
            log_warning(f"âš ï¸ è½¬å½•å®Œæˆä½†æ²¡æœ‰å¾—åˆ°ä»»ä½•æ–‡æœ¬ç‰‡æ®µï¼Œè¯·æ£€æŸ¥éŸ³é¢‘å†…å®¹æˆ–é˜ˆå€¼è®¾ç½® (audio_size_mb={audio_size_mb:.2f})")
        
        return all_transcription_results
        
    except Exception as e:
        log_error(f"âŒ éŸ³é¢‘è½¬å½•å¤±è´¥: {e}")
        raise

def check_gpu_availability():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    try:
        import torch
        if torch.cuda.is_available():
            log_info("âœ… GPUå¯ç”¨")
            log_info(f"ğŸ¤– GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
            log_info(f"ğŸ¤– GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
            log_info(f"ğŸ¤– CUDAç‰ˆæœ¬: {torch.version.cuda}")
            
            # æ˜¾ç¤ºå†…å­˜é…ç½®
            log_info("ğŸ¤– GPUå†…å­˜é…ç½®:")
            log_info(f"  - ä¸“ç”¨å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
            log_info(f"  - å…±äº«å†…å­˜: å¯ç”¨ (é€šè¿‡ç³»ç»Ÿå†…å­˜)")
            log_info(f"  - å†…å­˜åˆ†é…: 90%ä¸“ç”¨ + å…±äº«å†…å­˜")
            
            return True
        else:
            log_info("âŒ GPUä¸å¯ç”¨")
            return False
    except Exception as e:
        log_error(f"âŒ GPUæ£€æµ‹å¤±è´¥: {e}")
        return False

def monitor_gpu_memory():
    """ç›‘æ§GPUå†…å­˜ä½¿ç”¨"""
    try:
        import torch
        if torch.cuda.is_available():
            total_memory = torch.cuda.get_device_properties(0).total_memory
            allocated_memory = torch.cuda.memory_allocated()
            reserved_memory = torch.cuda.memory_reserved()
            
            log_info(f"ğŸ“Š GPUå†…å­˜ç›‘æ§:")
            log_info(f"  - ä¸“ç”¨å†…å­˜: {total_memory / 1024**3:.1f}GB")
            log_info(f"  - å·²åˆ†é…: {allocated_memory / 1024**3:.1f}GB")
            log_info(f"  - å·²ä¿ç•™: {reserved_memory / 1024**3:.1f}GB")
            log_info(f"  - å¯ç”¨: {(total_memory - reserved_memory) / 1024**3:.1f}GB")
            
            # è®¡ç®—ä½¿ç”¨ç‡
            usage_percent = (reserved_memory / total_memory) * 100
            log_info(f"  - ä½¿ç”¨ç‡: {usage_percent:.1f}%")
            
            return {
                'total': total_memory,
                'allocated': allocated_memory,
                'reserved': reserved_memory,
                'usage_percent': usage_percent
            }
    except Exception as e:
        log_error(f"âŒ GPUå†…å­˜ç›‘æ§å¤±è´¥: {e}")
        return None

def install_dependencies():
    """æ£€æŸ¥å¹¶æç¤ºå®‰è£…ä¾èµ–"""
    missing_deps = []
    
    if not check_ffmpeg_availability():
        missing_deps.append("ffmpeg (æ¨èå®‰è£…ï¼Œå¤„ç†å¤§æ–‡ä»¶å¿…éœ€)")
    
    if not LIBROSA_AVAILABLE:
        missing_deps.append("librosa (pip install librosa)")
    
    if not SOUNDFILE_AVAILABLE:
        missing_deps.append("soundfile (pip install soundfile)")
    
    if not WHISPER_AVAILABLE:
        missing_deps.append("whisper (pip install openai-whisper)")
    
    if missing_deps:
        log_info("âš ï¸ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–ï¼š")
        for dep in missing_deps:
            log_info(f"  - {dep}")
        return False
    
    log_info("âœ… æ‰€æœ‰ä¾èµ–éƒ½å·²å®‰è£…")
    
    # æ£€æŸ¥GPU
    check_gpu_availability()
    
    return True

if __name__ == "__main__":
    import sys
    
    # æ£€æŸ¥ä¾èµ–
    if not install_dependencies():
        print("è¯·å®‰è£…ç¼ºå°‘çš„ä¾èµ–åé‡è¯•")
        sys.exit(1)
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python transcribe_audio.py <éŸ³é¢‘æ–‡ä»¶è·¯å¾„> [è¾“å‡ºæ–‡ä»¶è·¯å¾„]")
        sys.exit(1)
    
    audio_path = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else str(processing_path("transcription.json"))
    
    try:
        process_audio_segments(audio_path, output_file)
        print("è½¬å½•å®Œæˆï¼")
    except Exception as e:
        print(f"è½¬å½•å¤±è´¥: {e}")
        sys.exit(1)
