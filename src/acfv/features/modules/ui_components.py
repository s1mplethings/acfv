# ui_components.py - UIç»„ä»¶æ¨¡å—

import os
import sys
import json
import logging
import threading
import subprocess
import re
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache
from datetime import datetime
# ç§»é™¤RAGä¾èµ–ï¼Œåˆ‡ç‰‡é¡µä¸å†è¿›è¡ŒRAGå¤„ç†

try:
    from PyQt5.QtWidgets import *
    from PyQt5.QtCore import *
    from PyQt5.QtGui import *
    PYTQT5_AVAILABLE = True
except ImportError:
    PYTQT5_AVAILABLE = False
    print("PyQt5 æ¨¡å—æœªå®‰è£…ï¼Œå°†è·³è¿‡ç›¸å…³åŠŸèƒ½")

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("OpenCV æ¨¡å—æœªå®‰è£…ï¼Œå°†ä½¿ç”¨FFmpegæ›¿ä»£")

# å®‰å…¨å¯¼å…¥numpyï¼Œå¤„ç†å…¼å®¹æ€§é—®é¢˜
try:
    import warnings
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        import numpy
    NUMPY_AVAILABLE = True
except Exception as e:
    NUMPY_AVAILABLE = False
    print(f"Numpyæ¨¡å—å¯¼å…¥è­¦å‘Š: {e}")
    if 'dtype size changed' in str(e):
        print("è¿™æ˜¯numpyç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œä½†ä¸å½±å“åŸºæœ¬åŠŸèƒ½")

class SimpleThumbnailManager:
    """ç®€åŒ–çš„ç¼©ç•¥å›¾ç®¡ç†å™¨ - åªä¿ç•™åŸºæœ¬é€»è¾‘"""
    
    def __init__(self, thumbnail_dir="thumbnails"):
        self.thumbnail_dir = os.path.abspath(thumbnail_dir)
        # è‡ªåŠ¨åˆ›å»ºç¼©ç•¥å›¾ç›®å½•
        try:
            os.makedirs(self.thumbnail_dir, exist_ok=True)
            logging.info(f"ç¼©ç•¥å›¾ç›®å½•å·²åˆ›å»º: {self.thumbnail_dir}")
        except Exception as e:
            logging.error(f"åˆ›å»ºç¼©ç•¥å›¾ç›®å½•å¤±è´¥: {e}")
            # å›é€€åˆ°å½“å‰ç›®å½•ä¸‹çš„thumbnails
            self.thumbnail_dir = os.path.abspath("./thumbnails")
            os.makedirs(self.thumbnail_dir, exist_ok=True)
    
    def get_thumbnail_path(self, video_path):
        """æ ¹æ®è§†é¢‘è·¯å¾„ç”Ÿæˆç¼©ç•¥å›¾è·¯å¾„"""
        # ä½¿ç”¨åŸæ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰ä½œä¸ºç¼©ç•¥å›¾æ–‡ä»¶å
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
        safe_name = "".join(c for c in video_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
        # å¦‚æœæ–‡ä»¶åå¤ªé•¿ï¼Œæˆªå–å‰100ä¸ªå­—ç¬¦
        if len(safe_name) > 100:
            safe_name = safe_name[:100]
        # å¦‚æœæ¸…ç†åæ–‡ä»¶åä¸ºç©ºï¼Œä½¿ç”¨å“ˆå¸Œ
        if not safe_name.strip():
            import hashlib
            safe_name = hashlib.md5(video_path.encode('utf-8')).hexdigest()[:16]
        return os.path.join(self.thumbnail_dir, f"{safe_name}.jpg")
    
    def has_thumbnail(self, video_path):
        """æ£€æŸ¥è§†é¢‘æ˜¯å¦å·²æœ‰ç¼©ç•¥å›¾"""
        thumbnail_path = self.get_thumbnail_path(video_path)
        return os.path.exists(thumbnail_path)
    
    def get_thumbnail(self, video_path):
        """è·å–ç¼©ç•¥å›¾ï¼ˆè¿”å›QImageï¼‰"""
        if not self.has_thumbnail(video_path):
            return None
        
        try:
            thumbnail_path = self.get_thumbnail_path(video_path)
            image = QImage(thumbnail_path)
            return image if not image.isNull() else None
        except Exception as e:
            logging.error(f"è¯»å–ç¼©ç•¥å›¾å¤±è´¥: {e}")
            return None
    
    def save_thumbnail(self, video_path, image):
        """ä¿å­˜ç¼©ç•¥å›¾"""
        try:
            thumbnail_path = self.get_thumbnail_path(video_path)
            if isinstance(image, QPixmap):
                image = image.toImage()
            
            if isinstance(image, QImage):
                return image.save(thumbnail_path, "JPEG", quality=85)
        except Exception as e:
            logging.error(f"ä¿å­˜ç¼©ç•¥å›¾å¤±è´¥: {e}")
        return False
    
    def remove_thumbnail(self, video_path):
        """åˆ é™¤ç¼©ç•¥å›¾"""
        try:
            thumbnail_path = self.get_thumbnail_path(video_path)
            if os.path.exists(thumbnail_path):
                os.remove(thumbnail_path)
                return True
        except Exception as e:
            logging.error(f"åˆ é™¤ç¼©ç•¥å›¾å¤±è´¥: {e}")
        return False
    
    def cleanup_orphaned_thumbnails(self, video_paths):
        """æ¸…ç†å­¤å„¿ç¼©ç•¥å›¾ï¼ˆå¯¹åº”çš„è§†é¢‘æ–‡ä»¶å·²ä¸å­˜åœ¨ï¼‰"""
        try:
            # è·å–æ‰€æœ‰ç¼©ç•¥å›¾æ–‡ä»¶
            if not os.path.exists(self.thumbnail_dir):
                return
            
            # ç”Ÿæˆæ‰€æœ‰æœ‰æ•ˆè§†é¢‘çš„ç¼©ç•¥å›¾è·¯å¾„é›†åˆ
            valid_thumbnail_paths = set()
            for video_path in video_paths:
                if os.path.exists(video_path):
                    valid_thumbnail_paths.add(self.get_thumbnail_path(video_path))
            
            # åˆ é™¤æ— æ•ˆçš„ç¼©ç•¥å›¾
            for filename in os.listdir(self.thumbnail_dir):
                if filename.endswith('.jpg'):
                    thumbnail_path = os.path.join(self.thumbnail_dir, filename)
                    if thumbnail_path not in valid_thumbnail_paths:
                        try:
                            os.remove(thumbnail_path)
                            logging.info(f"åˆ é™¤å­¤å„¿ç¼©ç•¥å›¾: {filename}")
                        except Exception as e:
                            logging.error(f"åˆ é™¤å­¤å„¿ç¼©ç•¥å›¾å¤±è´¥ {filename}: {e}")
        except Exception as e:
            logging.error(f"æ¸…ç†å­¤å„¿ç¼©ç•¥å›¾å¤±è´¥: {e}")

# å…¨å±€ç¼©ç•¥å›¾ç®¡ç†å™¨å®ä¾‹ - ä½¿ç”¨ä¸“é—¨çš„ç¼©ç•¥å›¾æ–‡ä»¶å¤¹
thumbnail_manager = SimpleThumbnailManager("thumbnails")

class Worker(QThread):
    """é€šç”¨å·¥ä½œçº¿ç¨‹"""
    finished = pyqtSignal(object)
    error = pyqtSignal(str)
    progress_update = pyqtSignal(str)
    progress_percent = pyqtSignal(int)

    def __init__(self, func, *args, parent=None, **kwargs):
        super().__init__(parent)
        self.func = func
        self.args = args
        self.kwargs = kwargs
        self._should_stop = False

    def run(self):
        try:
            # æ£€æŸ¥çº¿ç¨‹æ˜¯å¦åº”è¯¥åœæ­¢
            if self._should_stop:
                return
                
            import inspect
            sig = inspect.signature(self.func)
            if 'progress_callback' in sig.parameters:
                self.kwargs['progress_callback'] = self.emit_progress
            res = self.func(*self.args, **self.kwargs)
            
            # å†æ¬¡æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
            if not self._should_stop:
                self.finished.emit(res)
        except Exception as e:
            if not self._should_stop:
                self.error.emit(str(e))

    def emit_progress(self, stage, current, total, message=""):
        if self._should_stop:
            return
            
        if total > 0:
            percent = int((current / total) * 100)
            self.progress_percent.emit(percent)
        progress_text = f"[{stage}] {current}/{total} - {message}"
        self.progress_update.emit(progress_text)
    
    def stop(self):
        """åœæ­¢çº¿ç¨‹"""
        self._should_stop = True
        self.quit()
        if not self.wait(2000):  # ç­‰å¾…2ç§’
            self.terminate()
            self.wait(1000)


class SimpleThumbnailLoader(QThread):
    """ç®€åŒ–çš„ç¼©ç•¥å›¾åŠ è½½å™¨"""
    
    thumbnail_loaded = pyqtSignal(int, QImage, str)
    progress_update = pyqtSignal(str)
    batch_completed = pyqtSignal()

    def __init__(self, video_files, parent=None, max_workers=4):
        super().__init__(parent)
        self.video_files = video_files
        self.max_workers = max_workers  # å¢åŠ é»˜è®¤çº¿ç¨‹æ•°ä»¥æå‡é€Ÿåº¦
        self._should_stop = False

    def extract_thumbnail(self, filepath):
        """æå–ç¼©ç•¥å›¾ï¼ˆåªä½¿ç”¨OpenCVï¼Œæ›´ç¨³å®šï¼‰"""
        # åªä½¿ç”¨OpenCVæ–¹æ³•
        if CV2_AVAILABLE:
            image = self.extract_thumbnail_opencv(filepath)
            if image is not None:
                return image
        
        # å¦‚æœOpenCVä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œè¿”å›None
        return None

    def is_valid_thumbnail(self, image):
        """æ£€æŸ¥ç¼©ç•¥å›¾æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯å…¨é»‘ã€å…¨ç™½æˆ–å™ªç‚¹å›¾ï¼‰"""
        if image.isNull() or image.width() == 0 or image.height() == 0:
            return False
        
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾å¹¶è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            gray_image = image.convertToFormat(QImage.Format_Grayscale8)
            width, height = gray_image.width(), gray_image.height()
            
            # é‡‡æ ·æ£€æŸ¥ï¼ˆåªæ£€æŸ¥éƒ¨åˆ†åƒç´ ä»¥æå‡æ€§èƒ½ï¼‰
            sample_points = min(1000, width * height // 10)  # é‡‡æ ·10%çš„åƒç´ 
            pixel_values = []
            
            for i in range(0, sample_points):
                x = (i * 7) % width  # ä½¿ç”¨è´¨æ•°æ­¥é•¿é¿å…è§„å¾‹é‡‡æ ·
                y = (i * 11) % height
                pixel = gray_image.pixel(x, y)
                # QImage.pixelè¿”å›RGBå€¼ï¼Œå–Ré€šé“ï¼ˆå› ä¸ºæ˜¯ç°åº¦å›¾ï¼ŒRGBç›¸ç­‰ï¼‰
                gray_value = (pixel >> 16) & 0xFF
                pixel_values.append(gray_value)
            
            if not pixel_values:
                return False
                
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            import statistics
            mean_val = statistics.mean(pixel_values)
            
            # æ£€æŸ¥æ˜¯å¦å…¨é»‘æˆ–å…¨ç™½
            if mean_val < 5 or mean_val > 250:
                logging.debug("æ£€æµ‹åˆ°å…¨é»‘æˆ–å…¨ç™½ç¼©ç•¥å›¾")
                return False
            
            # æ£€æŸ¥æ–¹å·®ï¼ˆå¤ªå°è¯´æ˜å›¾åƒå•è°ƒï¼Œå¯èƒ½æ˜¯æŸåçš„ï¼‰
            try:
                variance = statistics.variance(pixel_values)
                if variance < 10:  # æ–¹å·®å¤ªå°ï¼Œå›¾åƒè¿‡äºå•è°ƒ
                    logging.debug("æ£€æµ‹åˆ°å•è°ƒç¼©ç•¥å›¾ï¼ˆæ–¹å·®è¿‡å°ï¼‰")
                    return False
            except statistics.StatisticsError:
                return False
                
            return True
            
        except Exception as e:
            logging.debug(f"ç¼©ç•¥å›¾è´¨é‡æ£€æŸ¥å‡ºé”™: {e}")
            return True  # å‡ºé”™æ—¶é»˜è®¤è®¤ä¸ºæœ‰æ•ˆ
    
    def extract_thumbnail_opencv(self, filepath):
        """ä½¿ç”¨OpenCVæå–ä¸­é—´å¸§ - ç®€åŒ–ç¨³å®šç‰ˆæœ¬"""
        try:
            cap = cv2.VideoCapture(filepath)
            if not cap.isOpened():
                return None
                
            # è·å–è§†é¢‘ä¿¡æ¯
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # è®¡ç®—ä¸­é—´å¸§ä½ç½®
            if total_frames > 100:  # æœ‰è¶³å¤Ÿå¸§æ•°çš„è§†é¢‘
                target_frame = total_frames // 2  # çœŸæ­£çš„ä¸­é—´å¸§
            elif total_frames > 30:  # çŸ­è§†é¢‘ä½¿ç”¨1/3å¤„
                target_frame = total_frames // 3
            else:  # å¾ˆçŸ­çš„è§†é¢‘ä½¿ç”¨ç¬¬10å¸§
                target_frame = min(10, total_frames - 1) if total_frames > 0 else 0
            
            # è·³è½¬åˆ°ç›®æ ‡å¸§
            cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
            ret, frame = cap.read()
            cap.release()
            
            if ret and frame is not None:
                # æ£€æŸ¥å¸§æ˜¯å¦æœ‰æ•ˆ
                if frame.shape[0] > 0 and frame.shape[1] > 0:
                    # ç¼©æ”¾åˆ°ç›®æ ‡å°ºå¯¸
                    frame = cv2.resize(frame, (320, 180), interpolation=cv2.INTER_LINEAR)
                    h, w, _ = frame.shape
                    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    return QImage(rgb.data, w, h, 3 * w, QImage.Format_RGB888)
                
        except Exception as e:
            logging.debug(f"OpenCVæå–ç¼©ç•¥å›¾å¤±è´¥ {os.path.basename(filepath)}: {e}")
        
        return None

    def create_placeholder(self, text="NO THUMB"):
        """åˆ›å»ºå ä½å›¾"""
        image = QImage(320, 180, QImage.Format_RGB32)
        
        # æ ¹æ®æ–‡æœ¬ç±»å‹ä½¿ç”¨ä¸åŒé¢œè‰²
        if "ERROR" in text or "æŸå" in text or "DAMAGED" in text:
            image.fill(QColor(120, 60, 60))  # æ·±çº¢è‰²èƒŒæ™¯è¡¨ç¤ºé”™è¯¯
            text_color = QColor(255, 200, 200)  # æµ…çº¢è‰²æ–‡å­—
        elif "NO THUMB" in text:
            image.fill(Qt.darkGray)  # æ·±ç°è‰²èƒŒæ™¯
            text_color = Qt.white
        else:
            image.fill(Qt.darkGray)
            text_color = Qt.white
            
        painter = QPainter(image)
        painter.setPen(text_color)
        font = QFont("Arial", 12, QFont.Bold)
        painter.setFont(font)
        painter.drawText(image.rect(), Qt.AlignCenter, text)
        painter.end()
        return image

    def run(self):
        """åŠ è½½æ‰€æœ‰ç¼©ç•¥å›¾ - ç®€åŒ–ç‰ˆæœ¬ï¼Œåªä½¿ç”¨OpenCV"""
        total_files = len(self.video_files)
        
        for i, (filename, filepath) in enumerate(self.video_files):
            if self._should_stop:
                break
            
            try:
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜ç¼©ç•¥å›¾
                cached_image = None
                if thumbnail_manager.has_thumbnail(filepath):
                    try:
                        cached_image = thumbnail_manager.get_thumbnail(filepath)
                    except Exception as e:
                        logging.debug(f"è¯»å–ç¼“å­˜ç¼©ç•¥å›¾å¤±è´¥ {filename}: {e}")
                        
                if cached_image and not cached_image.isNull():
                    self.thumbnail_loaded.emit(i, cached_image, filename)
                    self.progress_update.emit(f"ç¼“å­˜ {i+1}/{total_files}: {filename}")
                    continue
                
                # åªä½¿ç”¨OpenCVç”Ÿæˆæ–°ç¼©ç•¥å›¾
                image = None
                if CV2_AVAILABLE:
                    try:
                        image = self.extract_thumbnail_opencv(filepath)
                    except Exception as e:
                        logging.debug(f"OpenCVæå–ç¼©ç•¥å›¾å¤±è´¥ {filename}: {e}")
                
                if image is None or image.isNull():
                    # åˆ›å»ºå ä½å›¾
                    try:
                        image = self.create_placeholder("NO THUMB")
                    except Exception as e:
                        logging.error(f"åˆ›å»ºå ä½å›¾å¤±è´¥: {e}")
                        continue
                else:
                    # ä¿å­˜ç¼©ç•¥å›¾
                    try:
                        thumbnail_manager.save_thumbnail(filepath, image)
                    except Exception as e:
                        logging.debug(f"ä¿å­˜ç¼©ç•¥å›¾å¤±è´¥: {e}")
                
                self.thumbnail_loaded.emit(i, image, filename)
                self.progress_update.emit(f"ç”Ÿæˆ {i+1}/{total_files}: {filename}")
                
            except Exception as e:
                logging.error(f"å¤„ç†ç¼©ç•¥å›¾å¤±è´¥ {filename}: {e}")
                # å‘é€é”™è¯¯å ä½å›¾
                try:
                    error_image = self.create_placeholder("ERROR")
                    self.thumbnail_loaded.emit(i, error_image, filename)
                except Exception as e2:
                    logging.error(f"åˆ›å»ºé”™è¯¯å ä½å›¾ä¹Ÿå¤±è´¥: {e2}")
        
        if not self._should_stop:
            try:
                self.batch_completed.emit()
            except Exception as e:
                logging.error(f"å‘é€æ‰¹é‡å®Œæˆä¿¡å·å¤±è´¥: {e}")
                logging.error(f"å¤„ç†ç¼©ç•¥å›¾å¤±è´¥ {filename}: {e}")
                # å‘é€é”™è¯¯å ä½å›¾
                try:
                    error_image = self.create_placeholder("ERROR")
                    self.thumbnail_loaded.emit(i, error_image, filename)
                except Exception as e2:
                    logging.error(f"åˆ›å»ºé”™è¯¯å ä½å›¾ä¹Ÿå¤±è´¥: {e2}")
        
        if not self._should_stop:
            try:
                self.batch_completed.emit()
            except Exception as e:
                logging.error(f"å‘é€æ‰¹é‡å®Œæˆä¿¡å·å¤±è´¥: {e}")

    def stop(self):
        """åœæ­¢çº¿ç¨‹"""
        self._should_stop = True
        self.quit()
        if not self.wait(2000):
            self.terminate()
            self.wait(1000)


class OptimizedClipThumbnailLoader(QThread):
    """ä¼˜åŒ–çš„åˆ‡ç‰‡ç¼©ç•¥å›¾åŠ è½½çº¿ç¨‹ - ç®€åŒ–ä¸ºåªä½¿ç”¨OpenCV"""
    thumbnail_loaded = pyqtSignal(dict, QImage)
    progress_update = pyqtSignal(str)
    batch_completed = pyqtSignal()

    def __init__(self, clips, parent=None, max_workers=2, batch_size=8):
        super().__init__(parent)
        self.clips = clips
        self.max_workers = max_workers
        self.batch_size = batch_size
        self._should_stop = False

    def extract_thumbnail_opencv(self, filepath):
        """ä½¿ç”¨OpenCVæå–ä¸­é—´å¸§ - ç®€åŒ–ç‰ˆæœ¬"""
        try:
            cap = cv2.VideoCapture(filepath)
            if not cap.isOpened():
                return None
                
            # è·å–è§†é¢‘ä¿¡æ¯
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # è®¡ç®—ä¸­é—´å¸§ä½ç½®
            if total_frames > 100:
                target_frame = total_frames // 2  # çœŸæ­£çš„ä¸­é—´å¸§
            elif total_frames > 30:
                target_frame = total_frames // 3
            else:
                target_frame = min(10, total_frames - 1) if total_frames > 0 else 0
            
            cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
            ret, frame = cap.read()
            cap.release()
            
            if ret and frame is not None:
                if frame.shape[0] > 0 and frame.shape[1] > 0:
                    frame = cv2.resize(frame, (320, 180), interpolation=cv2.INTER_LINEAR)
                    h, w, _ = frame.shape
                    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    return QImage(rgb.data, w, h, 3 * w, QImage.Format_RGB888)
                
        except Exception as e:
            logging.debug(f"OpenCVæå–åˆ‡ç‰‡ç¼©ç•¥å›¾å¤±è´¥ {os.path.basename(filepath)}: {e}")
        
        return None

    def extract_thumbnail_opencv(self, filepath, use_middle_frame=True, use_random_middle=False):
        """ä½¿ç”¨OpenCVæå–ç¼©ç•¥å›¾ - ç®€åŒ–ç‰ˆæœ¬"""
        if not CV2_AVAILABLE:
            return None
        
        try:
            cap = cv2.VideoCapture(filepath)
            if not cap.isOpened():
                return None
                
            # è·å–è§†é¢‘ä¿¡æ¯
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # ç®€åŒ–çš„ä¸­é—´å¸§è®¡ç®—
            if total_frames > 100:
                target_frame = total_frames // 2  # çœŸæ­£çš„ä¸­é—´å¸§
            elif total_frames > 30:
                target_frame = total_frames // 3
            else:
                target_frame = min(10, total_frames - 1) if total_frames > 0 else 0
            
            cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
            ret, frame = cap.read()
            cap.release()
            
            if ret and frame is not None:
                frame = cv2.resize(frame, (320, 180), interpolation=cv2.INTER_LINEAR)
                h, w, _ = frame.shape
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                return QImage(rgb.data, w, h, 3 * w, QImage.Format_RGB888)
                
        except Exception as e:
            logging.debug(f"OpenCVæå–ç¼©ç•¥å›¾å¤±è´¥: {os.path.basename(filepath)}, é”™è¯¯: {e}")
        
        return None

    def load_single_clip_thumbnail(self, clip):
        """åŠ è½½å•ä¸ªåˆ‡ç‰‡ç¼©ç•¥å›¾ - ç®€åŒ–ç‰ˆæœ¬ï¼Œåªä½¿ç”¨OpenCV"""
        if self._should_stop:
            return None
        
        try:
            clip_path = clip["path"]
            filename = clip.get('file', os.path.basename(clip_path))
            logging.debug(f"[ClipThumb] å¼€å§‹åŠ è½½: {filename}")
            
            # é¦–å…ˆæ£€æŸ¥ç¼“å­˜
            cached_image = thumbnail_manager.get_thumbnail(clip_path)
            if cached_image:
                logging.debug(f"[ClipThumb] ä½¿ç”¨ç¼“å­˜: {filename}")
                return clip, cached_image
            
            # åªä½¿ç”¨OpenCVæå–ç¼©ç•¥å›¾
            image = None
            if CV2_AVAILABLE:
                image = self.extract_thumbnail_opencv(clip_path)
            
            # å¦‚æœå¤±è´¥äº†ï¼Œè¿”å›å ä½ç¬¦
            if image is None:
                image = QImage(320, 180, QImage.Format_RGB32)
                image.fill(Qt.darkGray)
                painter = QPainter(image)
                painter.setPen(Qt.white)
                font = QFont("Arial", 12)
                painter.setFont(font)
                painter.drawText(image.rect(), Qt.AlignCenter, "NO\nTHUMB")
                painter.end()
                logging.warning(f"[ClipThumb] ç”Ÿæˆå ä½: {filename}")
            
            # ä¿å­˜åˆ°ç¼“å­˜
            thumbnail_manager.save_thumbnail(clip_path, image)
            
            return clip, image
            
        except Exception as e:
            logging.error(f"åŠ è½½åˆ‡ç‰‡ç¼©ç•¥å›¾å¤±è´¥: {clip.get('path', '')}, é”™è¯¯: {e}")
            img = QImage(320, 180, QImage.Format_RGB32)
            img.fill(Qt.black)
            painter = QPainter(img)
            painter.setPen(Qt.white)
            font = QFont("Arial", 12)
            painter.setFont(font)
            painter.drawText(img.rect(), Qt.AlignCenter, "ERR")
            painter.end()
            return clip, img

    def run(self):
        """å¹¶è¡ŒåŠ è½½åˆ‡ç‰‡ç¼©ç•¥å›¾ - çº¿ç¨‹å®‰å…¨ç‰ˆæœ¬"""
        try:
            total_clips = len(self.clips)
            if total_clips == 0:
                return
                
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡ - å’Œç›´æ’­å›æ”¾ä¸€æ ·
                future_to_clip = {}
                for clip in self.clips:
                    if self._should_stop:
                        break
                    
                    # ç¡®ä¿clipæ˜¯æœ‰æ•ˆçš„å­—å…¸
                    if not isinstance(clip, dict) or not clip.get('path'):
                        continue
                        
                    future = executor.submit(self.load_single_clip_thumbnail, clip)
                    future_to_clip[future] = clip
                
                # æ”¶é›†ç»“æœ - å’Œç›´æ’­å›æ”¾ä¸€æ ·
                completed_count = 0
                for future in as_completed(future_to_clip):
                    if self._should_stop:
                        break
                    
                    try:
                        result = future.result(timeout=30)
                        if result and len(result) == 2:
                            clip_res, image = result
                            # éªŒè¯ç»“æœæœ‰æ•ˆæ€§
                            if isinstance(clip_res, dict) and hasattr(image, 'isNull') and not image.isNull():
                                self.thumbnail_loaded.emit(clip_res, image)
                                progress_name = clip_res.get('file', '')
                            else:
                                clip_res = future_to_clip.get(future, {})
                                progress_name = clip_res.get('file', '') if isinstance(clip_res, dict) else ''
                        else:
                            clip_res = future_to_clip.get(future, {})
                            progress_name = clip_res.get('file', '') if isinstance(clip_res, dict) else ''
                            
                        completed_count += 1
                        if progress_name:
                            self.progress_update.emit(
                                f"åŠ è½½åˆ‡ç‰‡ç¼©ç•¥å›¾ {completed_count}/{total_clips}: {progress_name}"
                            )
                        else:
                            self.progress_update.emit(
                                f"åŠ è½½åˆ‡ç‰‡ç¼©ç•¥å›¾ {completed_count}/{total_clips}"
                            )
                        
                    except Exception as e:
                        logging.error(f"åˆ‡ç‰‡ç¼©ç•¥å›¾åŠ è½½ä»»åŠ¡å¼‚å¸¸: {e}")
                        completed_count += 1
                        # ç»§ç»­å¤„ç†å…¶ä»–ä»»åŠ¡ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                        
        except Exception as e:
            logging.error(f"ç¼©ç•¥å›¾åŠ è½½çº¿ç¨‹å¼‚å¸¸: {e}")
            # ç¡®ä¿çº¿ç¨‹èƒ½å¤Ÿæ­£å¸¸ç»“æŸï¼Œä¸å´©æºƒ
        
        if not self._should_stop:
            self.batch_completed.emit()

    def stop(self):
        """åœæ­¢çº¿ç¨‹"""
        self._should_stop = True
        self.quit()
        if not self.wait(2000):
            self.terminate()
            self.wait(1000)


class SimpleClipThumbnailLoader(QThread):
    """ç®€åŒ–çš„åˆ‡ç‰‡ç¼©ç•¥å›¾åŠ è½½å™¨"""
    
    thumbnail_loaded = pyqtSignal(dict, QImage)
    progress_update = pyqtSignal(str)
    batch_completed = pyqtSignal()

    def __init__(self, clips, parent=None):
        super().__init__(parent)
        self.clips = clips
        self._should_stop = False

    def extract_thumbnail(self, filepath):
        """æå–ç¼©ç•¥å›¾ï¼ˆåªä½¿ç”¨OpenCVï¼‰"""
        # åªä½¿ç”¨OpenCVæ–¹æ³•
        if CV2_AVAILABLE:
            image = self.extract_thumbnail_opencv(filepath)
            if image is not None:
                return image
        
        return None

    def extract_thumbnail_opencv(self, filepath):
        """ä½¿ç”¨OpenCVæå–ä¸­é—´å¸§ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œé‡ç‚¹ä½¿ç”¨ä¸­é—´å¸§"""
        try:
            cap = cv2.VideoCapture(filepath)
            if not cap.isOpened():
                return None
            
            # è·å–è§†é¢‘ä¿¡æ¯æ¥è®¡ç®—çœŸæ­£çš„ä¸­é—´å¸§
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            if total_frames > 0:
                # ä½¿ç”¨çœŸæ­£çš„ä¸­é—´å¸§
                target_frame = total_frames // 2
            else:
                # å¦‚æœæ— æ³•è·å–å¸§æ•°ï¼Œä¼°ç®—ä¸­é—´ä½ç½®
                fps = cap.get(cv2.CAP_PROP_FPS) or 25
                target_frame = int(15 * fps)  # ä¼°ç®—15ç§’å¤„ä½œä¸ºä¸­é—´ç‚¹
            
            cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
            ret, frame = cap.read()
            cap.release()
            
            if ret and frame is not None:
                # ç›´æ¥ç¼©æ”¾
                frame = cv2.resize(frame, (320, 180), interpolation=cv2.INTER_LINEAR)
                h, w, _ = frame.shape
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                return QImage(rgb.data, w, h, 3 * w, QImage.Format_RGB888)
                
        except Exception as e:
            logging.debug(f"OpenCVæå–åˆ‡ç‰‡ç¼©ç•¥å›¾å¤±è´¥: {e}")
        return None

    def create_placeholder(self, text="NO THUMB"):
        """åˆ›å»ºå ä½å›¾"""
        image = QImage(320, 180, QImage.Format_RGB32)
        image.fill(Qt.darkGray)
        painter = QPainter(image)
        painter.setPen(Qt.white)
        font = QFont("Arial", 12)
        painter.setFont(font)
        painter.drawText(image.rect(), Qt.AlignCenter, text)
        painter.end()
        return image

    def run(self):
        """åŠ è½½æ‰€æœ‰åˆ‡ç‰‡ç¼©ç•¥å›¾"""
        total_clips = len(self.clips)
        
        for i, clip in enumerate(self.clips):
            if self._should_stop:
                break
            
            try:
                if not isinstance(clip, dict) or not clip.get('path'):
                    continue
                
                clip_path = clip["path"]
                filename = clip.get('file', os.path.basename(clip_path))
                
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼©ç•¥å›¾
                cached_image = thumbnail_manager.get_thumbnail(clip_path)
                if cached_image:
                    self.thumbnail_loaded.emit(clip, cached_image)
                    self.progress_update.emit(f"åŠ è½½åˆ‡ç‰‡ç¼©ç•¥å›¾ {i+1}/{total_clips}: {filename}")
                    continue
                
                # ç”Ÿæˆæ–°ç¼©ç•¥å›¾
                image = self.extract_thumbnail(clip_path)
                
                if image is None:
                    image = self.create_placeholder()
                else:
                    # ä¿å­˜ç¼©ç•¥å›¾
                    thumbnail_manager.save_thumbnail(clip_path, image)
                
                self.thumbnail_loaded.emit(clip, image)
                self.progress_update.emit(f"åŠ è½½åˆ‡ç‰‡ç¼©ç•¥å›¾ {i+1}/{total_clips}: {filename}")
                
            except Exception as e:
                logging.error(f"å¤„ç†åˆ‡ç‰‡ç¼©ç•¥å›¾å¤±è´¥: {e}")
                error_image = self.create_placeholder("ERROR")
                self.thumbnail_loaded.emit(clip, error_image)
        
        if not self._should_stop:
            self.batch_completed.emit()

    def stop(self):
        """åœæ­¢çº¿ç¨‹"""
        self._should_stop = True
        self.quit()
        if not self.wait(2000):
            self.terminate()
            self.wait(1000)


class SettingsDialog(QDialog):
    """è®¾ç½®å¯¹è¯æ¡†"""
    
    def __init__(self, config_manager, parent=None):
        super().__init__(parent)
        self.config_manager = config_manager
        self.monitor_runtime = None
        self.monitor_config = None
        self.monitor_cfg_path = None
        try:
            from acfv.runtime import stream_monitor as monitor_runtime
            self.monitor_runtime = monitor_runtime
            self.monitor_config, self.monitor_cfg_path, _ = monitor_runtime.load_stream_monitor_config(None)
        except Exception as exc:
            logging.warning(f"ç›´æ’­ç›‘æ§é…ç½®ä¸å¯ç”¨ï¼š{exc}")
        self.setWindowTitle("ç¨‹åºè®¾ç½®")
        self.setMinimumWidth(700)
        self.init_ui()
    
    def init_ui(self):
        layout = QVBoxLayout(self)
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        tabs = QTabWidget()
        layout.addWidget(tabs)
        
        # åŸºæœ¬è®¾ç½®æ ‡ç­¾é¡µ
        self.init_basic_tab(tabs)
        
        # æƒé‡è®¾ç½®æ ‡ç­¾é¡µ
        self.init_weights_tab(tabs)

        # ç›´æ’­ç›‘æ§è®¾ç½®
        self.init_monitor_tab(tabs)
        
        # åº•éƒ¨æŒ‰é’®
        self.init_buttons(layout)
    
    def init_basic_tab(self, tabs):
        tab_basic = QWidget()
        form_basic = QFormLayout(tab_basic)
        
        # è¾“å‡ºåˆ‡ç‰‡æ•°é‡
        self.edit_max_clips = QLineEdit(str(self.config_manager.get("MAX_CLIP_COUNT")))
        form_basic.addRow("è¾“å‡ºåˆ‡ç‰‡æ•°é‡:", self.edit_max_clips)
        
        # åˆ‡ç‰‡åŸºç¡€ç›®å½•
        self.edit_clips_base_dir = QLineEdit(self.config_manager.get("CLIPS_BASE_DIR"))
        clips_dir_layout = QHBoxLayout()
        clips_dir_layout.addWidget(self.edit_clips_base_dir)
        clips_dir_btn = QPushButton("é€‰æ‹©")
        clips_dir_btn.clicked.connect(self.choose_clips_dir)
        clips_dir_layout.addWidget(clips_dir_btn)
        form_basic.addRow("åˆ‡ç‰‡åŸºç¡€ç›®å½•:", clips_dir_layout)
        
        # å›æ”¾ä¸‹è½½ç›®å½•
        self.edit_replay_download_dir = QLineEdit(self.config_manager.get("replay_download_folder", "./data/twitch"))
        replay_dir_layout = QHBoxLayout()
        replay_dir_layout.addWidget(self.edit_replay_download_dir)
        replay_dir_btn = QPushButton("é€‰æ‹©")
        replay_dir_btn.clicked.connect(self.choose_replay_dir)
        replay_dir_layout.addWidget(replay_dir_btn)
        form_basic.addRow("å›æ”¾ä¸‹è½½ç›®å½•:", replay_dir_layout)
        
        # Whisperæ¨¡å‹
        self.edit_whisper = QLineEdit(self.config_manager.get("WHISPER_MODEL"))
        form_basic.addRow("Whisper æ¨¡å‹:", self.edit_whisper)

        # HuggingFace Tokenï¼ˆéšè—æ˜¾ç¤ºåˆ‡æ¢ï¼‰
        hf_layout = QHBoxLayout()
        hf_token_value = self.config_manager.get("HUGGINGFACE_TOKEN", "") or ""
        self.edit_hf_token = QLineEdit(hf_token_value)
        self.edit_hf_token.setPlaceholderText("hf_xxx...")
        self.edit_hf_token.setEchoMode(QLineEdit.Password)
        self.edit_hf_token.setClearButtonEnabled(True)
        self.edit_hf_token.setToolTip("åœ¨æ­¤å¡«å†™ HuggingFace è®¿é—®ä»¤ç‰Œï¼Œç”¨äºéœ€è¦ HuggingFace Hub çš„åŠŸèƒ½ã€‚")
        self.btn_toggle_hf = QPushButton("æ˜¾ç¤º")
        self.btn_toggle_hf.setCheckable(True)
        self.btn_toggle_hf.setFixedWidth(60)
        self.btn_toggle_hf.setToolTip("ç‚¹å‡»ä¸´æ—¶æ˜¾ç¤ºæˆ–éšè—ä»¤ç‰Œå†…å®¹")
        self.btn_toggle_hf.toggled.connect(self.toggle_hf_visibility)
        hf_layout.addWidget(self.edit_hf_token)
        hf_layout.addWidget(self.btn_toggle_hf)
        form_basic.addRow("HuggingFace Token:", hf_layout)
        
        # æ–‡æœ¬æƒ…ç»ªæ¨¡å‹è·¯å¾„
        self.edit_local_emotion = QLineEdit(self.config_manager.get("LOCAL_EMOTION_MODEL_PATH"))
        form_basic.addRow("æ–‡æœ¬æƒ…ç»ªæ¨¡å‹è·¯å¾„:", self.edit_local_emotion)
        
        # è§†é¢‘æƒ…ç»ªæ¨¡å‹æ–‡ä»¶
        self.edit_video_emotion = QLineEdit(self.config_manager.get("VIDEO_EMOTION_MODEL_PATH"))
        form_basic.addRow("è§†é¢‘æƒ…ç»ªæ¨¡å‹æ–‡ä»¶:", self.edit_video_emotion)
        
        # è§†é¢‘æƒ…ç»ªåˆ†ææ®µé•¿åº¦
        self.edit_emotion_segment_length = QLineEdit(str(self.config_manager.get("VIDEO_EMOTION_SEGMENT_LENGTH")))
        form_basic.addRow("è§†é¢‘æƒ…ç»ªåˆ†ææ®µé•¿åº¦(ç§’):", self.edit_emotion_segment_length)
        
        # LLMè®¾å¤‡
        self.edit_llm_device = QLineEdit(str(self.config_manager.get("LLM_DEVICE")))
        form_basic.addRow("LLM_DEVICE (GPU=0/CPU=-1):", self.edit_llm_device)
        
        # æ£€æŸ¥ç‚¹è®¾ç½®
        self.edit_checkpoint_interval = QLineEdit(str(self.config_manager.get("CHECKPOINT_INTERVAL", 10)))
        form_basic.addRow("æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”:", self.edit_checkpoint_interval)
        
        self.edit_max_workers = QLineEdit(str(self.config_manager.get("MAX_WORKERS", 4)))
        form_basic.addRow("å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°:", self.edit_max_workers)
        
        self.edit_gpu_device = QLineEdit(str(self.config_manager.get("GPU_DEVICE", "cuda:0")))
        form_basic.addRow("GPUè®¾å¤‡:", self.edit_gpu_device)
        
        # åˆ‡ç‰‡é…ç½®
        self.edit_min_clip_duration = QLineEdit(str(self.config_manager.get("MIN_CLIP_DURATION", 60.0)))
        form_basic.addRow("æœ€å°åˆ‡ç‰‡æ—¶é•¿(ç§’):", self.edit_min_clip_duration)
        
        self.edit_clip_context_extend = QLineEdit(str(self.config_manager.get("CLIP_CONTEXT_EXTEND", 15.0)))
        form_basic.addRow("å‰åæ–‡æ‰©å±•æ—¶é•¿(ç§’):", self.edit_clip_context_extend)
        
        self.edit_clip_merge_threshold = QLineEdit(str(self.config_manager.get("CLIP_MERGE_THRESHOLD", 10.0)))
        form_basic.addRow("åˆ‡ç‰‡åˆå¹¶é˜ˆå€¼(ç§’):", self.edit_clip_merge_threshold)
        
        # è¯­ä¹‰åˆå¹¶é…ç½®
        self.edit_semantic_similarity_threshold = QLineEdit(str(self.config_manager.get("SEMANTIC_SIMILARITY_THRESHOLD", 0.75)))
        form_basic.addRow("è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼(0-1):", self.edit_semantic_similarity_threshold)
        
        self.edit_semantic_max_time_gap = QLineEdit(str(self.config_manager.get("SEMANTIC_MAX_TIME_GAP", 60.0)))
        form_basic.addRow("è¯­ä¹‰åˆå¹¶æœ€å¤§é—´éš”(ç§’):", self.edit_semantic_max_time_gap)
        

        
        # å¼€å…³é€‰é¡¹
        self.checkbox_enable_gpu = QCheckBox()
        self.checkbox_enable_gpu.setChecked(self.config_manager.get("ENABLE_GPU_ACCELERATION", True))
        form_basic.addRow("å¯ç”¨GPUåŠ é€Ÿ:", self.checkbox_enable_gpu)
        
        self.checkbox_enable_video_emotion = QCheckBox()
        self.checkbox_enable_video_emotion.setChecked(self.config_manager.get("ENABLE_VIDEO_EMOTION"))
        self.checkbox_enable_video_emotion.toggled.connect(self.on_video_emotion_toggled)
        form_basic.addRow("å¯ç”¨è§†é¢‘æƒ…ç»ªåˆ†æ:", self.checkbox_enable_video_emotion)
        
        self.checkbox_merge_nearby_clips = QCheckBox()
        self.checkbox_merge_nearby_clips.setChecked(self.config_manager.get("MERGE_NEARBY_CLIPS", True))
        form_basic.addRow("åˆå¹¶ç›¸é‚»åˆ‡ç‰‡:", self.checkbox_merge_nearby_clips)
        
        self.checkbox_enable_semantic_merge = QCheckBox()
        self.checkbox_enable_semantic_merge.setChecked(self.config_manager.get("ENABLE_SEMANTIC_MERGE", True))
        form_basic.addRow("å¯ç”¨è¯­ä¹‰åˆå¹¶:", self.checkbox_enable_semantic_merge)
        
        # æ£€æŸ¥ç‚¹ç®¡ç†
        self.init_checkpoint_management(form_basic)
        
        tabs.addTab(tab_basic, "åŸºæœ¬è®¾ç½®")
    
    def init_weights_tab(self, tabs):
        tab_weights = QWidget()
        form_weights = QFormLayout(tab_weights)
        
        self.edit_chat_density = QLineEdit(str(self.config_manager.get("CHAT_DENSITY_WEIGHT")))
        form_weights.addRow("Chat å¯†åº¦æƒé‡:", self.edit_chat_density)
        
        self.edit_chat_sentiment = QLineEdit(str(self.config_manager.get("CHAT_SENTIMENT_WEIGHT")))
        form_weights.addRow("Chat æƒ…ç»ªæƒé‡:", self.edit_chat_sentiment)
        
        self.edit_video_emotion_weight = QLineEdit(str(self.config_manager.get("VIDEO_EMOTION_WEIGHT")))
        form_weights.addRow("è§†é¢‘æƒ…ç»ªæƒé‡:", self.edit_video_emotion_weight)
        
        self.edit_interest_threshold = QLineEdit(str(self.config_manager.get("INTEREST_SCORE_THRESHOLD")))
        form_weights.addRow("å…´è¶£åˆ†æ•°é˜ˆå€¼:", self.edit_interest_threshold)
        
        tabs.addTab(tab_weights, "æƒé‡è®¾ç½®")

    def init_monitor_tab(self, tabs):
        tab_monitor = QWidget()
        form = QFormLayout(tab_monitor)

        if not self.monitor_runtime or not self.monitor_config:
            label = QLabel("å½“å‰ç¯å¢ƒæœªå®‰è£… StreamGet æˆ–ç›´æ’­ç›‘æ§æ¨¡å—ï¼Œæ— æ³•ç¼–è¾‘ç›¸å…³è®¾ç½®ã€‚")
            label.setWordWrap(True)
            form.addRow(label)
            tabs.addTab(tab_monitor, "ç›‘æ§")
            return

        self.monitor_ffmpeg_edit = QLineEdit(self.monitor_config.ffmpeg_path)
        form.addRow("ffmpeg è·¯å¾„:", self.monitor_ffmpeg_edit)

        self.monitor_quality_combo = QComboBox()
        self.monitor_quality_combo.addItems(["OD", "UHD", "HD", "SD", "LD"])
        idx = self.monitor_quality_combo.findText(self.monitor_config.default_quality)
        if idx >= 0:
            self.monitor_quality_combo.setCurrentIndex(idx)
        form.addRow("é»˜è®¤æ¸…æ™°åº¦:", self.monitor_quality_combo)

        self.monitor_poll_spin = QSpinBox()
        self.monitor_poll_spin.setRange(5, 3600)
        self.monitor_poll_spin.setValue(int(self.monitor_config.default_poll_interval))
        form.addRow("é»˜è®¤è½®è¯¢é—´éš”(ç§’):", self.monitor_poll_spin)

        self.monitor_format_combo = QComboBox()
        self.monitor_format_combo.addItems(["mp4", "flv", "ts", "mkv"])
        idx = self.monitor_format_combo.findText(self.monitor_config.default_format)
        if idx >= 0:
            self.monitor_format_combo.setCurrentIndex(idx)
        form.addRow("é»˜è®¤å°è£…æ ¼å¼:", self.monitor_format_combo)

        self.monitor_output_edit = QLineEdit(str(self.monitor_config.output_root))
        out_layout = QHBoxLayout()
        out_layout.addWidget(self.monitor_output_edit)
        btn_choose = QPushButton("é€‰æ‹©")
        btn_choose.clicked.connect(self.choose_monitor_output_dir)
        out_layout.addWidget(btn_choose)
        form.addRow("è¾“å‡ºæ ¹ç›®å½•:", out_layout)

        tabs.addTab(tab_monitor, "ç›‘æ§")

    def choose_monitor_output_dir(self):
        directory = QFileDialog.getExistingDirectory(self, "é€‰æ‹©è¾“å‡ºæ ¹ç›®å½•", self.monitor_output_edit.text())
        if directory:
            self.monitor_output_edit.setText(directory)
    
    def init_checkpoint_management(self, form):
        checkpoint_layout = QHBoxLayout()
        
        btn_view_checkpoint = QPushButton("æŸ¥çœ‹æ£€æŸ¥ç‚¹")
        btn_view_checkpoint.clicked.connect(self.view_checkpoint_info)
        btn_view_checkpoint.setStyleSheet("QPushButton { padding: 5px 15px; }")
        checkpoint_layout.addWidget(btn_view_checkpoint)
        
        btn_clear_checkpoint = QPushButton("æ¸…ç†æ£€æŸ¥ç‚¹")
        btn_clear_checkpoint.clicked.connect(self.clear_checkpoint_confirm)
        btn_clear_checkpoint.setStyleSheet("QPushButton { padding: 5px 15px; background-color: #dc3545; color: white; }")
        checkpoint_layout.addWidget(btn_clear_checkpoint)
        
        form.addRow("æ£€æŸ¥ç‚¹ç®¡ç†:", checkpoint_layout)
    
    def init_buttons(self, layout):
        btns = QHBoxLayout()
        btn_ok = QPushButton("ä¿å­˜å¹¶å…³é—­")
        btn_ok.clicked.connect(self.on_save)
        btn_cancel = QPushButton("å–æ¶ˆ")
        btn_cancel.clicked.connect(self.reject)
        btns.addWidget(btn_ok)
        btns.addWidget(btn_cancel)
        layout.addLayout(btns)
    
    def choose_clips_dir(self):
        d = QFileDialog.getExistingDirectory(self, "é€‰æ‹©åˆ‡ç‰‡åŸºç¡€ç›®å½•", self.edit_clips_base_dir.text())
        if d:
            self.edit_clips_base_dir.setText(d)
            
    def choose_replay_dir(self):
        """é€‰æ‹©å›æ”¾ä¸‹è½½ç›®å½•"""
        d = QFileDialog.getExistingDirectory(self, "é€‰æ‹©å›æ”¾ä¸‹è½½ç›®å½•", self.edit_replay_download_dir.text())
        if d:
            self.edit_replay_download_dir.setText(d)

    def toggle_hf_visibility(self, checked):
        """åˆ‡æ¢ HuggingFace token çš„æ˜¾ç¤º/éšè—ã€‚"""
        if checked:
            self.edit_hf_token.setEchoMode(QLineEdit.Normal)
            self.btn_toggle_hf.setText("éšè—")
        else:
            self.edit_hf_token.setEchoMode(QLineEdit.Password)
            self.btn_toggle_hf.setText("æ˜¾ç¤º")
    
    def on_video_emotion_toggled(self, checked):
        self.edit_video_emotion.setEnabled(checked)
        self.edit_emotion_segment_length.setEnabled(checked)
        self.edit_video_emotion_weight.setEnabled(checked)
    
    def view_checkpoint_info(self):
        try:
            # analyze_data ä½äº processing åŒ…ä¸‹ï¼Œä¸èƒ½ä½¿ç”¨å½“å‰åŒ…çš„ç›¸å¯¹å¯¼å…¥
            from acfv.processing.analyze_data import CheckpointManager
            checkpoint_manager = CheckpointManager()
            
            if not checkpoint_manager.has_checkpoint():
                QMessageBox.information(self, "æ£€æŸ¥ç‚¹ä¿¡æ¯", "å½“å‰æ²¡æœ‰ä¿å­˜çš„æ£€æŸ¥ç‚¹ã€‚")
                return
            
            checkpoint_info = checkpoint_manager.get_checkpoint_info()
            if checkpoint_info:
                progress_percent = checkpoint_info['processed_count']/checkpoint_info['total_count']*100 if checkpoint_info['total_count'] > 0 else 0
                
                info_text = f"""æ£€æŸ¥ç‚¹è¯¦ç»†ä¿¡æ¯:

ğŸ“¹ è§†é¢‘æ–‡ä»¶: {os.path.basename(checkpoint_info['video_path'])}
ğŸ“Š åˆ†æè¿›åº¦: {checkpoint_info['processed_count']}/{checkpoint_info['total_count']} ç‰‡æ®µ
ğŸ’¾ å®Œæˆåº¦: {progress_percent:.1f}%
â° ä¸Šæ¬¡ä¿å­˜: {checkpoint_info['last_save_time']}
ğŸ”§ é…ç½®å“ˆå¸Œ: {checkpoint_info['config_hash'][:16]}...

ğŸ’¡ æç¤º: ä¸‹æ¬¡å¤„ç†è§†é¢‘æ—¶å°†è‡ªåŠ¨è¯¢é—®æ˜¯å¦ç»§ç»­æ­¤ä»»åŠ¡ã€‚"""
                
                QMessageBox.information(self, "æ£€æŸ¥ç‚¹ä¿¡æ¯", info_text)
            else:
                QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•è¯»å–æ£€æŸ¥ç‚¹ä¿¡æ¯ã€‚")
        except Exception as e:
            QMessageBox.warning(self, "é”™è¯¯", f"æŸ¥çœ‹æ£€æŸ¥ç‚¹ä¿¡æ¯å¤±è´¥: {e}")
    
    def clear_checkpoint_confirm(self):
        try:
            from acfv.processing.analyze_data import CheckpointManager
            checkpoint_manager = CheckpointManager()
            
            if not checkpoint_manager.has_checkpoint():
                QMessageBox.information(self, "æç¤º", "å½“å‰æ²¡æœ‰ä¿å­˜çš„æ£€æŸ¥ç‚¹ã€‚")
                return
            
            checkpoint_info = checkpoint_manager.get_checkpoint_info()
            if checkpoint_info:
                progress_percent = checkpoint_info['processed_count']/checkpoint_info['total_count']*100 if checkpoint_info['total_count'] > 0 else 0
                
                reply = QMessageBox.question(
                    self, "ç¡®è®¤æ¸…ç†", 
                    f"ç¡®å®šè¦æ¸…ç†æ£€æŸ¥ç‚¹å—ï¼Ÿ\n\nå°†åˆ é™¤ä»¥ä¸‹è¿›åº¦:\nğŸ“¹ {os.path.basename(checkpoint_info['video_path'])}\nğŸ’¾ {progress_percent:.1f}% å®Œæˆåº¦\n\næ­¤æ“ä½œæ— æ³•æ’¤é”€ï¼",
                    QMessageBox.Yes | QMessageBox.No, QMessageBox.No
                )
                
                if reply == QMessageBox.Yes:
                    checkpoint_manager.clear_checkpoint()
                    QMessageBox.information(self, "å®Œæˆ", "æ£€æŸ¥ç‚¹å·²æ¸…ç†ã€‚")
        except Exception as e:
            QMessageBox.warning(self, "é”™è¯¯", f"æ¸…ç†æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def on_save(self):
        # ä¿å­˜æ‰€æœ‰è®¾ç½®
        self.config_manager.set("MAX_CLIP_COUNT", int(self.edit_max_clips.text().strip() or 0))
        self.config_manager.set("CLIPS_BASE_DIR", self.edit_clips_base_dir.text().strip())
        self.config_manager.set("replay_download_folder", self.edit_replay_download_dir.text().strip())
        self.config_manager.set("WHISPER_MODEL", self.edit_whisper.text().strip())
        self.config_manager.set("HUGGINGFACE_TOKEN", self.edit_hf_token.text().strip())
        self.config_manager.set("LOCAL_EMOTION_MODEL_PATH", self.edit_local_emotion.text().strip())
        self.config_manager.set("VIDEO_EMOTION_MODEL_PATH", self.edit_video_emotion.text().strip())
        self.config_manager.set("VIDEO_EMOTION_SEGMENT_LENGTH", float(self.edit_emotion_segment_length.text().strip() or 4.0))
        self.config_manager.set("ENABLE_VIDEO_EMOTION", self.checkbox_enable_video_emotion.isChecked())
        self.config_manager.set("LLM_DEVICE", int(self.edit_llm_device.text().strip()))
        self.config_manager.set("CHAT_DENSITY_WEIGHT", float(self.edit_chat_density.text().strip()))
        self.config_manager.set("CHAT_SENTIMENT_WEIGHT", float(self.edit_chat_sentiment.text().strip()))
        self.config_manager.set("VIDEO_EMOTION_WEIGHT", float(self.edit_video_emotion_weight.text().strip()))
        self.config_manager.set("INTEREST_SCORE_THRESHOLD", float(self.edit_interest_threshold.text().strip()))
        self.config_manager.set("CHECKPOINT_INTERVAL", int(self.edit_checkpoint_interval.text().strip() or 10))
        self.config_manager.set("MAX_WORKERS", int(self.edit_max_workers.text().strip() or 4))
        self.config_manager.set("GPU_DEVICE", self.edit_gpu_device.text().strip())
        self.config_manager.set("ENABLE_GPU_ACCELERATION", self.checkbox_enable_gpu.isChecked())
        
        # ä¿å­˜åˆ‡ç‰‡é…ç½®
        self.config_manager.set("MIN_CLIP_DURATION", float(self.edit_min_clip_duration.text().strip() or 60.0))
        self.config_manager.set("CLIP_CONTEXT_EXTEND", float(self.edit_clip_context_extend.text().strip() or 15.0))
        self.config_manager.set("CLIP_MERGE_THRESHOLD", float(self.edit_clip_merge_threshold.text().strip() or 10.0))
        self.config_manager.set("MERGE_NEARBY_CLIPS", self.checkbox_merge_nearby_clips.isChecked())
        
        # ä¿å­˜è¯­ä¹‰åˆå¹¶é…ç½®
        self.config_manager.set("ENABLE_SEMANTIC_MERGE", self.checkbox_enable_semantic_merge.isChecked())
        self.config_manager.set("SEMANTIC_SIMILARITY_THRESHOLD", float(self.edit_semantic_similarity_threshold.text().strip() or 0.75))
        self.config_manager.set("SEMANTIC_MAX_TIME_GAP", float(self.edit_semantic_max_time_gap.text().strip() or 60.0))

        if self.monitor_runtime and self.monitor_config:
            self.monitor_config.ffmpeg_path = self.monitor_ffmpeg_edit.text().strip() or "ffmpeg"
            self.monitor_config.default_quality = self.monitor_quality_combo.currentText()
            self.monitor_config.default_poll_interval = self.monitor_poll_spin.value()
            self.monitor_config.default_format = self.monitor_format_combo.currentText()
            output_root = self.monitor_output_edit.text().strip()
            if output_root:
                self.monitor_config.output_root = Path(output_root)
            self.monitor_runtime.save_stream_monitor_config(self.monitor_config, self.monitor_cfg_path)

        
        self.config_manager.save()
        self.accept()


class ClipRatingDialog(QDialog):
    """åˆ‡ç‰‡è¯„åˆ†å¯¹è¯æ¡†"""
    
    def __init__(self, clip_path, rating_file, parent=None):
        super().__init__(parent)
        self.clip_path = clip_path
        self.rating_file = rating_file
        self.clip_name = os.path.basename(clip_path)
        
        self.setWindowTitle(f"è¯„åˆ†: {self.clip_name}")
        self.resize(600, 400)
        self.init_ui()
        self.load_existing_rating()
    
    def init_ui(self):
        layout = QVBoxLayout(self)
        
        # è§†é¢‘é¢„è§ˆ
        self.preview = QLabel("è§†é¢‘é¢„è§ˆ")
        self.preview.setAlignment(Qt.AlignCenter)
        self.preview.setMinimumHeight(240)
        self.load_video_preview()
        layout.addWidget(self.preview)
        
        # æ’­æ”¾æŒ‰é’®
        btn_open = QPushButton("æ’­æ”¾è§†é¢‘")
        btn_open.clicked.connect(self.play_video)
        layout.addWidget(btn_open)
        
        # è¯„åˆ†æ»‘å—
        self.init_rating_slider(layout)
        
        # å¤‡æ³¨
        layout.addWidget(QLabel("å¤‡æ³¨:"))
        self.notes = QTextEdit()
        layout.addWidget(self.notes)
        
        # æŒ‰é’®
        self.init_buttons(layout)
    
    def load_video_preview(self):
        cap = cv2.VideoCapture(self.clip_path)
        ret, frame = cap.read()
        if ret:
            h, w, _ = frame.shape
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = QImage(rgb.data, w, h, 3 * w, QImage.Format_RGB888)
            pix = QPixmap.fromImage(img).scaled(
                560, 315, Qt.KeepAspectRatio | Qt.SmoothTransformation
            )
            self.preview.setPixmap(pix)
        cap.release()
    
    def init_rating_slider(self, layout):
        rating_layout = QHBoxLayout()
        rating_layout.addWidget(QLabel("è¯„åˆ†:"))
        
        self.rating_slider = QSlider(Qt.Horizontal)
        self.rating_slider.setMinimum(1)
        self.rating_slider.setMaximum(5)
        self.rating_slider.setValue(3)
        self.rating_slider.setTickPosition(QSlider.TicksBelow)
        self.rating_slider.setTickInterval(1)
        rating_layout.addWidget(self.rating_slider)
        
        self.rating_label = QLabel("3 | ä¸€èˆ¬")
        self.rating_slider.valueChanged.connect(self.update_rating_label)
        rating_layout.addWidget(self.rating_label)
        
        layout.addLayout(rating_layout)
    
    def init_buttons(self, layout):
        btns = QHBoxLayout()
        btn_save = QPushButton("ä¿å­˜è¯„åˆ†")
        btn_save.clicked.connect(self.save_rating)
        btn_cancel = QPushButton("å–æ¶ˆ")
        btn_cancel.clicked.connect(self.reject)
        btns.addWidget(btn_save)
        btns.addWidget(btn_cancel)
        layout.addLayout(btns)
    
    def update_rating_label(self):
        v = self.rating_slider.value()
        mapping = {
            1: ("éå¸¸ä¸å–œæ¬¢", "#d9534f"),
            2: ("ä¸å–œæ¬¢", "#f0ad4e"),
            3: ("ä¸€èˆ¬", "#5bc0de"),
            4: ("å–œæ¬¢", "#5cb85c"),
            5: ("éå¸¸å–œæ¬¢", "#4cae4c"),
        }
        text, color = mapping.get(v, ("ä¸€èˆ¬", "#5bc0de"))
        self.rating_label.setText(f"{v} | {text}")
        # ç®€å•ç€è‰²
        self.rating_label.setStyleSheet(f"color:{color}; font-weight:bold;")
    
    def play_video(self):
        if sys.platform.startswith('win'):
            os.startfile(self.clip_path)
        elif sys.platform.startswith('darwin'):
            subprocess.call(['open', self.clip_path])
        else:
            subprocess.call(['xdg-open', self.clip_path])
    
    def load_existing_rating(self):
        if os.path.exists(self.rating_file):
            try:
                with open(self.rating_file, 'r', encoding='utf-8') as f:
                    ratings = json.load(f)
                    
                clip_basename = os.path.basename(self.clip_path)
                if clip_basename in ratings:
                    rating_data = ratings[clip_basename]
                    self.rating_slider.setValue(rating_data.get('rating', 3))
                    self.notes.setText(rating_data.get('notes', ''))
            except Exception as e:
                logging.error(f"åŠ è½½è¯„åˆ†å¤±è´¥: {e}")
    
    def save_rating(self):
        ratings = {}
        if os.path.exists(self.rating_file):
            try:
                with open(self.rating_file, 'r', encoding='utf-8') as f:
                    ratings = json.load(f)
            except Exception:
                pass
        
        clip_basename = os.path.basename(self.clip_path)
        # åˆå¹¶ä¿å­˜ï¼Œä¿ç•™å·²æœ‰çš„ text/start/end/duration ç­‰å­—æ®µï¼Œé¿å…è¦†ç›–ä¸¢å¤±
        existing = ratings.get(clip_basename, {}) if isinstance(ratings, dict) else {}
        try:
            new_entry = dict(existing)
        except Exception:
            new_entry = {}  # å›é€€
        new_entry.update({
            'rating': self.rating_slider.value(),
            'notes': self.notes.toPlainText(),
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        ratings[clip_basename] = new_entry
        
        try:
            with open(self.rating_file, 'w', encoding='utf-8') as f:
                json.dump(ratings, f, ensure_ascii=False, indent=2)
                # ç§»é™¤è¯„åˆ†åçš„RAGè‡ªåŠ¨å¤„ç†
                self.accept()
        except Exception as e:
            QMessageBox.warning(self, "é”™è¯¯", f"ä¿å­˜è¯„åˆ†å¤±è´¥: {e}")

    def _infer_video_dir(self, clip_path: str):
        """ä»åˆ‡ç‰‡è·¯å¾„æ¨æ–­è§†é¢‘ç›®å½•ä¸åç§°ï¼š.../clips/<video_name>/runs/run_xxx/output_clips/file.mp4"""
        p = os.path.abspath(clip_path)
        # å‘ä¸ŠæŸ¥æ‰¾ 'runs' ç›®å½•
        d = os.path.dirname(p)
        for _ in range(5):
            name = os.path.basename(d)
            if name == 'runs':
                video_dir = os.path.dirname(d)
                return video_dir, os.path.basename(video_dir)
            d = os.path.dirname(d)
        # å›é€€ï¼šè¿”å›çˆ¶ç›®å½•
        video_dir = os.path.dirname(os.path.dirname(os.path.dirname(p)))
        return video_dir, os.path.basename(video_dir)

    def _parse_time_from_filename(self, filename: str):
        """ä»æ–‡ä»¶åä¸­è§£æèµ·æ­¢æ—¶é—´ï¼š..._<start>s-<end>s.mp4"""
        try:
            m = re.search(r"_(\d+(?:\.\d+)?)s-(\d+(?:\.\d+)?)s\.[Mm][Pp]4$", filename)
            if m:
                return float(m.group(1)), float(m.group(2))
        except Exception:
            pass
        return None, None

    def _extract_transcript_text(self, video_dir_path: str, start_s: float, end_s: float) -> str:
        """æå–ä¸ç‰‡æ®µæ—¶é—´èŒƒå›´é‡å çš„è½¬å½•æ–‡æœ¬å¹¶æ‹¼æ¥ï¼ˆä»…ç”¨äºè‹±æ–‡å‘é‡ç”Ÿæˆï¼‰"""
        try:
            if not video_dir_path:
                return ""
            transcript_candidates = [
                os.path.join(video_dir_path, 'data', 'transcription.json'),
                os.path.join(video_dir_path, 'transcription.json'),
            ]
            for fp in transcript_candidates:
                if os.path.exists(fp):
                    with open(fp, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    texts = []
                    for seg in data if isinstance(data, list) else []:
                        try:
                            st = float(seg.get('start', 0))
                            et = float(seg.get('end', 0))
                            if start_s is None or end_s is None or (et >= start_s and st <= end_s):
                                txt = str(seg.get('text', '')).strip()
                                if txt:
                                    texts.append(txt)
                        except Exception:
                            continue
                    return '\n'.join(texts)[:4000]
        except Exception as e:
            logging.debug(f"_extract_transcript_textå¼‚å¸¸ï¼š{e}")
        return ""


# å…¼å®¹æ€§åˆ«åï¼Œä¿æŒå‘åå…¼å®¹
VideoThumbnailLoader = SimpleThumbnailLoader
ClipThumbnailLoader = SimpleClipThumbnailLoader
