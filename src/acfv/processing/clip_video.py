import os
import subprocess
from main_logging import log_info, log_error, log_debug, log_warning
import datetime
import json
from acfv import config

# å¯é€‰ä¾èµ–ï¼šcv2
try:
    import cv2
    CV2_AVAILABLE = True
    log_info("[clip_video] OpenCVæ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    CV2_AVAILABLE = False
    log_warning(f"[clip_video] OpenCVæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    log_info("[clip_video] å°†ä½¿ç”¨æ›¿ä»£æ–¹æ³•å¤„ç†è§†é¢‘ä¿¡æ¯")

# è¯­ä¹‰åˆ†æç›¸å…³å¯¼å…¥
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    SEMANTIC_AVAILABLE = True
    log_info("[clip_video] è¯­ä¹‰åˆ†ææ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    SEMANTIC_AVAILABLE = False
    log_error(f"[clip_video] è¯­ä¹‰åˆ†ææ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

# å…¨å±€å˜é‡ç”¨äºç¼“å­˜TF-IDFå‘é‡å™¨
_tfidf_vectorizer = None

def _probe_clip_info(output_path):
    """ä½¿ç”¨ ffprobe æ£€æŸ¥è¾“å‡ºæ–‡ä»¶çš„æ—¶é•¿ä¸æ˜¯å¦åŒ…å«è§†é¢‘æµã€‚
    è¿”å› (has_video_stream: bool, has_audio_stream: bool, duration_seconds: float)
    """
    try:
        cmd = [
            'ffprobe', '-v', 'quiet', '-print_format', 'json',
            '-show_format', '-show_streams', output_path
        ]
        pr = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', timeout=15)
        if pr.returncode != 0:
            return False, False, 0.0
        import json as _json
        info = _json.loads(pr.stdout or '{}')
        streams = info.get('streams', []) or []
        has_video = any(s.get('codec_type') == 'video' for s in streams)
        has_audio = any(s.get('codec_type') == 'audio' for s in streams)
        duration = 0.0
        try:
            duration = float((info.get('format') or {}).get('duration') or 0.0)
        except Exception:
            duration = 0.0
        return has_video, has_audio, duration
    except Exception:
        return False, False, 0.0

def cut_video_ffmpeg(input_path, output_path, start_time, duration):
    """ä½¿ç”¨FFmpegå¿«é€Ÿåˆ‡ç‰‡ï¼Œä¼˜å…ˆæµæ‹·è´ï¼›è‹¥æ£€æµ‹åˆ°å¼‚å¸¸ï¼ˆ0ç§’/æ— è§†é¢‘æµï¼‰ï¼Œè‡ªåŠ¨å›é€€é‡ç¼–ç ã€‚"""
    fast_cmd = [
        "ffmpeg", "-y",
        "-hide_banner", "-loglevel", "error", "-nostdin",
        "-ss", str(start_time),
        "-i", input_path,
        "-t", str(duration),
        "-map", "0:v:0",
        "-map", "0:a?",
        "-c:v", "copy",
        "-c:a", "aac",
        "-b:a", "160k",
        "-movflags", "+faststart",
        output_path
    ]
    subprocess.run(fast_cmd, check=True)

    # æ ¡éªŒè¾“å‡ºï¼Œé¿å…ç”Ÿæˆ0ç§’æ–‡ä»¶
    has_v, has_a, dur = _probe_clip_info(output_path)
    if (not has_v) or (dur <= 0.5):
        # å›é€€åˆ°é‡ç¼–ç æ¨¡å¼ï¼Œç¡®ä¿å¯æ’­æ”¾
        fallback_cmd = [
            "ffmpeg", "-y",
            "-hide_banner", "-loglevel", "error", "-nostdin",
            "-ss", str(start_time),
            "-i", input_path,
            "-t", str(duration),
            "-map", "0:v:0",
            "-map", "0:a?",
            "-c:v", "libx264",
            "-preset", "veryfast",
            "-crf", "23",
            "-pix_fmt", "yuv420p",
            "-c:a", "aac",
            "-b:a", "160k",
            "-fflags", "+genpts",
            "-avoid_negative_ts", "make_zero",
            "-reset_timestamps", "1",
            "-movflags", "+faststart",
            output_path
        ]
        subprocess.run(fallback_cmd, check=True)

def generate_clips_from_segments(video_path, segments, output_dir, progress_callback=None, audio_source=None):
    """ä»ç‰‡æ®µç”Ÿæˆåˆ‡ç‰‡æ–‡ä»¶"""
    clip_files = []
    
    for i, segment in enumerate(segments):
        try:
            start_time = segment['start']
            end_time = segment['end']
            duration = end_time - start_time
            
            # ğŸ†• éªŒè¯ç‰‡æ®µæ•°æ®
            if start_time >= end_time:
                log_error(f"[clip_video] âŒ ç‰‡æ®µ {i+1} æ•°æ®å¼‚å¸¸: start={start_time:.1f}s >= end={end_time:.1f}s")
                log_error(f"[clip_video] è·³è¿‡å¼‚å¸¸ç‰‡æ®µ: {segment}")
                continue
                
            if duration <= 0:
                log_error(f"[clip_video] âŒ ç‰‡æ®µ {i+1} æŒç»­æ—¶é—´å¼‚å¸¸: {duration:.1f}s")
                continue
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            segment_index = i + 1
            clip_filename = f"clip_{segment_index:03d}_{start_time:.1f}s-{end_time:.1f}s.mp4"
            output_path = os.path.join(output_dir, clip_filename)
            
            # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§æ–‡ä»¶
            if os.path.exists(output_path):
                try:
                    os.remove(output_path)
                    log_info(f"[clip_video] æ¸…ç†æ—§æ–‡ä»¶: {output_path}")
                except Exception as e:
                    log_warning(f"[clip_video] æ¸…ç†æ—§æ–‡ä»¶å¤±è´¥: {e}")
            
            log_info(f"[clip_video] ç”Ÿæˆåˆ‡ç‰‡ {i+1}/{len(segments)}: {clip_filename} ({duration:.1f}s)")
            
            # ä½¿ç”¨å¿«é€Ÿåˆ‡ç‰‡å‡½æ•°
            try:
                cut_video_ffmpeg(video_path, output_path, start_time, duration)
                
                if os.path.exists(output_path):
                    clip_files.append(output_path)
                    log_info(f"[clip_video] åˆ‡ç‰‡ç”ŸæˆæˆåŠŸ: {clip_filename}")
                    
                    # æ›´æ–°è¿›åº¦
                    if progress_callback:
                        try:
                            progress_callback(i + 1, len(segments))
                        except:
                            pass
                else:
                    log_error(f"[clip_video] åˆ‡ç‰‡æ–‡ä»¶æœªç”Ÿæˆ: {clip_filename}")
                    
            except subprocess.CalledProcessError as e:
                log_error(f"[clip_video] FFmpegåˆ‡ç‰‡å¤±è´¥: {clip_filename}")
                log_error(f"[clip_video] FFmpegé”™è¯¯: {e}")
                
        except Exception as e:
            log_error(f"[clip_video] ç”Ÿæˆåˆ‡ç‰‡ {i+1} æ—¶å‡ºé”™: {e}")
    
    log_info(f"[clip_video] åˆ‡ç‰‡ç”Ÿæˆå®Œæˆï¼ŒæˆåŠŸç”Ÿæˆ {len(clip_files)} ä¸ªæ–‡ä»¶")
    return clip_files

def get_video_duration(video_path):
    """è·å–è§†é¢‘æ—¶é•¿"""
    try:
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
        cap.release()
        
        if fps > 0:
            return frame_count / fps
        return 0
    except Exception as e:
        log_error(f"[clip_video] è·å–è§†é¢‘æ—¶é•¿å¤±è´¥: {e}")
        return 0

def clip_video(video_path, analysis_file, output_dir, progress_callback=None, audio_source=None):
    """
    æ ¹æ®åˆ†æç»“æœå‰ªè¾‘è§†é¢‘ - åŸºäºè¯­ä¹‰çš„è‡ªé€‚åº”åˆ†æ®µï¼ˆä¸å¼ºåˆ¶å›ºå®š5åˆ†é’Ÿï¼‰
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        analysis_file: åˆ†æç»“æœæ–‡ä»¶è·¯å¾„
        output_dir: å‰ªè¾‘è¾“å‡ºç›®å½•
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        audio_source: éŸ³é¢‘æºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºæ›¿æ¢è§†é¢‘ä¸­çš„éŸ³é¢‘ï¼‰
    
    Returns:
        list: å‰ªè¾‘æ–‡ä»¶åˆ—è¡¨
    """
    # è¯»å–åˆ†æç»“æœ
    try:
        with open(analysis_file, 'r', encoding='utf-8') as f:
            segments = json.load(f)
        log_info(f"[clip_video] æˆåŠŸè¯»å–åˆ†æç»“æœæ–‡ä»¶: {analysis_file}")
        log_info(f"[clip_video] åˆ†æç»“æœåŒ…å« {len(segments)} ä¸ªç‰‡æ®µ")
    except Exception as e:
        log_error(f"[clip_video] Error reading analysis file: {e}")
        log_error(f"[clip_video] åˆ†ææ–‡ä»¶è·¯å¾„: {analysis_file}")
        log_error(f"[clip_video] æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(analysis_file)}")
        return []

    if not segments:
        log_error("[clip_video] No segments to clip")
        log_error(f"[clip_video] åˆ†æç»“æœä¸ºç©ºï¼Œæ–‡ä»¶: {analysis_file}")
        return []
        
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        log_error(f"[clip_video] Video file not found: {video_path}")
        return []

    # æµ‹è¯•ffmpegæ˜¯å¦å¯ç”¨
    try:
        test_result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True, timeout=10)
        if test_result.returncode != 0:
            log_error("[clip_video] ffmpegä¸å¯ç”¨")
            return []
        log_info("[clip_video] ffmpegå¯ç”¨")
    except Exception as e:
        log_error(f"[clip_video] ffmpegæµ‹è¯•å¤±è´¥: {e}")
        return []
        
    # è·å–è§†é¢‘æ€»æ—¶é•¿
    video_duration = get_video_duration(video_path)
    if video_duration <= 0:
        log_error("[clip_video] Could not determine video duration")
        return []

    log_info(f"[clip_video] Video duration: {video_duration:.1f}s")
    
    # ğŸ†• è°ƒè¯•ï¼šæ£€æŸ¥ä¼ å…¥çš„segmentsæ•°æ®
    log_info(f"[clip_video] æ”¶åˆ° {len(segments)} ä¸ªç‰‡æ®µ")
    
    # ğŸ†• è¿‡æ»¤æ— æ•ˆç‰‡æ®µ
    valid_segments = []
    for i, seg in enumerate(segments):
        start = seg.get('start', 0)
        end = seg.get('end', 0)
        score = seg.get('score', 0)
        
        # æ£€æŸ¥ç‰‡æ®µæœ‰æ•ˆæ€§
        if start >= end:
            log_warning(f"[clip_video] è·³è¿‡æ— æ•ˆç‰‡æ®µ {i+1}: start({start}) >= end({end})")
            continue
            
        if score <= 0:
            log_warning(f"[clip_video] è·³è¿‡ä½åˆ†ç‰‡æ®µ {i+1}: score={score}")
            continue
            
        if end - start < 5:  # å°‘äº5ç§’çš„ç‰‡æ®µ
            log_warning(f"[clip_video] è·³è¿‡è¿‡çŸ­ç‰‡æ®µ {i+1}: æŒç»­æ—¶é—´={end-start:.1f}s")
            continue
            
        valid_segments.append(seg)
        log_info(f"[clip_video] æœ‰æ•ˆç‰‡æ®µ {len(valid_segments)}: {start:.1f}s-{end:.1f}s, è¯„åˆ†={score:.3f}")
    
    if len(valid_segments) == 0:
        log_error("[clip_video] âŒ æ²¡æœ‰æœ‰æ•ˆçš„ç‰‡æ®µæ•°æ®ï¼")
        return []
        
    log_info(f"[clip_video] è¿‡æ»¤åå‰©ä½™ {len(valid_segments)} ä¸ªæœ‰æ•ˆç‰‡æ®µ")
    segments = valid_segments  # ä½¿ç”¨è¿‡æ»¤åçš„ç‰‡æ®µ
    
    # è¯­ä¹‰ç›¸è¿‘èšåˆä¸ºè‡ªé€‚åº”åˆ‡ç‰‡
    log_info("[clip_video] å¯ç”¨è¯­ä¹‰è‡ªé€‚åº”åˆ†æ®µæ¨¡å¼")

    def _simple_tokenize(text: str):
        import re
        text = (text or "").lower()
        text = re.sub(r"[^\w\u4e00-\u9fa5]+", " ", text)
        return [tok for tok in text.split() if len(tok) > 1]

    def _cosine_dict(a: dict, b: dict):
        if not a or not b:
            return 0.0
        import math
        dot = 0.0
        for k, v in a.items():
            if k in b:
                dot += v * b[k]
        na = math.sqrt(sum(v*v for v in a.values()))
        nb = math.sqrt(sum(v*v for v in b.values()))
        if na == 0 or nb == 0:
            return 0.0
        return dot / (na * nb)

    def _vectorize_texts(texts):
        """è¿”å› (vectors, method)ï¼›ä¼˜å…ˆTF-IDFï¼Œå¤±è´¥åˆ™ç¨€ç–è®¡æ•°å‘é‡"""
        try:
            global _tfidf_vectorizer
            if SEMANTIC_AVAILABLE:
                if _tfidf_vectorizer is None:
                    _tfidf_vectorizer = TfidfVectorizer(max_features=5000)
                mat = _tfidf_vectorizer.fit_transform(texts)
                return mat, 'tfidf'
        except Exception as e:
            log_warning(f"[clip_video] TF-IDFå‘é‡åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€æ˜“å‘é‡: {e}")
        # fallback: è®¡æ•°å‘é‡
        from collections import Counter
        vecs = [Counter(_simple_tokenize(t)) for t in texts]
        return vecs, 'bow'

    # æŒ‰å¼€å§‹æ—¶é—´æ’åº
    segments.sort(key=lambda s: (float(s.get('start', 0.0)), -float(s.get('score', 0.0))))
    texts = [s.get('text', '') for s in segments]
    vecs, method = _vectorize_texts(texts)
    log_info(f"[clip_video] è¯­ä¹‰å‘é‡æ–¹å¼: {method}")

    # ä»é…ç½®è¯»å–é˜ˆå€¼
    try:
        cm = config.config_manager
        min_sec = float(cm.get("MIN_CLIP_DURATION", 60.0))
        sim_threshold = float(cm.get("SEMANTIC_SIMILARITY_THRESHOLD", 0.75))
        max_gap = float(cm.get("SEMANTIC_MAX_TIME_GAP", 60.0))
        # ä¸Šé™ä¸ºæœ€å°æ—¶é•¿çš„3å€ï¼Œé˜²æ­¢è¿‡é•¿
        max_sec = max(min_sec * 3.0, min_sec + 1.0)
    except Exception:
        min_sec = 60.0
        max_sec = 180.0
        sim_threshold = 0.18
        max_gap = 90.0

    processed_segments = []
    cur_start = None
    cur_end = None
    cur_score = 0.0
    cur_texts = []
    cur_indices = []

    def _flush_block():
        nonlocal cur_start, cur_end, cur_score, cur_texts, cur_indices
        if cur_start is None:
            return
        processed_segments.append({
            'start': max(0.0, cur_start),
            'end': min(video_duration, cur_end),
            'score': cur_score,
            'text': ' '.join(cur_texts),
            'semantic_approx_5min': True,
            'original_indices': cur_indices[:]
        })
        cur_start = None
        cur_end = None
        cur_score = 0.0
        cur_texts = []
        cur_indices = []

    for idx, seg in enumerate(segments):
        s = float(seg.get('start', 0.0))
        e = float(seg.get('end', 0.0))
        sc = float(seg.get('score', 0.0))
        txt = seg.get('text', '')
        if cur_start is None:
            cur_start, cur_end = s, e
            cur_score = sc
            cur_texts = [txt]
            cur_indices = [idx]
            continue
        # ä¸ä¸Šä¸€æ®µçš„é—´éš”
        gap = s - cur_end
        # ç›¸ä¼¼åº¦ï¼ˆä¸ä¸Šä¸€æ®µæ¯”è¾ƒæˆ–ä¸å½“å‰å—æœ«æ®µæ¯”è¾ƒï¼‰
        similar = True
        try:
            if method == 'tfidf':
                # å–æœ¬æ®µä¸ä¸Šæ®µtfidfç›¸ä¼¼åº¦
                import numpy as np
                last_idx = cur_indices[-1]
                sim = float(cosine_similarity(vecs[last_idx], vecs[idx])[0][0])
            else:
                from collections import Counter
                last_idx = cur_indices[-1]
                sim = _cosine_dict(vecs[last_idx], vecs[idx])
            similar = sim >= sim_threshold
        except Exception:
            similar = True

        new_dur = (max(cur_end, e) - cur_start)
        # è‡ªé€‚åº”è§„åˆ™ï¼š
        # - æ—¶é—´é—´éš”è¿‡å¤§ -> ç»“å—
        # - è¾¾åˆ°ä¸Šé™ -> ç»“å—
        # - å·²è¾¾åˆ°æœ€å°æ—¶é•¿ä¸”è¯­ä¹‰ä¸ç›¸ä¼¼ -> ç»“å—
        if (gap > max_gap) or (new_dur >= max_sec) or ((new_dur >= min_sec) and (not similar)):
            # è‹¥å½“å‰å—ä¸è¶³æœ€å°é•¿åº¦ï¼Œå°½é‡å¹¶å…¥å½“å‰æ®µå†åˆ‡
            if (cur_end - cur_start) < min_sec and (new_dur <= max_sec):
                # å¹¶å…¥
                cur_end = max(cur_end, e)
                cur_score = max(cur_score, sc)
                cur_texts.append(txt)
                cur_indices.append(idx)
            else:
                _flush_block()
                cur_start, cur_end = s, e
                cur_score = sc
                cur_texts = [txt]
                cur_indices = [idx]
        else:
            # å¹¶å…¥å½“å‰å—
            cur_end = max(cur_end, e)
            cur_score = max(cur_score, sc)
            cur_texts.append(txt)
            cur_indices.append(idx)

    _flush_block()

    # çº¦æŸåˆ°è§†é¢‘èŒƒå›´ï¼Œå¹¶è¿‡æ»¤å¼‚å¸¸
    processed_segments = [p for p in processed_segments if (p['end'] - p['start']) > 1.0 and p['start'] < video_duration]
    processed_segments.sort(key=lambda x: x['start'])
    log_info(f"[clip_video] è¯­ä¹‰åˆ†æ®µå®Œæˆï¼Œå…±ç”Ÿæˆ {len(processed_segments)} ä¸ªç‰‡æ®µ")
    
    # ä¿å­˜å¤„ç†è®¡åˆ’
    plan_file = os.path.join(output_dir, "clip_plan.json")
    plan_data = {
        "mode": "semantic_variable",
        "min_sec": min_sec,
        "max_sec": max_sec,
        "sim_threshold": sim_threshold,
        "max_gap": max_gap,
        "segments": processed_segments,
        "video_duration": video_duration,
        "total_segments": len(processed_segments)
    }
    
    with open(plan_file, 'w', encoding='utf-8') as f:
        json.dump(plan_data, f, ensure_ascii=False, indent=2)
    
    log_info(f"[clip_video] åˆ‡ç‰‡è®¡åˆ’å·²ä¿å­˜åˆ°: {plan_file}")
    
    # ç›´æ¥è¿›å…¥åˆ‡ç‰‡ç”Ÿæˆé˜¶æ®µ
    return generate_clips_from_segments(video_path, processed_segments, output_dir, progress_callback, audio_source)


def extend_segment(segment, context_extend, video_duration):
    """æ‰©å±•ç‰‡æ®µå‰åæ–‡"""
    try:
        start = segment['start']
        end = segment['end']
        
        # å‘å‰æ‰©å±•
        new_start = max(0, start - context_extend)
        # å‘åæ‰©å±•
        new_end = min(video_duration, end + context_extend)
        
        # æ›´æ–°ç‰‡æ®µ
        segment['start'] = new_start
        segment['end'] = new_end
        
        log_debug(f"[clip_video] æ‰©å±•ç‰‡æ®µ: {start:.1f}-{end:.1f}s -> {new_start:.1f}-{new_end:.1f}s")
        return segment
        
    except Exception as e:
        log_error(f"[clip_video] æ‰©å±•ç‰‡æ®µå¤±è´¥: {e}")
        return segment


def ensure_min_duration(segments_data, min_duration, video_duration):
    """ç¡®ä¿ç‰‡æ®µè¾¾åˆ°æœ€å°æ—¶é•¿"""
    try:
        processed_segments = []
        
        for segment in segments_data:
            start = segment['start']
            end = segment['end']
            current_duration = end - start
            
            if current_duration < min_duration:
                # è®¡ç®—éœ€è¦æ‰©å±•çš„æ€»æ—¶é•¿
                extend_total = min_duration - current_duration
                extend_each = extend_total / 2  # å‰åå„æ‰©å±•ä¸€åŠ
                
                # è®¡ç®—æ–°çš„å¼€å§‹å’Œç»“æŸæ—¶é—´
                new_start = max(0, start - extend_each)
                new_end = min(video_duration, end + extend_each)
                
                # å¦‚æœå‰é¢æ— æ³•æ‰©å±•è¶³å¤Ÿï¼Œåé¢å¤šæ‰©å±•ä¸€äº›
                if new_start == 0:
                    new_end = min(video_duration, start + min_duration)
                # å¦‚æœåé¢æ— æ³•æ‰©å±•è¶³å¤Ÿï¼Œå‰é¢å¤šæ‰©å±•ä¸€äº›
                elif new_end == video_duration:
                    new_start = max(0, end - min_duration)
                
                segment['start'] = new_start
                segment['end'] = new_end
                
                log_debug(f"[clip_video] æ‰©å±•ç‰‡æ®µè‡³æœ€å°æ—¶é•¿: {start:.1f}-{end:.1f}s ({current_duration:.1f}s) -> {new_start:.1f}-{new_end:.1f}s ({new_end - new_start:.1f}s)")
            
            processed_segments.append(segment)
        
        return processed_segments
        
    except Exception as e:
        log_error(f"[clip_video] ç¡®ä¿æœ€å°æ—¶é•¿å¤±è´¥: {e}")
        return segments_data
