    1: # Extracted core backend functionality from main.py
    2: 
    3: from __future__ import annotations
    4: 
    5: from typing import List, Tuple
    6: 
    7: def _segment_score(seg: dict) -> float:
    8:     for key in ("score", "interest_score", "rating", "density", "clip_score"):
    9:         val = seg.get(key)
   10:         if val is None:
   11:             continue
   12:         try:
   13:             return float(val)
   14:         except Exception:
   15:             continue
   16:     return 0.0
   17: 
   18: def _normalize_segments_to_target(
   19:     segments: List[dict],
   20:     desired_count: int,
   21:     video_duration: float,
   22:     min_sec: float,
   23:     target_sec: float,
   24:     max_sec: float,
   25:     prefer_score: bool = True,
   26: ) -> List[dict]:
   27:     processed: List[Tuple[float, int, float, float, dict]] = []
   28:     for idx, seg in enumerate(segments):
   29:         try:
   30:             start = float(seg.get("start", 0.0))
   31:             end = float(seg.get("end", 0.0))
   32:         except Exception:
   33:             continue
   34:         if end <= start:
   35:             continue
   36:         processed.append((_segment_score(seg), idx, start, end, seg))
   37: 
   38:     if not processed:
   39:         return []
   40: 
   41:     highest_end = max(item[3] for item in processed)
   42:     if not video_duration or video_duration < highest_end:
   43:         video_duration = max(highest_end, video_duration or 0.0)
   44: 
   45:     if prefer_score:
   46:         ordering = sorted(processed, key=lambda x: (x[0], -x[2]), reverse=True)
   47:     else:
   48:         ordering = sorted(processed, key=lambda x: x[2])
   49: 
   50:     selected: List[dict] = []
   51:     used_indices = set()
   52: 
   53:     def overlaps(range_a, range_b):
   54:         inter = min(range_a[1], range_b[1]) - max(range_a[0], range_b[0])
   55:         if inter <= 0:
   56:             return 0.0
   57:         union = max(range_a[1], range_b[1]) - min(range_a[0], range_b[0])
   58:         return inter / union if union > 0 else 0.0
   59: 
   60:     def adjust_window(start: float, end: float) -> Tuple[float, float]:
   61:         length = end - start
   62:         target = target_sec
   63:         if length > max_sec:
   64:             target = max_sec
   65:         elif length < min_sec:
   66:             target = target_sec
   67:         else:
   68:             target = max(min(length, max_sec), min_sec)
   69:         center = (start + end) / 2.0
   70:         start_new = center - target / 2.0
   71:         if start_new < 0.0:
   72:             start_new = 0.0
   73:         end_new = start_new + target
   74:         if end_new > video_duration:
   75:             end_new = video_duration
   76:             start_new = max(0.0, end_new - target)
   77:         if end_new - start_new < min_sec:
   78:             if end_new == video_duration:
   79:                 start_new = max(0.0, video_duration - min_sec)
   80:                 end_new = video_duration
   81:             else:
   82:                 end_new = min(video_duration, start_new + min_sec)
   83:         return start_new, end_new
   84: 
   85:     def add_candidate(score: float, idx_seg: int, start: float, end: float, origin: dict) -> bool:
   86:         start_adj, end_adj = adjust_window(start, end)
   87:         candidate_range = (start_adj, end_adj)
   88:         for existing in selected:
   89:             if overlaps(candidate_range, (existing['start'], existing['end'])) > 0.35:
   90:                 return False
   91:         seg_copy = dict(origin)
   92:         seg_copy['start'] = float(start_adj)
   93:         seg_copy['end'] = float(end_adj)
   94:         seg_copy['score'] = float(score)
   95:         seg_copy['_source_index'] = idx_seg
   96:         selected.append(seg_copy)
   97:         used_indices.add(idx_seg)
   98:         return True
   99: 
  100:     for score, idx_seg, start, end, seg in ordering:
  101:         if desired_count > 0 and len(selected) >= desired_count:
  102:             break
  103:         add_candidate(score, idx_seg, start, end, seg)
  104: 
  105:     if desired_count > 0 and len(selected) < desired_count:
  106:         remaining = [item for item in sorted(processed, key=lambda x: x[2]) if item[1] not in used_indices]
  107:         for score, idx_seg, start, end, seg in remaining:
  108:             if desired_count > 0 and len(selected) >= desired_count:
  109:                 break
  110:             if not add_candidate(score, idx_seg, start, end, seg):
  111:                 start_adj, end_adj = adjust_window(start, end)
  112:                 seg_copy = dict(seg)
  113:                 seg_copy['start'] = float(start_adj)
  114:                 seg_copy['end'] = float(end_adj)
  115:                 seg_copy['score'] = float(score)
  116:                 seg_copy['_source_index'] = idx_seg
  117:                 selected.append(seg_copy)
  118: 
  119:     if desired_count > 0 and len(selected) > desired_count:
  120:         selected = sorted(selected, key=lambda x: x.get('score', 0.0), reverse=True)[:desired_count]
  121: 
  122:     selected.sort(key=lambda x: float(x.get('start', 0.0)))
  123:     for seg in selected:
  124:         seg.pop('_source_index', None)
  125:     return selected
  126: 
  127: 
  128: import os
  129: import json
  130: import threading
  131: import shutil
  132: import importlib
  133: import logging
  134: import pickle
  135: import subprocess
  136: from pathlib import Path
  137: import re
  138: try:
  139:     import faiss
  140:     FAISS_AVAILABLE = True
  141: except ImportError:
  142:     FAISS_AVAILABLE = False
  143:     print("faiss æ¨¡å—æœªå®‰è£…ï¼Œå°†è·³è¿‡ç›¸å…³å†…å®¹ç´¢å¼•åŠŸèƒ½")
  144: try:
  145:     from PyQt5.QtCore import QThread, pyqtSignal
  146:     PYTQT5_AVAILABLE = True
  147: except ImportError:
  148:     PYTQT5_AVAILABLE = False
  149:     print("PyQt5 æ¨¡å—æœªå®‰è£…ï¼Œå°†è·³è¿‡ç›¸å…³åŠŸèƒ½")
  150: 
  151: from acfv import config
  152: from acfv.utils import safe_slug
  153: from acfv.runtime.storage import processing_path, settings_path
  154: import sys
  155: 
  156: 
  157: def _sanitize_component(text: str) -> str:
  158:     """Sanitize and shorten a filename component for filesystem usage."""
  159:     return safe_slug(text, max_length=80)
  160: 
  161: # æ¡ä»¶å¯¼å…¥å„ä¸ªæ¨¡å—
  162: try:
  163:     from acfv.processing.extract_chat import extract_chat
  164:     EXTRACT_CHAT_AVAILABLE = True
  165: except ImportError as e:
  166:     EXTRACT_CHAT_AVAILABLE = False
  167:     print(f"extract_chat æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
  168: 
  169: try:
  170:     from acfv.processing.transcribe_audio import process_audio_segments
  171:     TRANSCRIBE_AUDIO_AVAILABLE = True
  172: except ImportError as e:
  173:     TRANSCRIBE_AUDIO_AVAILABLE = False
  174:     print(f"transcribe_audio æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
  175: 
  176: # å°†analyze_dataçš„å¯¼å…¥ç§»åˆ°å‡½æ•°å†…éƒ¨ï¼Œé¿å…å¾ªç¯å¯¼å…¥
  177: ANALYZE_DATA_AVAILABLE = True
  178: 
  179: try:
  180:     from utils import filter_meaningless_content, build_content_index
  181:     UTILS_AVAILABLE = True
  182: except ImportError as e:
  183:     UTILS_AVAILABLE = False
  184:     print(f"utils æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
  185: 
  186: try:
  187:     from acfv.processing.clip_video import clip_video
  188:     CLIP_VIDEO_AVAILABLE = True
  189: except ImportError as e:
  190:     CLIP_VIDEO_AVAILABLE = False
  191:     print(f"clip_video æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
  192: 
  193: try:
  194:     from acfv.processing.video_emotion_infer import run as infer_emotion
  195:     VIDEO_EMOTION_AVAILABLE = True
  196: except ImportError as e:
  197:     VIDEO_EMOTION_AVAILABLE = False
  198:     print(f"video_emotion_infer æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
  199: 
  200: # é…ç½®æ—¥å¿—ç³»ç»Ÿ
  201: import logging.handlers
  202: import os
  203: 
  204: # åˆ›å»ºlogsç›®å½•
  205: os.makedirs("logs", exist_ok=True)
  206: 
  207: # é…ç½®æ—¥å¿—å¤„ç†å™¨
  208: logger = logging.getLogger()
  209: logger.setLevel(logging.INFO)
  210: 
  211: # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
  212: for handler in logger.handlers[:]:
  213:     logger.removeHandler(handler)
  214: 
  215: # æ§åˆ¶å°å¤„ç†å™¨
  216: console_handler = logging.StreamHandler()
  217: console_handler.setLevel(logging.INFO)
  218: console_formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
  219: console_handler.setFormatter(console_formatter)
  220: logger.addHandler(console_handler)
  221: 
  222: # æ–‡ä»¶å¤„ç†å™¨ - processing.log
  223: file_handler = logging.handlers.RotatingFileHandler(
  224:     "processing.log", 
  225:     maxBytes=10*1024*1024,  # 10MB
  226:     backupCount=5,
  227:     encoding='utf-8'
  228: )
  229: file_handler.setLevel(logging.INFO)
  230: file_formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
  231: file_handler.setFormatter(file_formatter)
  232: logger.addHandler(file_handler)
  233: 
  234: # è¯¦ç»†æ—¥å¿—æ–‡ä»¶ - video_processor.log
  235: detailed_handler = logging.handlers.RotatingFileHandler(
  236:     "logs/video_processor.log", 
  237:     maxBytes=10*1024*1024,  # 10MB
  238:     backupCount=5,
  239:     encoding='utf-8'
  240: )
  241: detailed_handler.setLevel(logging.DEBUG)
  242: detailed_formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
  243: detailed_handler.setFormatter(detailed_formatter)
  244: logger.addHandler(detailed_handler)
  245: 
  246: def log_info(message):
  247:     """è®°å½•ä¿¡æ¯æ—¥å¿—"""
  248:     logging.info(message)
  249:     # ç¡®ä¿æ—¥å¿—ç«‹å³å†™å…¥æ–‡ä»¶
  250:     for handler in logging.getLogger().handlers:
  251:         if isinstance(handler, logging.handlers.RotatingFileHandler):
  252:             handler.flush()
  253: 
  254: 
  255: def log_error(message):
  256:     """è®°å½•é”™è¯¯æ—¥å¿—"""
  257:     logging.error(message)
  258:     # ç¡®ä¿æ—¥å¿—ç«‹å³å†™å…¥æ–‡ä»¶
  259:     for handler in logging.getLogger().handlers:
  260:         if isinstance(handler, logging.handlers.RotatingFileHandler):
  261:             handler.flush()
  262: 
  263: def log_warning(message):
  264:     """è®°å½•è­¦å‘Šæ—¥å¿—"""
  265:     logging.warning(message)
  266:     # ç¡®ä¿æ—¥å¿—ç«‹å³å†™å…¥æ–‡ä»¶
  267:     for handler in logging.getLogger().handlers:
  268:         if isinstance(handler, logging.handlers.RotatingFileHandler):
  269:             handler.flush()
  270: 
  271: 
  272: class ConfigManager:
  273:     def __init__(self, config_file=None):
  274:         self.config_file = config_file or str(settings_path("config.json"))
  275:         self.cfg = {
  276:             "VIDEO_FILE": "",
  277:             "CHAT_FILE": "",
  278:             "CHAT_OUTPUT": str(processing_path("chat_with_emotes.json")),
  279:             "TRANSCRIPTION_OUTPUT": str(processing_path("transcription.json")),
  280:             "ANALYSIS_OUTPUT": str(processing_path("high_interest_segments.json")),
  281:             "OUTPUT_CLIPS_DIR": str(processing_path("output_clips")),
  282:             "CLIPS_BASE_DIR": "clips",
  283:             "MAX_CLIP_COUNT": 10,
  284:             "WHISPER_MODEL": "large",
  285:             "LLM_DEVICE": 0,
  286:             "CHAT_DENSITY_WEIGHT": 0.3,
  287:             "CHAT_SENTIMENT_WEIGHT": 0.4,
  288:             "VIDEO_EMOTION_WEIGHT": 0.3,
  289:             "AUDIO_TARGET_BONUS": 1.0,
  290:             "TEXT_TARGET_BONUS": 1.0,
  291:             "INTEREST_SCORE_THRESHOLD": 0.5,
  292:             "LOCAL_EMOTION_MODEL_PATH": "",
  293:             "VIDEO_EMOTION_MODEL_PATH": "",
  294:             "VIDEO_EMOTION_SEGMENT_LENGTH": 4.0,
  295:             "ENABLE_VIDEO_EMOTION": False,
  296:             "twitch_client_id": "",
  297:             "twitch_oauth_token": "",
  298:             "twitch_username": "",
  299:             "twitch_download_folder": "./data/twitch",
  300:         }
  301:         self.load()
  302: 
  303:     def load(self):
  304:         if not os.path.isfile(self.config_file):
  305:             self.save()
  306:             return
  307:         try:
  308:             with open(self.config_file, "r", encoding="utf-8") as f:
  309:                 data = json.load(f)
  310:             self.cfg.update(data)
  311:         except Exception:
  312:             pass
  313: 
  314:     def save(self):
  315:         try:
  316:             with open(self.config_file, "w", encoding="utf-8") as f:
  317:                 json.dump(self.cfg, f, ensure_ascii=False, indent=4)
  318:         except Exception:
  319:             pass
  320: 
  321:     def get(self, key):
  322:         return self.cfg.get(key)
  323: 
  324:     def set(self, key, value):
  325:         self.cfg[key] = value
  326: 
  327: 
  328: if PYTQT5_AVAILABLE:
  329:     class Worker(QThread):
  330:         finished = pyqtSignal(object)
  331:         error = pyqtSignal(str)
  332:         progress_update = pyqtSignal(str)
  333:         progress_percent = pyqtSignal(int)
  334: 
  335:         def __init__(self, func, *args, parent=None, **kwargs):
  336:             super().__init__(parent)
  337:             self.func = func
  338:             self.args = args
  339:             self.kwargs = kwargs
  340:             self._should_stop = False
  341: else:
  342:     class Worker:
  343:         def __init__(self, func, *args, parent=None, **kwargs):
  344:             self.func = func
  345:             self.args = args
  346:             self.kwargs = kwargs
  347:             self._should_stop = False
  348: 
  349:         def run(self):
  350:             try:
  351:                 # æ£€æŸ¥çº¿ç¨‹æ˜¯å¦åº”è¯¥åœæ­¢
  352:                 if self._should_stop:
  353:                     return
  354:                     
  355:                 import inspect
  356:                 sig = inspect.signature(self.func)
  357:                 if 'progress_callback' in sig.parameters:
  358:                     self.kwargs['progress_callback'] = self.emit_progress
  359:                 res = self.func(*self.args, **self.kwargs)
  360:                 
  361:                 # å†æ¬¡æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
  362:                 if not self._should_stop:
  363:                     self.finished.emit(res)
  364:             except Exception as e:
  365:                 if not self._should_stop:
  366:                     self.error.emit(str(e))
  367: 
  368:         def emit_progress(self, stage, current, total, message=""):
  369:             if self._should_stop:
  370:                 return
  371:                 
  372:             if total > 0:
  373:                 percent = int((current / total) * 100)
  374:                 self.progress_percent.emit(percent)
  375:             progress_text = f"[{stage}] {current}/{total} - {message}"
  376:             self.progress_update.emit(progress_text)
  377:         
  378:         def stop(self):
  379:             """åœæ­¢çº¿ç¨‹"""
  380:             self._should_stop = True
  381:             self.quit()
  382:             if not self.wait(2000):  # ç­‰å¾…2ç§’
  383:                 self.terminate()
  384:                 self.wait(1000)
  385: 
  386: 
  387: def run_pipeline(cfg_manager, video, chat, has_chat, chat_output, transcription_output,
  388:                  video_emotion_output, analysis_output, output_clips_dir,
  389:                  video_clips_dir, progress_callback=None):
  390:     """è§†é¢‘å¤„ç†ç®¡é“ä¸»å‡½æ•° - æ”¯æŒä¸­æ–­åœæ­¢"""
  391:     from concurrent.futures import ThreadPoolExecutor, as_completed
  392:     
  393:     # å…¨å±€åœæ­¢æ ‡å¿—æ£€æŸ¥å‡½æ•°
  394:     def should_stop():
  395:         """æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢å¤„ç†"""
  396:         try:
  397:             stop_flag_file = os.path.join("processing", "stop_flag.txt")
  398:             return os.path.exists(stop_flag_file)
  399:         except Exception:
  400:             return False
  401:     
  402:     def cleanup_stop_flag():
  403:         """æ¸…ç†åœæ­¢æ ‡å¿—æ–‡ä»¶"""
  404:         try:
  405:             stop_flag_file = os.path.join("processing", "stop_flag.txt")
  406:             if os.path.exists(stop_flag_file):
  407:                 os.remove(stop_flag_file)
  408:         except Exception:
  409:             pass
  410:     
  411:     # æ¸…ç†ä¹‹å‰çš„åœæ­¢æ ‡å¿—
  412:     cleanup_stop_flag()
  413:     
  414:     def emit_progress(stage, current, total, message=""):
  415:         # æ£€æŸ¥åœæ­¢æ ‡å¿—
  416:         if should_stop():
  417:             logging.info(f"æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œç»ˆæ­¢å¤„ç†: {stage}")
  418:             raise InterruptedError("ç”¨æˆ·ä¸­æ–­å¤„ç†")
  419:             
  420:         if progress_callback:
  421:             progress_callback(stage, current, total, message)
  422:         
  423:         # æ›´æ–°è¿›åº¦æ–‡ä»¶ï¼ŒåŒ…å«æ›´è¯¦ç»†çš„ä¿¡æ¯
  424:         try:
  425:             import time
  426:             import json
  427:             
  428:             # è®¡ç®—æ›´å‡†ç¡®çš„è¿›åº¦ç™¾åˆ†æ¯”
  429:             stage_weights = {
  430:                 "å¹¶è¡Œæ•°æ®å‡†å¤‡": 0.4,
  431:                 "è§†é¢‘æƒ…ç»ªåˆ†æ": 0.15,
  432:                 "æ•°æ®å‡†å¤‡": 0.05,
  433:                 "æ™ºèƒ½åˆ†æ": 0.2,
  434:                 "å¹¶è¡Œè§†é¢‘åˆ‡ç‰‡": 0.15,
  435:                 "å®Œæˆ": 0.05
  436:             }
  437:             
  438:             # è·å–å½“å‰é˜¶æ®µæƒé‡
  439:             stage_weight = stage_weights.get(stage, 0.1)
  440:             
  441:             # è®¡ç®—é˜¶æ®µå†…è¿›åº¦
  442:             stage_progress = (current / total) if total > 0 else 0
  443:             
  444:             # è®¡ç®—ç´¯ç§¯è¿›åº¦ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®ä½ çš„å®é™…æƒ…å†µè°ƒæ•´ï¼‰
  445:             base_progress = sum(stage_weights.get(s, 0) for s in stage_weights.keys() 
  446:                                if s != stage and "å‰é¢å·²å®Œæˆçš„é˜¶æ®µ")
  447:             current_stage_contribution = stage_weight * stage_progress
  448:             total_percentage = (base_progress + current_stage_contribution) * 100
  449:             
  450:             progress_data = {
  451:                 "stage": stage,
  452:                 "current": current,
  453:                 "total": total,
  454:                 "message": message,
  455:                 "timestamp": time.time(),
  456:                 "percentage": min(100, total_percentage),
  457:                 "estimated_remaining_minutes": _calculate_smart_remaining_time(total_percentage)
  458:             }
  459:             
  460:             progress_file = processing_path("analysis_progress.json")
  461:             progress_file.parent.mkdir(parents=True, exist_ok=True)
  462:             with progress_file.open('w', encoding='utf-8') as f:
  463:                 json.dump(progress_data, f, ensure_ascii=False, indent=2)
  464:         except InterruptedError:
  465:             raise  # é‡æ–°æŠ›å‡ºä¸­æ–­å¼‚å¸¸
  466:         except Exception as e:
  467:             logging.error(f"æ›´æ–°è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
  468:     
  469:     def _calculate_smart_remaining_time(percentage):
  470:         """æ™ºèƒ½è®¡ç®—å‰©ä½™æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨æ™ºèƒ½é¢„æµ‹å™¨ï¼Œå¤±è´¥åˆ™æŒ‰ç™¾åˆ†æ¯”ä¼°ç®—"""
  471:         try:
  472:             if 'smart_predictor' in locals() and smart_predictor:
  473:                 remain_str = smart_predictor.get_estimated_remaining_time()
  474:                 if remain_str:
  475:                     if "å³å°†å®Œæˆ" in remain_str:
  476:                         return 1
  477:                     if "å°æ—¶" in remain_str:
  478:                         try:
  479:                             # å½¢å¦‚ "2å°æ—¶15åˆ†é’Ÿ"
  480:                             parts = remain_str.replace("å°æ—¶", ":").replace("åˆ†é’Ÿ", "").split(":")
  481:                             hours = int(parts[0])
  482:                             minutes = int(parts[1]) if len(parts) > 1 and parts[1] else 0
  483:                             return max(1, hours * 60 + minutes)
  484:                         except Exception:
  485:                             pass
  486:                     if "åˆ†é’Ÿ" in remain_str:
  487:                         try:
  488:                             minutes = int(remain_str.replace("åˆ†é’Ÿ", "").strip())
  489:                             return max(1, minutes)
  490:                         except Exception:
  491:                             pass
  492:                     if "ç§’" in remain_str:
  493:                         try:
  494:                             secs = int(remain_str.replace("ç§’", "").strip())
  495:                             return max(1, (secs + 59) // 60)
  496:                         except Exception:
  497:                             pass
  498:         except Exception:
  499:             pass
  500: 
  501:         if percentage <= 0:
  502:             return 30
  503:         if percentage >= 100:
  504:             return 0
  505:         remaining_percent = 100 - percentage
  506:         return max(1, int(remaining_percent / 8))
  507:     
  508:     # å¯åŠ¨æ™ºèƒ½è¿›åº¦é¢„æµ‹ (å¯é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®ç¦ç”¨)
  509:     predicted_time_info = None
  510:     disable_smart = os.environ.get('DISABLE_SMART_PROGRESS', '0') == '1' or \
  511:         str(cfg_manager.get('DISABLE_SMART_PROGRESS') or '').lower() in ('1','true','yes')
  512:     smart_predictor = None
  513:     if disable_smart:
  514:         log_info("âš™ï¸ å·²æ ¹æ®é…ç½®/ç¯å¢ƒç¦ç”¨æ™ºèƒ½è¿›åº¦é¢„æµ‹ (DISABLE_SMART_PROGRESS=1)")
  515:     try:
  516:         if not disable_smart:
  517:             from .smart_progress_predictor import SmartProgressPredictor
  518:             smart_predictor = SmartProgressPredictor()
  519:         
  520:         # é¢„æµ‹è§†é¢‘å¤„ç†æ—¶é—´
  521:         if os.path.exists(video):
  522:             cmd = ["ffprobe", "-v", "quiet", "-show_entries", "format=duration", "-of", "csv=p=0", video]
  523:             result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore')
  524:             if result.returncode == 0:
  525:                 duration = float(result.stdout.strip())
  526:                 size_mb = os.path.getsize(video) / (1024 * 1024)
  527:                 predicted_time = smart_predictor.predict_video_processing_time(duration, size_mb)
  528:                 predicted_time_info = predicted_time
  529:                 log_info(f"ğŸ¯ é¢„æµ‹æ€»å¤„ç†æ—¶é—´: {predicted_time}")
  530:                 # å¼€å§‹æ–°çš„é¢„æµ‹ä¼šè¯ï¼Œè®°å½•æ•´ä½“ç”¨æ—¶
  531:                 try:
  532:                     smart_predictor.start_session(duration_seconds=duration, size_mb=size_mb, video_path=video)
  533:                 except Exception:
  534:                     pass
  535:                 
  536:                 # é€šè¿‡è¿›åº¦å›è°ƒä¼ é€’é¢„æµ‹æ—¶é—´ä¿¡æ¯
  537:                 if progress_callback:
  538:                     progress_callback("é¢„æµ‹æ—¶é—´", 1, 1, f"é¢„è®¡å¤„ç†æ—¶é—´: {predicted_time}")
  539:         
  540:         # å¯åŠ¨å„ä¸ªå¤„ç†é˜¶æ®µ
  541:         if smart_predictor:
  542:             smart_predictor.start_stage("éŸ³é¢‘æå–", 1)
  543:             smart_predictor.start_stage("è¯´è¯äººåˆ†ç¦»", 1)
  544:             smart_predictor.start_stage("éŸ³é¢‘è½¬å½•", 10)
  545:             smart_predictor.start_stage("æƒ…æ„Ÿåˆ†æ", 1)
  546:             smart_predictor.start_stage("åˆ‡ç‰‡ç”Ÿæˆ", 1)
  547:             log_info("âœ… æ™ºèƒ½è¿›åº¦é¢„æµ‹å¯åŠ¨æˆåŠŸ")
  548:         
  549:     except ImportError as e:
  550:         log_info("âš ï¸ æ™ºèƒ½è¿›åº¦é¢„æµ‹æ¨¡å—åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–é¢„æµ‹å™¨")
  551:         # ä½¿ç”¨ç®€åŒ–ç‰ˆé¢„æµ‹å™¨ä½œä¸ºfallback
  552:         try:
  553:             from .smart_progress_predictor import SimplePredictor
  554:             smart_predictor = SimplePredictor() if not disable_smart else None
  555:             
  556:             # ç®€å•é¢„æµ‹å¤„ç†æ—¶é—´
  557:             if os.path.exists(video):
  558:                 try:
  559:                     cmd = ["ffprobe", "-v", "quiet", "-show_entries", "format=duration", "-of", "csv=p=0", video]
  560:                     result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', timeout=10)
  561:                     if result.returncode == 0:
  562:                         duration = float(result.stdout.strip())
  563:                         size_mb = os.path.getsize(video) / (1024 * 1024)
  564:                         predicted_time = smart_predictor.predict_video_processing_time(duration, size_mb)
  565:                         predicted_time_info = predicted_time
  566:                         log_info(f"ğŸ¯ é¢„æµ‹æ€»å¤„ç†æ—¶é—´(ç®€åŒ–): {predicted_time}")
  567:                         
  568:                         # é€šè¿‡è¿›åº¦å›è°ƒä¼ é€’é¢„æµ‹æ—¶é—´ä¿¡æ¯
  569:                         if progress_callback:
  570:                             progress_callback("é¢„æµ‹æ—¶é—´", 1, 1, f"é¢„è®¡å¤„ç†æ—¶é—´: {predicted_time}")
  571:                 except Exception:
  572:                     pass
  573:                     
  574:             if smart_predictor:
  575:                 log_info("âœ… ä½¿ç”¨ç®€åŒ–è¿›åº¦é¢„æµ‹å™¨")
  576:         except ImportError:
  577:             # å¦‚æœè¿SimplePredictoréƒ½æ— æ³•å¯¼å…¥ï¼Œåˆ›å»ºä¸€ä¸ªæœ€åŸºç¡€çš„æ›¿ä»£
  578:             class BasicPredictor:
  579:                 def predict_video_processing_time(self, duration, size_mb):
  580:                     return f"{int(duration/30)}-{int(duration/15)}åˆ†é’Ÿ"
  581:                 def start_stage(self, stage_name, weight): pass
  582:                 def update_progress(self, stage_name, progress): pass
  583:                 def complete_stage(self, stage_name): pass
  584:                 def finish_stage(self, stage_name): pass
  585:             smart_predictor = BasicPredictor()
  586:             log_info("âœ… ä½¿ç”¨åŸºç¡€è¿›åº¦é¢„æµ‹å™¨")
  587:         
  588:     except Exception as e:
  589:         log_info(f"âš ï¸ æ™ºèƒ½è¿›åº¦é¢„æµ‹å¯åŠ¨å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€é¢„æµ‹å™¨: {e}")
  590:         # åˆ›å»ºåŸºç¡€é¢„æµ‹å™¨
  591:         if not disable_smart:
  592:             class BasicPredictor:
  593:                 def predict_video_processing_time(self, duration, size_mb):
  594:                     return f"{int(duration/30)}-{int(duration/15)}åˆ†é’Ÿ"
  595:                 def start_stage(self, stage_name, weight): pass
  596:                 def update_progress(self, stage_name, progress): pass
  597:                 def complete_stage(self, stage_name): pass
  598:                 def finish_stage(self, stage_name): pass
  599:             smart_predictor = BasicPredictor()
  600: 
  601:     enable_video_emotion = cfg_manager.get("ENABLE_VIDEO_EMOTION")
  602:     log_info(f"[pipeline] è§†é¢‘æƒ…ç»ªåˆ†æå¼€å…³çŠ¶æ€: {enable_video_emotion}")
  603: 
  604:     has_transcription = os.path.exists(transcription_output) and os.path.getsize(transcription_output) > 10
  605:     has_chat_json = has_chat and os.path.exists(chat_output) and os.path.getsize(chat_output) > 10
  606:     has_video_emotion = enable_video_emotion and os.path.exists(video_emotion_output) and os.path.getsize(video_emotion_output) > 10
  607: 
  608:     # æ£€æŸ¥æ˜¯å¦å·²æœ‰å®Œæ•´å¤„ç†å†…å®¹
  609:     has_analysis = os.path.exists(analysis_output) and os.path.getsize(analysis_output) > 10
  610:     
  611:     # æ£€æŸ¥clipsç›®å½•æ˜¯å¦å­˜åœ¨ä¸”æœ‰å†…å®¹ï¼ˆä½¿ç”¨è¿è¡Œçº§è¾“å‡ºç›®å½•ï¼‰
  612:     clips_dir_exists = os.path.exists(output_clips_dir)
  613:     existing_clips = []
  614:     if clips_dir_exists:
  615:         try:
  616:             for file in os.listdir(output_clips_dir):
  617:                 if file.lower().endswith('.mp4'):
  618:                     clip_path = os.path.join(output_clips_dir, file)
  619:                     if os.path.isfile(clip_path) and os.path.getsize(clip_path) > 1024:  # å¤§äº1KB
  620:                         existing_clips.append(file)
  621:         except Exception as e:
  622:             log_error(f"[pipeline] æ£€æŸ¥åˆ‡ç‰‡ç›®å½•å¤±è´¥: {e}")
  623:     
  624:     # æ£€æŸ¥dataç›®å½•æ˜¯å¦å­˜åœ¨ä¸”æœ‰å†…å®¹ï¼ˆåŸºäºè½¬å½•è¾“å‡ºæ‰€åœ¨ç›®å½•ï¼‰
  625:     data_dir = os.path.dirname(transcription_output)
  626:     data_dir_exists = os.path.exists(data_dir)
  627:     has_data_files = False
  628:     if data_dir_exists:
  629:         try:
  630:             data_files = os.listdir(data_dir)
  631:             has_data_files = len(data_files) > 0
  632:             log_info(f"[pipeline] dataç›®å½•åŒ…å« {len(data_files)} ä¸ªæ–‡ä»¶")
  633:         except Exception as e:
  634:             log_error(f"[pipeline] æ£€æŸ¥dataç›®å½•å¤±è´¥: {e}")
  635:     
  636:     # æ£€æŸ¥æ˜¯å¦å·²æœ‰å®Œæ•´å¤„ç†å†…å®¹
  637:     has_complete_processing = (
  638:         has_transcription and 
  639:         has_analysis and 
  640:         clips_dir_exists and 
  641:         len(existing_clips) > 0
  642:     )
  643:     
  644:     # æ·»åŠ è°ƒè¯•ä¿¡æ¯
  645:     log_info(f"[DEBUG] å®Œæ•´å¤„ç†æ£€æŸ¥:")
  646:     log_info(f"[DEBUG] - has_transcription: {has_transcription} ({transcription_output})")
  647:     log_info(f"[DEBUG] - has_analysis: {has_analysis} ({analysis_output})")
  648:     log_info(f"[DEBUG] - clips_dir_exists: {clips_dir_exists} ({output_clips_dir})")
  649:     log_info(f"[DEBUG] - existing_clips: {len(existing_clips)} ä¸ª")
  650:     log_info(f"[DEBUG] - has_complete_processing: {has_complete_processing}")
  651:     
  652:     # å¦‚æœå·²æœ‰å®Œæ•´å¤„ç†å†…å®¹ï¼Œç›´æ¥è¿”å›
  653:     if has_complete_processing:
  654:         log_info(f"[pipeline] æ£€æµ‹åˆ°å®Œæ•´å¤„ç†å†…å®¹ï¼Œè·³è¿‡å¤„ç†")
  655:         log_info(f"[pipeline] è½¬å½•æ–‡ä»¶: {'âœ…' if has_transcription else 'âŒ'}")
  656:         log_info(f"[pipeline] åˆ†ææ–‡ä»¶: {'âœ…' if has_analysis else 'âŒ'}")
  657:         log_info(f"[pipeline] åˆ‡ç‰‡ç›®å½•: {'âœ…' if clips_dir_exists else 'âŒ'}")
  658:         log_info(f"[pipeline] åˆ‡ç‰‡æ–‡ä»¶: {len(existing_clips)} ä¸ª")
  659:         log_info(f"[pipeline] dataç›®å½•: {'âœ…' if data_dir_exists else 'âŒ'}")
  660:         log_info(f"[pipeline] dataæ–‡ä»¶: {'âœ…' if has_data_files else 'âŒ'}")
  661:         
  662:         # æ›´æ–°UIè¿›åº¦æ˜¾ç¤º
  663:         emit_progress("æ£€æŸ¥ç°æœ‰å†…å®¹", 1, 6, "æ£€æµ‹åˆ°å®Œæ•´å¤„ç†å†…å®¹...")
  664:         emit_progress("è·³è¿‡è½¬å½•", 2, 6, "è½¬å½•æ–‡ä»¶å·²å­˜åœ¨")
  665:         emit_progress("è·³è¿‡åˆ†æ", 3, 6, "åˆ†ææ–‡ä»¶å·²å­˜åœ¨")
  666:         emit_progress("è·³è¿‡åˆ‡ç‰‡", 4, 6, f"å·²æœ‰{len(existing_clips)}ä¸ªåˆ‡ç‰‡æ–‡ä»¶")
  667:         emit_progress("å®Œæˆ", 6, 6, f"ä½¿ç”¨ç°æœ‰å¤„ç†ç»“æœï¼Œå·²æœ‰{len(existing_clips)}ä¸ªåˆ‡ç‰‡")
  668:         
  669:         # æ›´æ–°æ™ºèƒ½è¿›åº¦é¢„æµ‹ - ç«‹å³å®Œæˆæ‰€æœ‰é˜¶æ®µ
  670:         if smart_predictor:
  671:             smart_predictor.finish_stage("éŸ³é¢‘æå–")
  672:             smart_predictor.finish_stage("è¯´è¯äººåˆ†ç¦»")
  673:             smart_predictor.finish_stage("éŸ³é¢‘è½¬å½•")
  674:             smart_predictor.finish_stage("æƒ…æ„Ÿåˆ†æ")
  675:             smart_predictor.finish_stage("åˆ‡ç‰‡ç”Ÿæˆ")
  676:             # å¼ºåˆ¶æ›´æ–°è¿›åº¦æ˜¾ç¤º
  677:             emit_progress("æ£€æŸ¥", 1, 1, "âœ… æ£€æµ‹åˆ°å·²æœ‰å¤„ç†å†…å®¹ï¼Œè·³è¿‡æ‰€æœ‰æ­¥éª¤")
  678:         
  679:         return output_clips_dir, existing_clips, has_chat
  680: 
  681:     total_steps = 6
  682:     current_step = 0
  683: 
  684:     # step 1-3: å¹¶è¡Œæ•°æ®å‡†å¤‡
  685:     current_step += 1
  686:     emit_progress("å¹¶è¡Œæ•°æ®å‡†å¤‡", current_step, total_steps, "å¹¶è¡Œå¤„ç†èŠå¤©æå–ã€è½¬å½•ã€æƒ…ç»ªåˆ†æå’Œä¸»æ’­åˆ†ç¦»...")
  687:     
  688:     # æ·»åŠ åœæ­¢æ£€æŸ¥
  689:     if should_stop():
  690:         logging.info("å¤„ç†è¢«ä¸­æ–­ - å¹¶è¡Œæ•°æ®å‡†å¤‡é˜¶æ®µ")
  691:         cleanup_stop_flag()
  692:         return None, None, False
  693:     
  694:     # æ£€æŸ¥å¼ºåˆ¶é‡è½¬å½•
  695:     force_retranscription_value = cfg_manager.get("FORCE_RETRANSCRIPTION", False)
  696:     if isinstance(force_retranscription_value, str):
  697:         force_retranscription = force_retranscription_value
  698:     else:
  699:         force_retranscription = bool(force_retranscription_value)
  700:     
  701:     # æ£€æŸ¥ä¸»æ’­åˆ†ç¦»
  702:     enable_speaker_separation_value = cfg_manager.get("ENABLE_SPEAKER_SEPARATION", False)
  703:     if isinstance(enable_speaker_separation_value, str):
  704:         enable_speaker_separation = enable_speaker_separation_value
  705:     else:
  706:         enable_speaker_separation = bool(enable_speaker_separation_value)
  707:     
  708:     # å¹¶è¡Œæ‰§è¡Œæ•°æ®å‡†å¤‡ä»»åŠ¡
  709:     host_audio_path = None
  710:     with ThreadPoolExecutor(max_workers=4) as executor:
  711:         futures = {}
  712:         
  713:         # åœæ­¢æ£€æŸ¥
  714:         if should_stop():
  715:             logging.info("å¤„ç†è¢«ä¸­æ–­ - æ•°æ®å‡†å¤‡é˜¶æ®µ")
  716:             cleanup_stop_flag()
  717:             return None, None, False
  718:         
  719:         # èŠå¤©æå–ä»»åŠ¡
  720:         if has_chat and not has_chat_json:
  721:             log_info(f"[pipeline] å¹¶è¡Œæå–èŠå¤©: {chat} -> {chat_output}")
  722:             futures['chat'] = executor.submit(extract_chat, chat, chat_output)
  723:         
  724:         # éŸ³é¢‘æå–ä»»åŠ¡ï¼ˆä¼˜å…ˆæ‰§è¡Œï¼Œç¡®ä¿å®Œæ•´æå–ï¼‰
  725:         audio_save_dir = os.path.join(os.path.dirname(transcription_output), "audio")
  726:         # åªåœ¨çœŸæ­£éœ€è¦æ—¶æ‰åˆ›å»ºç›®å½•
  727:         # os.makedirs(audio_save_dir, exist_ok=True)
  728:         audio_save_path = os.path.join(audio_save_dir, "extracted_audio.wav")
  729:         
  730:         if not os.path.exists(audio_save_path):
  731:             # åœæ­¢æ£€æŸ¥
  732:             if should_stop():
  733:                 logging.info("å¤„ç†è¢«ä¸­æ–­ - éŸ³é¢‘æå–å‰")
  734:                 cleanup_stop_flag()
  735:                 return None, None, False
  736:             
  737:             # åœ¨çœŸæ­£éœ€è¦éŸ³é¢‘æå–æ—¶æ‰åˆ›å»ºç›®å½•
  738:             os.makedirs(audio_save_dir, exist_ok=True)
  739:             
  740:             log_info("[pipeline] å¼€å§‹å®Œæ•´éŸ³é¢‘æå–...")
  741:             emit_progress("éŸ³é¢‘æå–", 1, 3, "æ­£åœ¨ä»è§†é¢‘ä¸­æå–å®Œæ•´éŸ³é¢‘...")
  742:             
  743:             try:
  744:                 cmd = [
  745:                     "ffmpeg", "-y",
  746:                     "-hide_banner", "-loglevel", "error", "-nostdin",
  747:                     "-i", video, "-vn", "-acodec", "pcm_s16le",
  748:                     "-ar", "16000", "-ac", "1",
  749:                     "-threads", "0",
  750:                     audio_save_path
  751:                 ]
  752:                 # æ ¹æ®è§†é¢‘æ—¶é•¿åŠ¨æ€è®¡ç®—è¶…æ—¶æ—¶é—´
  753:                 try:
  754:                     probe_cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', video]
  755:                     probe_result = subprocess.run(probe_cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', timeout=30)
  756:                     if probe_result.returncode == 0:
  757:                         import json
  758:                         probe_data = json.loads(probe_result.stdout)
  759:                         video_duration = float(probe_data['format']['duration'])
  760:                         # è¶…æ—¶æ—¶é—´ = è§†é¢‘æ—¶é•¿ * 2 + 300ç§’ç¼“å†²
  761:                         timeout_seconds = min(int(video_duration * 2) + 300, 7200)  # æœ€å¤§2å°æ—¶
  762:                     else:
  763:                         timeout_seconds = 3600  # é»˜è®¤1å°æ—¶
  764:                 except:
  765:                     timeout_seconds = 3600  # é»˜è®¤1å°æ—¶
  766:                 
  767:                 log_info(f"[pipeline] éŸ³é¢‘æå–è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’")
  768:                 result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', timeout=timeout_seconds)
  769:                 
  770:                 # å†æ¬¡åœæ­¢æ£€æŸ¥
  771:                 if should_stop():
  772:                     logging.info("å¤„ç†è¢«ä¸­æ–­ - éŸ³é¢‘æå–å")
  773:                     cleanup_stop_flag()
  774:                     return None, None, False
  775:                 
  776:                 # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆï¼ˆå³ä½¿FFmpegè¢«ä¸­æ–­ï¼Œæ–‡ä»¶å¯èƒ½å·²ç»ç”Ÿæˆï¼‰
  777:                 if os.path.exists(audio_save_path) and os.path.getsize(audio_save_path) > 1024 * 1024:  # å¤§äº1MB
  778:                     file_size_mb = os.path.getsize(audio_save_path) / (1024 * 1024)
  779:                     log_info(f"[pipeline] éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜: {audio_save_path} ({file_size_mb:.1f}MB)")
  780:                     emit_progress("éŸ³é¢‘æå–", 2, 3, f"éŸ³é¢‘æå–å®Œæˆ ({file_size_mb:.1f}MB)")
  781:                 elif result.returncode == 0:
  782:                     file_size_mb = os.path.getsize(audio_save_path) / (1024 * 1024)
  783:                     log_info(f"[pipeline] éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜: {audio_save_path} ({file_size_mb:.1f}MB)")
  784:                     emit_progress("éŸ³é¢‘æå–", 2, 3, f"éŸ³é¢‘æå–å®Œæˆ ({file_size_mb:.1f}MB)")
  785:                 else:
  786:                     log_error(f"[pipeline] éŸ³é¢‘æ–‡ä»¶ä¿å­˜å¤±è´¥: {result.stderr}")
  787:                     emit_progress("éŸ³é¢‘æå–", 3, 3, "éŸ³é¢‘æå–å¤±è´¥")
  788:                     cleanup_stop_flag()
  789:                     return None, None, False
  790:             except subprocess.TimeoutExpired:
  791:                 log_error("[pipeline] éŸ³é¢‘æå–è¶…æ—¶")
  792:                 emit_progress("éŸ³é¢‘æå–", 3, 3, "éŸ³é¢‘æå–è¶…æ—¶")
  793:                 cleanup_stop_flag()
  794:                 return None, None, False
  795:             except InterruptedError:
  796:                 log_info("[pipeline] éŸ³é¢‘æå–è¢«ç”¨æˆ·ä¸­æ–­")
  797:                 cleanup_stop_flag()
  798:                 return None, None, False
  799:             except Exception as e:
  800:                 log_error(f"[pipeline] éŸ³é¢‘æ–‡ä»¶ä¿å­˜å¼‚å¸¸: {e}")
  801:                 cleanup_stop_flag()
  802:                 return None, None, False
  803:                 emit_progress("éŸ³é¢‘æå–", 3, 3, f"éŸ³é¢‘æå–å¼‚å¸¸: {e}")
  804:                 return None, None, False
  805:         else:
  806:             file_size_mb = os.path.getsize(audio_save_path) / (1024 * 1024)
  807:             log_info(f"[pipeline] éŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨: {audio_save_path} ({file_size_mb:.1f}MB)")
  808:             emit_progress("éŸ³é¢‘æå–", 3, 3, f"ä½¿ç”¨ç°æœ‰éŸ³é¢‘æ–‡ä»¶ ({file_size_mb:.1f}MB)")
  809:         
  810:         # è½¬å½•ä»»åŠ¡ï¼ˆä½¿ç”¨æå–çš„éŸ³é¢‘ï¼‰
  811:         if not has_transcription or force_retranscription:
  812:             log_info(f"[pipeline] å¼€å§‹éŸ³é¢‘è½¬å½•: {audio_save_path} -> {transcription_output}")
  813:             whisper_model_name = cfg_manager.get("WHISPER_MODEL", "medium")
  814:             emit_progress("éŸ³é¢‘è½¬å½•", 1, 2, f"ä½¿ç”¨ {whisper_model_name} æ¨¡å‹è¿›è¡Œè½¬å½•...")
  815:             
  816:             futures['transcription'] = executor.submit(
  817:                 process_audio_segments,
  818:                 audio_path=audio_save_path,  # ä½¿ç”¨æå–çš„éŸ³é¢‘æ–‡ä»¶
  819:                 output_file=transcription_output,
  820:                 segment_length=cfg_manager.get("SEGMENT_LENGTH", 300),
  821:                 whisper_model_name=whisper_model_name
  822:             )
  823:         
  824:         # æƒ…ç»ªåˆ†æä»»åŠ¡
  825:         if enable_video_emotion and not has_video_emotion:
  826:             log_info(f"[pipeline] å¹¶è¡Œæƒ…ç»ªåˆ†æ: {video} -> {video_emotion_output}")
  827:             class EmotionArgs:
  828:                 def __init__(self, cfg_manager):
  829:                     self.segment_length = float(cfg_manager.get("VIDEO_EMOTION_SEGMENT_LENGTH") or 4.0)
  830:                     self.model_path = cfg_manager.get("VIDEO_EMOTION_MODEL_PATH") or ""
  831:                     self.device = cfg_manager.get("LLM_DEVICE") or 0
  832:             emotion_args = EmotionArgs(cfg_manager)
  833:             futures['emotion'] = executor.submit(infer_emotion, video, video_emotion_output, emotion_args)
  834:         
  835:         # ä¸»æ’­åˆ†ç¦»ä»»åŠ¡ï¼ˆå¯é€‰ï¼Œå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼‰
  836:         if enable_speaker_separation:
  837:             log_info("[pipeline] å¹¶è¡Œä¸»æ’­éŸ³é¢‘åˆ†ç¦»...")
  838:             try:
  839:                 from acfv.processing.speaker_separation_integration import SpeakerSeparationIntegration
  840:                 separation_output_dir = os.path.join(os.path.dirname(transcription_output), "speaker_separation")
  841:                 speaker_separation = SpeakerSeparationIntegration(cfg_manager)
  842:                 speaker_separation.set_progress_callback(emit_progress)
  843:                 
  844:                 # è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´ï¼Œé¿å…é˜»å¡
  845:                 futures['speaker_separation'] = executor.submit(
  846:                     speaker_separation.process_video_with_speaker_separation,
  847:                     video_path=video,
  848:                     output_dir=separation_output_dir
  849:                 )
  850:             except Exception as e:
  851:                 log_error(f"[pipeline] ä¸»æ’­åˆ†ç¦»ä»»åŠ¡åˆ›å»ºå¤±è´¥: {e}")
  852:                 # ä¸é˜»æ­¢æ•´ä¸ªæµç¨‹ç»§ç»­
  853:                 pass
  854:         
  855:         # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
  856:         for name, future in futures.items():
  857:             try:
  858:                 # ä¸ºè¯´è¯äººåˆ†ç¦»è®¾ç½®å¯é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºéŸ³é¢‘æ–‡ä»¶å¯èƒ½å¾ˆå¤§
  859:                 speaker_timeout = cfg_manager.get("SPEAKER_SEPARATION_TIMEOUT", 1800)
  860:                 timeout = speaker_timeout if name == 'speaker_separation' else 1800  # è¯´è¯äººåˆ†ç¦»å¯é…ç½®ï¼Œå…¶ä»–30åˆ†é’Ÿ
  861:                 result = future.result(timeout=timeout)
  862:                 if name == 'speaker_separation' and result and result.get('host_audio_file'):
  863:                     host_audio_path = result['host_audio_file']
  864:                     log_info(f"[pipeline] ä¸»æ’­éŸ³é¢‘åˆ†ç¦»å®Œæˆ: {host_audio_path}")
  865:                 log_info(f"[pipeline] å¹¶è¡Œä»»åŠ¡ {name} å®Œæˆ")
  866:                 
  867:                 # æ›´æ–°æ™ºèƒ½è¿›åº¦é¢„æµ‹
  868:                 if smart_predictor:
  869:                     if name == 'chat':
  870:                         smart_predictor.finish_stage("éŸ³é¢‘æå–")
  871:                     elif name == 'speaker_separation':
  872:                         smart_predictor.finish_stage("è¯´è¯äººåˆ†ç¦»")
  873:                     elif name == 'transcription':
  874:                         smart_predictor.finish_stage("éŸ³é¢‘è½¬å½•")
  875:                     elif name == 'emotion':
  876:                         smart_predictor.finish_stage("æƒ…æ„Ÿåˆ†æ")
  877:                         
  878:             except Exception as e:
  879:                 log_error(f"[pipeline] å¹¶è¡Œä»»åŠ¡ {name} å¤±è´¥: {e}")
  880:                 # å¯¹äºè¯´è¯äººåˆ†ç¦»å¤±è´¥ï¼Œä¸é˜»æ­¢æ•´ä¸ªæµç¨‹
  881:                 if name == 'speaker_separation':
  882:                     log_warning(f"[pipeline] è¯´è¯äººåˆ†ç¦»å¤±è´¥ï¼Œç»§ç»­å…¶ä»–å¤„ç†: {e}")
  883:                     # æ›´æ–°æ™ºèƒ½è¿›åº¦é¢„æµ‹ï¼Œæ ‡è®°è¯´è¯äººåˆ†ç¦»å®Œæˆï¼ˆå³ä½¿å¤±è´¥ï¼‰
  884:                     if smart_predictor:
  885:                         smart_predictor.finish_stage("è¯´è¯äººåˆ†ç¦»")
  886:                 else:
  887:                     log_error(f"[pipeline] å…³é”®ä»»åŠ¡ {name} å¤±è´¥ï¼Œå¯èƒ½å½±å“åç»­å¤„ç†")
  888:                                     # æ›´æ–°æ™ºèƒ½è¿›åº¦é¢„æµ‹
  889:                 if smart_predictor:
  890:                     if name == 'chat':
  891:                         smart_predictor.finish_stage("éŸ³é¢‘æå–")
  892:                     elif name == 'transcription':
  893:                         smart_predictor.finish_stage("éŸ³é¢‘è½¬å½•")
  894:                     elif name == 'emotion':
  895:                         smart_predictor.finish_stage("æƒ…æ„Ÿåˆ†æ")
  896:                     elif name == 'speaker_separation':
  897:                         smart_predictor.finish_stage("è¯´è¯äººåˆ†ç¦»")
  898:     
  899:     # å¤„ç†æœªå¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡
  900:     if has_chat and not has_chat_json and 'chat' not in futures:
  901:         log_info(f"[pipeline] ä¸²è¡Œæå–èŠå¤©: {chat} -> {chat_output}")
  902:         try:
  903:             extract_chat(chat, chat_output)
  904:         except Exception as e:
  905:             log_error(f"[pipeline] èŠå¤©æå–å¤±è´¥: {e}")
  906:     
  907:     if not has_transcription or force_retranscription:
  908:         if 'transcription' not in futures:
  909:             log_info(f"[pipeline] ä¸²è¡Œè½¬å½•: {video} -> {transcription_output}")
  910:             try:
  911:                 process_audio_segments(
  912:                     audio_path=video,
  913:                     output_file=transcription_output,
  914:                     segment_length=cfg_manager.get("SEGMENT_LENGTH", 300),
  915:                     whisper_model_name="medium"
  916:                 )
  917:                 
  918:                 # åŒæ—¶ä¿å­˜éŸ³é¢‘æ–‡ä»¶åˆ°clipç›®å½•
  919:                 audio_save_dir = os.path.join(os.path.dirname(transcription_output), "audio")
  920:                 # åªåœ¨çœŸæ­£éœ€è¦æ—¶æ‰åˆ›å»ºç›®å½•
  921:                 # os.makedirs(audio_save_dir, exist_ok=True)
  922:                 audio_save_path = os.path.join(audio_save_dir, "extracted_audio.wav")
  923:                 
  924:                 # æå–å¹¶ä¿å­˜éŸ³é¢‘æ–‡ä»¶
  925:                 log_info("[pipeline] ä¿å­˜éŸ³é¢‘æ–‡ä»¶...")
  926:                 try:
  927:                     cmd = [
  928:                         "ffmpeg", "-y",
  929:                         "-hide_banner", "-loglevel", "error", "-nostdin",
  930:                         "-i", video, "-vn", "-acodec", "pcm_s16le",
  931:                         "-ar", "16000", "-ac", "1",
  932:                         "-threads", "0",
  933:                         audio_save_path
  934:                     ]
  935:                     result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', timeout=600)
  936:                     if result.returncode == 0:
  937:                         log_info(f"[pipeline] éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜: {audio_save_path}")
  938:                         emit_progress("éŸ³é¢‘æå–", 1, 1, f"éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜: {os.path.basename(audio_save_path)}")
  939:                     else:
  940:                         log_error(f"[pipeline] éŸ³é¢‘æ–‡ä»¶ä¿å­˜å¤±è´¥: {result.stderr}")
  941:                 except Exception as e:
  942:                     log_error(f"[pipeline] éŸ³é¢‘æ–‡ä»¶ä¿å­˜å¼‚å¸¸: {e}")
  943:                     
  944:             except Exception as e:
  945:                 log_error(f"[pipeline] è½¬å½•å¤±è´¥: {e}")
  946:     
  947:     if enable_video_emotion and not has_video_emotion:
  948:         if 'emotion' not in futures:
  949:             log_info(f"[pipeline] ä¸²è¡Œæƒ…ç»ªåˆ†æ: {video} -> {video_emotion_output}")
  950:             try:
  951:                 class EmotionArgs:
  952:                     def __init__(self, cfg_manager):
  953:                         self.segment_length = float(cfg_manager.get("VIDEO_EMOTION_SEGMENT_LENGTH") or 4.0)
  954:                         self.model_path = cfg_manager.get("VIDEO_EMOTION_MODEL_PATH") or ""
  955:                         self.device = cfg_manager.get("LLM_DEVICE") or 0
  956:                 emotion_args = EmotionArgs(cfg_manager)
  957:                 infer_emotion(video, video_emotion_output, emotion_args)
  958:             except Exception as e:
  959:                 log_error(f"[pipeline] æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
  960:     
  961:     if enable_speaker_separation and 'speaker_separation' not in futures:
  962:         log_info("[pipeline] ä¸²è¡Œä¸»æ’­éŸ³é¢‘åˆ†ç¦»...")
  963:         try:
  964:             from acfv.processing.speaker_separation_integration import SpeakerSeparationIntegration
  965:             separation_output_dir = os.path.join(os.path.dirname(transcription_output), "speaker_separation")
  966:             speaker_separation = SpeakerSeparationIntegration(cfg_manager)
  967:             speaker_separation.set_progress_callback(emit_progress)
  968:             
  969:             separation_result = speaker_separation.process_video_with_speaker_separation(
  970:                 video_path=video,
  971:                 output_dir=separation_output_dir
  972:             )
  973:             
  974:             if separation_result and separation_result.get('host_audio_file'):
  975:                 host_audio_path = separation_result['host_audio_file']
  976:                 log_info(f"[pipeline] ä¸»æ’­éŸ³é¢‘åˆ†ç¦»å®Œæˆ: {host_audio_path}")
  977:         except Exception as e:
  978:             log_error(f"[pipeline] ä¸»æ’­åˆ†ç¦»å¤±è´¥: {e}")
  979:             log_warning(f"[pipeline] è¯´è¯äººåˆ†ç¦»å¤±è´¥ï¼Œä½†ä¸ä¼šé˜»æ­¢æ•´ä¸ªå¤„ç†æµç¨‹")
  980:     
  981:     log_info("[pipeline] å¹¶è¡Œæ•°æ®å‡†å¤‡å®Œæˆ")
  982: 
  983:     # step 3 video emotion
  984:     current_step += 1
  985:     emit_progress("è§†é¢‘æƒ…ç»ªåˆ†æ", current_step, total_steps,
  986:                   "ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹åˆ†æè§†é¢‘æƒ…ç»ª..." if enable_video_emotion else "è·³è¿‡è§†é¢‘æƒ…ç»ªåˆ†æ...")
  987:     t3 = None
  988:     if enable_video_emotion and not has_video_emotion:
  989:         log_info(f"[pipeline] Processing video emotion inference: {video} -> {video_emotion_output}")
  990:         try:
  991:             class EmotionArgs:
  992:                 def __init__(self, cfg_manager):
  993:                     self.segment_length = float(cfg_manager.get("VIDEO_EMOTION_SEGMENT_LENGTH") or 4.0)
  994:                     self.model_path = cfg_manager.get("VIDEO_EMOTION_MODEL_PATH") or ""
  995:                     self.device = cfg_manager.get("LLM_DEVICE") or 0
  996:             emotion_args = EmotionArgs(cfg_manager)
  997:             t3 = threading.Thread(target=infer_emotion, args=(video, video_emotion_output, emotion_args))
  998:             t3.start()
  999:         except Exception as e:
 1000:             log_error(f"[pipeline] Error starting video emotion inference: {e}")
 1001:             with open(video_emotion_output, "w", encoding="utf-8") as f:
 1002:                 import json
 1003:                 json.dump([], f)
 1004:     elif not enable_video_emotion:
 1005:         log_info(f"[pipeline] Video emotion analysis disabled, creating empty emotion file: {video_emotion_output}")
 1006:         with open(video_emotion_output, "w", encoding="utf-8") as f:
 1007:             import json
 1008:             json.dump([], f)
 1009:     else:
 1010:         log_info(f"[pipeline] Using existing video emotion file: {video_emotion_output}")
 1011: 
 1012:     # ç­‰å¾…t3çº¿ç¨‹å®Œæˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
 1013:     if t3:
 1014:         t3.join()
 1015: 
 1016:     # step 4 data prep
 1017:     current_step += 1
 1018:     emit_progress("æ•°æ®å‡†å¤‡", current_step, total_steps, "å‡†å¤‡åˆ†ææ•°æ®...")
 1019:     if not has_chat and not os.path.exists(chat_output):
 1020:         with open(chat_output, "w", encoding="utf-8") as f:
 1021:             import json
 1022:             json.dump([], f)
 1023:             log_info(f"[pipeline] Created empty chat file: {chat_output}")
 1024: 
 1025:     # step 5 analyze
 1026:     current_step += 1
 1027:     emit_progress("æ™ºèƒ½åˆ†æ", current_step, total_steps, "ä½¿ç”¨AIè¿›è¡Œå†…å®¹å…´è¶£åº¦åˆ†æ...")
 1028:     # å®‰å…¨åœ°é‡è½½/å¯¼å…¥ configï¼Œé¿å… "module config not in sys.modules" å¼‚å¸¸
 1029:     try:
 1030:         if 'config' in sys.modules:
 1031:             importlib.reload(sys.modules['config'])
 1032:         else:
 1033:             importlib.import_module('config')
 1034:     except Exception as e:
 1035:         log_error(f"[pipeline] config æ¨¡å—é‡è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨ cfg_manager å€¼: {e}")
 1036: 
 1037:     # å°†é…ç½®å†™å› config æ¨¡å—ï¼ˆè‹¥å­˜åœ¨ï¼‰ä¾›ä¸‹æ¸¸è¯»å–ï¼›å¤±è´¥åˆ™å¿½ç•¥å¹¶ä¾èµ– cfg_manager
 1038:     try:
 1039:         cfg_mod = sys.modules.get('config')
 1040:         if cfg_mod is not None:
 1041:             cfg_mod.CHAT_DENSITY_WEIGHT = cfg_manager.get("CHAT_DENSITY_WEIGHT")
 1042:             cfg_mod.CHAT_SENTIMENT_WEIGHT = cfg_manager.get("CHAT_SENTIMENT_WEIGHT")
 1043:             cfg_mod.TEXT_TARGET_BONUS = cfg_manager.get("TEXT_TARGET_BONUS")
 1044:             cfg_mod.AUDIO_TARGET_BONUS = cfg_manager.get("AUDIO_TARGET_BONUS")
 1045:             cfg_mod.CLIPS_BASE_DIR = cfg_manager.get("CLIPS_BASE_DIR")
 1046:             cfg_mod.OUTPUT_CLIPS_DIR = output_clips_dir
 1047:     except Exception as e:
 1048:         log_error(f"[pipeline] å›å†™ config æ¨¡å—é…ç½®å¤±è´¥ï¼ˆå°†ç›´æ¥ä½¿ç”¨ cfg_managerï¼‰: {e}")
 1049:     max_clips = int(cfg_manager.get("MAX_CLIP_COUNT") or 0)
 1050:     video_emotion_weight = float(cfg_manager.get("VIDEO_EMOTION_WEIGHT") or 0.3) if enable_video_emotion else 0.0
 1051:     log_info(f"[pipeline] Analysis configuration: max_clips={max_clips}, video_emotion_weight={video_emotion_weight}, enable_video_emotion={enable_video_emotion}")
 1052:     segments_data = []
 1053:     analysis_success = False
 1054:     try:
 1055:         import inspect
 1056:         # å°è¯•ä» processing.analyze_data å¯¼å…¥å‡½æ•°
 1057:         analyze_params = []
 1058:         _analyze_func = None
 1059:         try:
 1060:             from acfv.processing.analyze_data import analyze_data as _analyze_func  # å…¼å®¹æ—§æ¥å£
 1061:         except ImportError:
 1062:             try:
 1063:                 from acfv.processing.analyze_data import analyze_data_with_checkpoint as _analyze_func
 1064:             except ImportError:
 1065:                 _analyze_func = None
 1066:         if _analyze_func is not None:
 1067:             analyze_sig = inspect.signature(_analyze_func)
 1068:             analyze_params = list(analyze_sig.parameters.keys())
 1069:             log_info(f"[pipeline] analyze_data function parameters: {analyze_params}")
 1070:         else:
 1071:             log_warning("[pipeline] æœªæ‰¾åˆ° processing.analyze_data ä¸­çš„åˆ†æå‡½æ•°ï¼Œåç»­å°†ç›´æ¥å›é€€")
 1072:         analyze_kwargs = {
 1073:             'chat_file': chat_output,
 1074:             'transcription_file': transcription_output,
 1075:             'output_file': analysis_output
 1076:         }
 1077:         if 'progress_callback' in analyze_params:
 1078:             analyze_kwargs['progress_callback'] = emit_progress
 1079:         if 'enable_video_emotion' in analyze_params:
 1080:             analyze_kwargs.update({
 1081:                 'video_emotion_file': video_emotion_output,
 1082:                 'video_emotion_weight': video_emotion_weight,
 1083:                 'top_n': max_clips if max_clips > 0 else 9999,
 1084:                 'enable_video_emotion': enable_video_emotion,
 1085:                 'device': 'cuda:0'
 1086:             })
 1087:         elif 'video_emotion_file' in analyze_params and 'video_emotion_weight' in analyze_params:
 1088:             analyze_kwargs.update({
 1089:                 'video_emotion_file': video_emotion_output,
 1090:                 'video_emotion_weight': video_emotion_weight,
 1091:                 'top_n': max_clips if max_clips > 0 else 9999
 1092:             })
 1093:         elif 'top_n' in analyze_params:
 1094:             analyze_kwargs['top_n'] = max_clips if max_clips > 0 else 9999
 1095:         
 1096:         # è¯­ä¹‰è‡ªé€‚åº”åˆ†æ
 1097:         log_info("[pipeline] ä½¿ç”¨è¯­ä¹‰è‡ªé€‚åº”åˆ†ææ¨¡å¼")
 1098:         if _analyze_func is not None:
 1099:             segments_data = _analyze_func(**analyze_kwargs)
 1100:         else:
 1101:             try:
 1102:                 from acfv.processing.analyze_data import analyze_data_with_checkpoint as _fallback_analyze
 1103:                 segments_data = _fallback_analyze(**analyze_kwargs)
 1104:             except Exception as _ie:
 1105:                 log_warning(f"[pipeline] æ— æ³•å¯¼å…¥ processing.analyze_data: {_ie}; ä½¿ç”¨ç©ºç»“æœå›é€€")
 1106:                 segments_data = []
 1107:         if segments_data:
 1108:             analysis_success = True
 1109:             log_info("[pipeline] Analysis completed successfully")
 1110:             
 1111:             # æ›´æ–°æ™ºèƒ½è¿›åº¦é¢„æµ‹
 1112:             if smart_predictor:
 1113:                 smart_predictor.finish_stage("æƒ…æ„Ÿåˆ†æ")
 1114:             # âœ… é¢å¤–æ ¡éªŒï¼šç¡®è®¤åˆ†æè¾“å‡ºæ–‡ä»¶æ˜¯å¦çœŸæ­£å†™å‡º
 1115:             try:
 1116:                 if not os.path.exists(analysis_output) or os.path.getsize(analysis_output) < 50:
 1117:                     log_warning(f"[pipeline][diagnostic] åˆ†æå‡½æ•°è¿”å›äº† {len(segments_data)} ä¸ªç‰‡æ®µï¼Œä½†æœªæ£€æµ‹åˆ°æœ‰æ•ˆåˆ†æè¾“å‡ºæ–‡ä»¶: {analysis_output}ï¼Œå°è¯•è¡¥å†™â€¦")
 1118:                     try:
 1119:                         os.makedirs(os.path.dirname(analysis_output), exist_ok=True)
 1120:                         with open(analysis_output, 'w', encoding='utf-8') as _af:
 1121:                             json.dump(segments_data, _af, ensure_ascii=False, indent=2)
 1122:                         log_info("[pipeline][diagnostic] å·²è¡¥å†™ analysis_output æ–‡ä»¶")
 1123:                     except Exception as _we:
 1124:                         log_error(f"[pipeline][diagnostic] è¡¥å†™ analysis_output å¤±è´¥: {_we}")
 1125:                 else:
 1126:                     log_info(f"[pipeline][diagnostic] æ£€æµ‹åˆ°åˆ†æè¾“å‡ºæ–‡ä»¶: {analysis_output} ({os.path.getsize(analysis_output)} bytes)")
 1127:             except Exception as _ce:
 1128:                 log_warning(f"[pipeline][diagnostic] åˆ†æè¾“å‡ºæ–‡ä»¶æ ¡éªŒå¤±è´¥: {_ce}")
 1129:             
 1130:             # âœ… è¯„ä¼°scoreåˆ†å¸ƒï¼Œè¾…åŠ©å‘ç°å…¨0é—®é¢˜
 1131:             try:
 1132:                 scores = [float(s.get('score', 0) or 0) for s in segments_data if isinstance(s, dict)]
 1133:                 if scores:
 1134:                     mx = max(scores); mn = min(scores); avg = sum(scores)/len(scores)
 1135:                     non_zero = sum(1 for v in scores if v > 0)
 1136:                     log_info(f"[pipeline][diagnostic] è¯„åˆ†ç»Ÿè®¡: count={len(scores)}, non_zero={non_zero}, min={mn:.4f}, max={mx:.4f}, avg={avg:.4f}")
 1137:                     if mx <= 0.05:
 1138:                         log_warning("[pipeline][diagnostic] æ£€æµ‹åˆ°æ‰€æœ‰è¯„åˆ†éå¸¸ä½ (max <= 0.05)ï¼Œå¯èƒ½èŠå¤©/æ–‡æœ¬/æƒé‡å…¨éƒ¨ä¸º0 æˆ–è¢«æ‹†åˆ†ç¨€é‡Š")
 1139:                 else:
 1140:                     log_warning("[pipeline][diagnostic] åˆ†æè¿”å›çš„ç‰‡æ®µç¼ºå°‘ score å­—æ®µ")
 1141:             except Exception as _se:
 1142:                 log_warning(f"[pipeline][diagnostic] è¯„åˆ†ç»Ÿè®¡å¤±è´¥: {_se}")
 1143:                 
 1144:     except Exception as e:
 1145:         log_error(f"[pipeline] Analysis failed: {e}")
 1146:         analysis_success = False
 1147: 
 1148:     current_step += 1
 1149:     emit_progress("å¹¶è¡Œè§†é¢‘åˆ‡ç‰‡", current_step, total_steps, "å¹¶è¡Œç”Ÿæˆè§†é¢‘åˆ‡ç‰‡æ–‡ä»¶...")
 1150: 
 1151:     if not analysis_success:
 1152:         if os.path.exists(analysis_output) and os.path.getsize(analysis_output) > 10:
 1153:             log_info(f"[pipeline] Reading analysis result: {analysis_output}")
 1154:             try:
 1155:                 with open(analysis_output, "r", encoding="utf-8") as f:
 1156:                     segments_data = json.load(f)
 1157:                 log_info(f"[pipeline] Found {len(segments_data)} segments in analysis result")
 1158:                 # ç¡®ä¿å…ˆæŒ‰è¯„åˆ†æ’åºå†é™åˆ¶æ•°é‡ï¼Œé¿å…æŒ‰æ—¶é—´æˆªå–
 1159:                 try:
 1160:                     segments_data = sorted(segments_data, key=lambda x: x.get('score', 0), reverse=True)
 1161:                 except Exception:
 1162:                     pass
 1163:                 if max_clips > 0 and len(segments_data) > max_clips:
 1164:                     original_count = len(segments_data)
 1165:                     segments_data = segments_data[:max_clips]
 1166:                     log_info(f"[pipeline] Limited segments from {original_count} to {len(segments_data)} based on MAX_CLIP_COUNT={max_clips}")
 1167:                 # Fallback æƒ…å†µä¸‹åŒæ ·ç»™å‡ºè¯„åˆ†åˆ†å¸ƒè¯Šæ–­
 1168:                 try:
 1169:                     scores = [float(s.get('score', 0) or 0) for s in segments_data if isinstance(s, dict)]
 1170:                     if scores:
 1171:                         mx = max(scores); mn = min(scores); avg = sum(scores)/len(scores)
 1172:                         non_zero = sum(1 for v in scores if v > 0)
 1173:                         log_info(f"[pipeline][diagnostic][fallback] è¯„åˆ†ç»Ÿè®¡: count={len(scores)}, non_zero={non_zero}, min={mn:.4f}, max={mx:.4f}, avg={avg:.4f}")
 1174:                         if mx <= 0.05:
 1175:                             log_warning("[pipeline][diagnostic][fallback] åˆ†æç»“æœè¯„åˆ†å…¨éƒ¨æä½æˆ–ä¸º0ï¼Œå¯èƒ½ upstream æœªå†™å…¥æœ‰æ•ˆè¯„åˆ†")
 1176:                 except Exception:
 1177:                     pass
 1178:             except Exception as e:
 1179:                 log_error(f"[pipeline] Error reading analysis result: {e}")
 1180:                 segments_data = []
 1181:         else:
 1182:             log_warning("[pipeline][diagnostic] åˆ†æå¤±è´¥ä¸”æœªæ‰¾åˆ°å¯ç”¨çš„åˆ†æè¾“å‡ºæ–‡ä»¶ï¼Œåç»­æ­¥éª¤å°†ä½¿ç”¨ç©ºç‰‡æ®µåˆ—è¡¨")
 1183: 
 1184:     # åˆ‡ç‰‡å‰ç®€å•æ£€æµ‹æ˜¯å¦å­˜åœ¨æ–°çš„è¯„åˆ†ï¼ˆä»…æ—¥å¿—æç¤ºï¼‰
 1185:     try:
 1186:         run_dir = os.path.dirname(analysis_output)
 1187:         ratings_log_path = os.path.join(run_dir, 'acfv_ratings.jsonl')
 1188:         if os.path.exists(ratings_log_path) and os.path.getsize(ratings_log_path) > 0:
 1189:             with open(ratings_log_path, 'r', encoding='utf-8') as f:
 1190:                 ratings_lines = sum(1 for _ in f)
 1191:             log_info(f"[pipeline][RAG] æ£€æµ‹åˆ°è¯„åˆ†è®°å½• {ratings_lines} æ¡ï¼ˆä»…æ£€æµ‹ï¼Œä¸è¿›è¡ŒRAGå¤„ç†ï¼‰")
 1192:         else:
 1193:             log_info("[pipeline][RAG] æœªæ£€æµ‹åˆ°è¯„åˆ†è®°å½•æˆ–è¯„åˆ†æ–‡ä»¶ä¸ºç©º")
 1194:     except Exception as e:
 1195:         log_warning(f"[pipeline][RAG] è¯„åˆ†æ£€æµ‹å¤±è´¥: {e}")
 1196: 
 1197:     # äºŒæ¬¡ä¿éšœï¼ˆå¯é€‰ï¼‰ï¼šä» ratings.json é‡å»ºç‰‡æ®µé¡ºåº
 1198:     try:
 1199:         prefer_from_ratings = False
 1200:         try:
 1201:             prefer_from_ratings = bool(cfg_manager.get("PREFER_RATINGS_JSON", False))
 1202:         except Exception:
 1203:             prefer_from_ratings = False
 1204:         if prefer_from_ratings and not use_semantic_segment_mode:
 1205:             ratings_path = os.path.join(os.path.dirname(analysis_output), "ratings.json")
 1206:             video_dir = os.path.dirname(video)
 1207:             latest_dir = os.path.join(video_dir, "runs", "latest")
 1208:             candidate_latest = os.path.join(latest_dir, "ratings.json")
 1209:             candidate_video = os.path.join(video_dir, "ratings.json")
 1210:             if not os.path.exists(ratings_path):
 1211:                 if os.path.exists(candidate_latest):
 1212:                     ratings_path = candidate_latest
 1213:                 elif os.path.exists(candidate_video):
 1214:                     ratings_path = candidate_video
 1215:             if os.path.exists(ratings_path):
 1216:                 with open(ratings_path, 'r', encoding='utf-8') as f:
 1217:                     ratings_data = json.load(f)
 1218:                 rated_segments = []
 1219:                 for clip_name, data in ratings_data.items():
 1220:                     try:
 1221:                         rated_segments.append({
 1222:                             'start': float(data.get('start', 0.0)),
 1223:                             'end': float(data.get('end', 0.0)),
 1224:                             'score': float(data.get('rating', 0.0)),
 1225:                             'text': data.get('text', ''),
 1226:                             'source': 'ratings.json'
 1227:                         })
 1228:                     except Exception:
 1229:                         continue
 1230:                 if rated_segments:
 1231:                     rated_segments.sort(key=lambda x: x.get('score', 0.0), reverse=True)
 1232:                     if max_clips > 0 and len(rated_segments) > max_clips:
 1233:                         rated_segments = rated_segments[:max_clips]
 1234:                     segments_data = rated_segments
 1235:                     log_info(f"[pipeline] é‡‡ç”¨ ratings.json è¯„åˆ†é‡å»ºç‰‡æ®µé¡ºåºï¼Œå…± {len(segments_data)} ä¸ª")
 1236:         else:
 1237:             log_info("[pipeline] å·²ç¦ç”¨ä» ratings.json é‡å»ºç‰‡æ®µï¼ˆPREFER_RATINGS_JSON=Falseï¼‰")
 1238:     except Exception as e:
 1239:         log_warning(f"[pipeline] ä½¿ç”¨ ratings.json é‡æ’å¤±è´¥: {e}")
 1240: 
 1241:     log_info(f"[pipeline] Final segments count: {len(segments_data)}")
 1242: 
 1243:     def _has_ranking_signals(items):
 1244:         try:
 1245:             for seg in items:
 1246:                 if not isinstance(seg, dict):
 1247:                     continue
 1248:                 score = seg.get("score")
 1249:                 if score is not None:
 1250:                     try:
 1251:                         if float(score) > 0:
 1252:                             return True
 1253:                     except Exception:
 1254:                         return True
 1255:                 source = str(seg.get("source", "")).lower()
 1256:                 if source in {"ratings.json", "manual", "acfv_ratings", "manual_rating"}:
 1257:                     return True
 1258:             return False
 1259:         except Exception:
 1260:             return False
 1261: 
 1262:     ranked_segments_detected = bool(segments_data) and _has_ranking_signals(segments_data)
 1263: 
 1264:     # è¯­ä¹‰åˆ†æ®µæ¨¡å¼ï¼ˆä»å¤´åˆ°å°¾æŒ‰è¯­ä¹‰è¿ç»­åˆ†æ®µï¼Œç›®æ ‡çº¦4åˆ†é’Ÿï¼Œé¿å…è¿‡çŸ­ï¼‰
 1265:     try:
 1266:         val = cfg_manager.get("SEMANTIC_SEGMENT_MODE")
 1267:         # é»˜è®¤å¼€å¯è¯­ä¹‰åˆ†æ®µæ¨¡å¼ï¼ˆç”¨æˆ·æœŸæœ›"ä»ä¸€å¼€å§‹å°±æŒ‰è¯­ä¹‰åˆ‡å—"ï¼‰
 1268:         use_semantic_segment_mode = bool(val) if val is not None else True
 1269:     except Exception:
 1270:         use_semantic_segment_mode = True
 1271: 
 1272:     if use_semantic_segment_mode and ranked_segments_detected:
 1273:         try:
 1274:             raw_force_semantic = cfg_manager.get("FORCE_SEMANTIC_SEGMENT")
 1275:         except Exception:
 1276:             raw_force_semantic = None
 1277:         force_semantic = bool(raw_force_semantic) if raw_force_semantic is not None else False
 1278:         if not force_semantic:
 1279:             log_info("[pipeline] æ£€æµ‹åˆ°è¯„åˆ†é©±åŠ¨çš„ç‰‡æ®µæ’åºï¼Œä¼˜å…ˆä¿ç•™è¯„åˆ†ç»“æœï¼Œè·³è¿‡è¯­ä¹‰åˆ†æ®µã€‚å¦‚éœ€å¼ºåˆ¶è¯­ä¹‰åˆ‡å—ï¼Œè¯·å¼€å¯ FORCE_SEMANTIC_SEGMENTã€‚")
 1280:             use_semantic_segment_mode = False
 1281:         else:
 1282:             log_info("[pipeline] FORCE_SEMANTIC_SEGMENT å·²å¯ç”¨ï¼Œæ£€æµ‹åˆ°è¯„åˆ†ä¹Ÿç»§ç»­æ‰§è¡Œè¯­ä¹‰åˆ†æ®µã€‚")
 1283: 
 1284:     if use_semantic_segment_mode:
 1285:         log_info("[pipeline] å¯ç”¨è¯­ä¹‰åˆ†æ®µæ¨¡å¼ï¼šä»å¤´æŒ‰è¯­ä¹‰è¿ç»­åˆ‡åˆ†ï¼ˆçº¦4åˆ†é’Ÿï¼‰")
 1286:         try:
 1287:             # åŠ è½½å®Œæ•´è½¬å½•ä½œä¸ºåˆ†æ®µä¾æ®
 1288:             if os.path.exists(transcription_output):
 1289:                 with open(transcription_output, 'r', encoding='utf-8') as f:
 1290:                     transcription_data = json.load(f)
 1291:             else:
 1292:                 transcription_data = []
 1293:             # å‚æ•°
 1294:             target_sec = float(cfg_manager.get("SEMANTIC_TARGET_DURATION") or 240.0)
 1295:             min_sec = float(cfg_manager.get("MIN_CLIP_DURATION") or max(60.0, target_sec * 0.6))
 1296:             max_sec = float(cfg_manager.get("MAX_CLIP_DURATION") or min(target_sec * 1.6, 600.0))
 1297:             sim_threshold = float(cfg_manager.get("SEMANTIC_SIMILARITY_THRESHOLD") or 0.75)
 1298:             max_gap = float(cfg_manager.get("SEMANTIC_MAX_TIME_GAP") or 60.0)
 1299: 
 1300:             # é¢„å¤„ç†è½¬å½•ç‰‡æ®µ
 1301:             segs = []
 1302:             for seg in transcription_data:
 1303:                 try:
 1304:                     s = float(seg.get('start', 0.0)); e = float(seg.get('end', 0.0))
 1305:                     txt = seg.get('text', '') or ''
 1306:                     if e > s and txt.strip():
 1307:                         segs.append({'start': s, 'end': e, 'text': txt})
 1308:                 except Exception:
 1309:                     continue
 1310:             segs.sort(key=lambda x: x['start'])
 1311: 
 1312:             # å‘é‡åŒ–ï¼ˆTF-IDFä¼˜å…ˆï¼›å¤±è´¥åˆ™BOWï¼‰
 1313:             try:
 1314:                 from sklearn.feature_extraction.text import TfidfVectorizer
 1315:                 from sklearn.metrics.pairwise import cosine_similarity
 1316:                 texts = [s['text'] for s in segs]
 1317:                 vectorizer = TfidfVectorizer(max_features=5000)
 1318:                 mat = vectorizer.fit_transform(texts) if texts else None
 1319:                 def cosine(i, j):
 1320:                     try:
 1321:                         return float(cosine_similarity(mat[i], mat[j])[0][0]) if mat is not None else 1.0
 1322:                     except Exception:
 1323:                         return 1.0
 1324:             except Exception:
 1325:                 # é€€åŒ–ä¸ºç®€å•è¯è¢‹ä½™å¼¦
 1326:                 def to_bow(t):
 1327:                     import re
 1328:                     toks = re.findall(r"\w+", (t or '').lower())
 1329:                     from collections import Counter
 1330:                     return Counter(toks)
 1331:                 bows = [to_bow(s['text']) for s in segs]
 1332:                 import math
 1333:                 def cosine(i, j):
 1334:                     a, b = bows[i], bows[j]
 1335:                     if not a or not b:
 1336:                         return 0.0
 1337:                     keys = set(a) | set(b)
 1338:                     dot = sum(a.get(k,0) * b.get(k,0) for k in keys)
 1339:                     na = math.sqrt(sum(v*v for v in a.values())); nb = math.sqrt(sum(v*v for v in b.values()))
 1340:                     return (dot / (na*nb)) if na>0 and nb>0 else 0.0
 1341: 
 1342:             # é¡ºåºåˆå¹¶ä¸ºè¯­ä¹‰å—
 1343:             def _avg(values):
 1344:                 return sum(values) / len(values) if values else None
 1345: 
 1346:             def _aggregate_segment_scores(group):
 1347:                 scores = []
 1348:                 interest_scores = []
 1349:                 densities = []
 1350:                 rag_priors = []
 1351:                 volumes = []
 1352:                 for seg in group:
 1353:                     try:
 1354:                         if seg.get("score") is not None:
 1355:                             scores.append(float(seg.get("score")))
 1356:                     except Exception:
 1357:                         pass
 1358:                     try:
 1359:                         if seg.get("interest_score") is not None:
 1360:                             interest_scores.append(float(seg.get("interest_score")))
 1361:                     except Exception:
 1362:                         pass
 1363:                     try:
 1364:                         if seg.get("density") is not None:
 1365:                             densities.append(float(seg.get("density")))
 1366:                     except Exception:
 1367:                         pass
 1368:                     try:
 1369:                         if seg.get("rag_prior") is not None:
 1370:                             rag_priors.append(float(seg.get("rag_prior")))
 1371:                     except Exception:
 1372:                         pass
 1373:                     try:
 1374:                         if seg.get("volume_penalty") is not None:
 1375:                             volumes.append(float(seg.get("volume_penalty")))
 1376:                     except Exception:
 1377:                         pass
 1378:                 payload = {}
 1379:                 avg_interest = _avg(scores or interest_scores)
 1380:                 if avg_interest is not None:
 1381:                     payload["score"] = avg_interest
 1382:                     payload["interest_score"] = avg_interest
 1383:                 avg_density = _avg(densities)
 1384:                 if avg_density is not None:
 1385:                     payload["density"] = avg_density
 1386:                 avg_rag = _avg(rag_priors)
 1387:                 if avg_rag is not None:
 1388:                     payload["rag_prior"] = avg_rag
 1389:                 avg_volume = _avg(volumes)
 1390:                 if avg_volume is not None:
 1391:                     payload["volume_penalty"] = avg_volume
 1392:                 return payload
 1393: 
 1394:             semantic_segments = []
 1395:             cur_start = None; cur_end = None; cur_last_idx = None; cur_texts = []; cur_segments = []
 1396:             for idx, seg in enumerate(segs):
 1397:                 s = seg['start']; e = seg['end']
 1398:                 if cur_start is None:
 1399:                     cur_start, cur_end, cur_last_idx, cur_texts = s, e, idx, [seg['text']]
 1400:                     cur_segments = [seg]
 1401:                     continue
 1402:                 gap = s - cur_end
 1403:                 similar = True
 1404:                 try:
 1405:                     similar = cosine(cur_last_idx, idx) >= sim_threshold
 1406:                 except Exception:
 1407:                     similar = True
 1408:                 new_dur = max(cur_end, e) - cur_start
 1409:                 # æ»¡è¶³ä»¥ä¸‹ä»»ä¸€æ¡ä»¶åˆ™åˆ‡å—ï¼š
 1410:                 # 1) é—´éš”è¿‡å¤§ï¼›2) è¾¾åˆ°ä¸Šé™ï¼›3) å·²æ¥è¿‘ç›®æ ‡ä¸”ç›¸ä¼¼åº¦ä¸è¶³
 1411:                 if (gap > max_gap) or (new_dur >= max_sec) or ((new_dur >= target_sec) and (not similar)):
 1412:                     # è‹¥å½“å‰å—è¿‡çŸ­ï¼Œå°½é‡å¹¶å…¥
 1413:                     if (cur_end - cur_start) < min_sec and (new_dur <= max_sec):
 1414:                         cur_end = max(cur_end, e)
 1415:                         cur_last_idx = idx
 1416:                         cur_texts.append(seg['text'])
 1417:                         cur_segments.append(seg)
 1418:                     else:
 1419:                         merged = {'start': cur_start, 'end': cur_end, 'text': ' '.join(cur_texts)}
 1420:                         merged.update(_aggregate_segment_scores(cur_segments))
 1421:                         semantic_segments.append(merged)
 1422:                         cur_start, cur_end, cur_last_idx, cur_texts = s, e, idx, [seg['text']]
 1423:                         cur_segments = [seg]
 1424:                 else:
 1425:                     cur_end = max(cur_end, e)
 1426:                     cur_last_idx = idx
 1427:                     cur_texts.append(seg['text'])
 1428:                     cur_segments.append(seg)
 1429:             if cur_start is not None:
 1430:                 merged = {'start': cur_start, 'end': cur_end, 'text': ' '.join(cur_texts)}
 1431:                 merged.update(_aggregate_segment_scores(cur_segments))
 1432:                 semantic_segments.append(merged)
 1433: 
 1434:             # è¦†ç›– segments_dataï¼ˆé¡ºåºè¾“å‡ºï¼Œä¸å†æŒ‰åˆ†æ•°é‡æ’ï¼‰
 1435:             segments_data = semantic_segments
 1436:             log_info(f"[pipeline] è¯­ä¹‰åˆ†æ®µå®Œæˆï¼Œå…± {len(segments_data)} æ®µï¼ˆç›®æ ‡â‰ˆ{target_sec:.0f}sï¼‰")
 1437: 
 1438:             # ä¿è¯è¾“å‡ºæ°å¥½ N æ®µä¸”ä¸é‡å ï¼ˆä¸è¶³åˆ™æŒ‰è½¬å½•è¾¹ç•Œæ‹†åˆ†æœ€é•¿æ®µï¼Œè¶…å‡ºåˆ™è£å‰ªï¼‰
 1439:             try:
 1440:                 desired_count = int(cfg_manager.get("MAX_CLIP_COUNT") or 10)
 1441:                 if desired_count <= 0:
 1442:                     desired_count = 10
 1443:             except Exception:
 1444:                 desired_count = 10
 1445: 
 1446:             # æ ¹æ®è½¬å½•è¾¹ç•Œåœ¨ç‰‡æ®µå†…éƒ¨å¯»æ‰¾æœ€ä¼˜æ‹†åˆ†ç‚¹
 1447:             def _find_split_time_within(seg_start: float, seg_end: float, transcription_list, prefer_time: float,
 1448:                                         min_side: float) -> float:
 1449:                 try:
 1450:                     candidates = []
 1451:                     for t in transcription_list:
 1452:                         try:
 1453:                             ts = float(t.get('start', 0.0)); te = float(t.get('end', 0.0))
 1454:                         except Exception:
 1455:                             continue
 1456:                         if ts <= seg_start or te >= seg_end:
 1457:                             continue
 1458:                         # é€‰ç”¨å¥å­è¾¹ç•Œçš„ä¸­ç‚¹ä½œä¸ºå€™é€‰ï¼Œä»¥åå‘è‡ªç„¶åœé¡¿
 1459:                         mid = (ts + te) / 2.0
 1460:                         # ä¸¤ä¾§éœ€ä¿ç•™æœ€å°é•¿åº¦
 1461:                         if (mid - seg_start) >= min_side and (seg_end - mid) >= min_side:
 1462:                             candidates.append(mid)
 1463:                     if not candidates:
 1464:                         return 0.0
 1465:                     # é€‰æ‹©æœ€æ¥è¿‘æœŸæœ›æ—¶é—´ç‚¹ï¼ˆé€šå¸¸ä¸ºä¸­ç‚¹ï¼‰çš„è¾¹ç•Œ
 1466:                     best = min(candidates, key=lambda x: abs(x - prefer_time))
 1467:                     return float(best)
 1468:                 except Exception:
 1469:                     return 0.0
 1470: 
 1471:             def _split_longest_until_exact(segments, target_n: int, transcription_list, min_len: float, video_len: float):
 1472:                 # å…è®¸çš„æœ€ä½æ‹†åˆ†å­ç‰‡æ®µé•¿åº¦ï¼ˆåœ¨min_lenåŸºç¡€ä¸Šé€‚åº¦æ”¾å®½ï¼‰
 1473:                 min_child = max(min_len * 0.75, 30.0)
 1474:                 safety_counter = 0
 1475:                 while len(segments) < target_n and safety_counter < 200:
 1476:                     safety_counter += 1
 1477:                     # é€‰å¯æ‹†åˆ†çš„æœ€é•¿ç‰‡æ®µ
 1478:                     idx = -1
 1479:                     max_dur = -1.0
 1480:                     for i, s in enumerate(segments):
 1481:                         try:
 1482:                             ds = float(s.get('start', 0.0)); de = float(s.get('end', 0.0))
 1483:                         except Exception:
 1484:                             continue
 1485:                         dur = max(0.0, de - ds)
 1486:                         # è‡³å°‘èƒ½æ‹†æˆä¸¤ä¸ªä¸å°äº min_child çš„å­æ®µ
 1487:                         if dur >= (2.0 * min_child) and dur > max_dur:
 1488:                             max_dur = dur
 1489:                             idx = i
 1490:                     if idx < 0:
 1491:                         break  # æ²¡æœ‰å¯æ‹†åˆ†çš„ç‰‡æ®µ
 1492: 
 1493:                     base = segments[idx]
 1494:                     s0 = float(base.get('start', 0.0)); e0 = float(base.get('end', 0.0))
 1495:                     mid_pref = (s0 + e0) / 2.0
 1496:                     split_t = _find_split_time_within(s0, e0, transcription_list, mid_pref, min_child)
 1497:                     if split_t <= 0.0:
 1498:                         # æ²¡æœ‰åˆé€‚çš„è½¬å½•è¾¹ç•Œï¼Œä½¿ç”¨ä¸­ç‚¹ä½†éµå®ˆæœ€å°é•¿åº¦
 1499:                         left = max(s0, min(mid_pref, e0 - min_child))
 1500:                         right = min(e0, max(mid_pref, s0 + min_child))
 1501:                         split_t = (left + right) / 2.0
 1502:                     # æ„é€ ä¸¤ä¸ªæ–°ç‰‡æ®µ
 1503:                     left_seg = dict(base)
 1504:                     right_seg = dict(base)
 1505:                     left_seg['start'] = float(s0)
 1506:                     left_seg['end'] = float(split_t)
 1507:                     right_seg['start'] = float(split_t)
 1508:                     right_seg['end'] = float(e0)
 1509:                     # æ ¡éªŒé•¿åº¦
 1510:                     if (left_seg['end'] - left_seg['start']) < min_child or (right_seg['end'] - right_seg['start']) < min_child:
 1511:                         # æ— æ³•æ»¡è¶³æœ€å°é•¿åº¦ï¼Œæ”¾å¼ƒæœ¬æ¬¡æ‹†åˆ†
 1512:                         break
 1513:                     # æ›¿æ¢å¹¶ä¿æŒæ—¶é—´é¡ºåº
 1514:                     segments.pop(idx)
 1515:                     segments.insert(idx, right_seg)
 1516:                     segments.insert(idx, left_seg)
 1517:                     segments.sort(key=lambda x: float(x.get('start', 0.0)))
 1518:                 return segments
 1519: 
 1520:             # è£å‰ªæˆ–æ‹†åˆ†ï¼Œä¿è¯æ°å¥½ desired_count æ®µ
 1521:             try:
 1522:                 # å…ˆåˆè§„æ’åº
 1523:                 segments_data = sorted(segments_data, key=lambda x: float(x.get('start', 0.0)))
 1524:                 if len(segments_data) > desired_count:
 1525:                     # è‹¥æ— scoreå­—æ®µï¼Œåˆ™ç›´æ¥å–æ—¶é—´é¡ºåºå‰Næ®µ
 1526:                     try:
 1527:                         segments_data = sorted(segments_data, key=lambda x: x.get('score', 0.0), reverse=True)[:desired_count]
 1528:                         segments_data = sorted(segments_data, key=lambda x: float(x.get('start', 0.0)))
 1529:                     except Exception:
 1530:                         segments_data = segments_data[:desired_count]
 1531:                 elif len(segments_data) < desired_count:
 1532:                     # æ‹†åˆ†æœ€é•¿æ®µç›´è‡³è¾¾åˆ°Næ®µ
 1533:                     segments_data = _split_longest_until_exact(segments_data, desired_count, transcription_data, min_sec, 0.0)
 1534:                 # å†æ¬¡ç¡®è®¤æ•°é‡
 1535:                 if len(segments_data) != desired_count:
 1536:                     log_warning(f"[pipeline] æ— æ³•ä¸¥æ ¼è¾¾åˆ° {desired_count} æ®µï¼Œå½“å‰ {len(segments_data)} æ®µï¼ˆå·²å°½æœ€å¤§åŠªåŠ›ï¼‰")
 1537:                 # æœ€ç»ˆç¡®ä¿ä¸é‡å ï¼ˆé¡ºåºå‹ç´§ï¼šæ¯æ®µç»“æŸä¸è¶…è¿‡ä¸‹ä¸€æ®µå¼€å§‹ï¼‰
 1538:                 segments_data = sorted(segments_data, key=lambda x: float(x.get('start', 0.0)))
 1539:                 for i in range(len(segments_data) - 1):
 1540:                     try:
 1541:                         if float(segments_data[i]['end']) > float(segments_data[i+1]['start']):
 1542:                             segments_data[i]['end'] = float(segments_data[i+1]['start'])
 1543:                     except Exception:
 1544:                         pass
 1545:             except Exception as _e:
 1546:                 log_warning(f"[pipeline] è°ƒæ•´ä¸ºæ°å¥½Næ®µå¤±è´¥ï¼Œå°†ä½¿ç”¨è¯­ä¹‰åˆ†æ®µåŸå§‹ç»“æœ: {_e}")
 1547:         except Exception as e:
 1548:             log_warning(f"[pipeline] è¯­ä¹‰åˆ†æ®µæ¨¡å¼å¤±è´¥ï¼Œå›é€€åˆ°åˆ†æç»“æœ: {e}")
 1549:     
 1550:     # åº”ç”¨åˆ‡ç‰‡æ—¶é•¿æ‰©å±•é€»è¾‘
 1551:     if segments_data:
 1552:         # è¯­ä¹‰å¯å˜æ—¶é•¿ï¼šä½¿ç”¨é…ç½®æˆ–é»˜è®¤å€¼
 1553:         if use_semantic_segment_mode:
 1554:             # åœ¨è¯­ä¹‰åˆ†æ®µæ¨¡å¼ä¸‹ï¼Œå›ºå®šå¼ºçº¦æŸï¼Œé¿å…å¤–éƒ¨æŠŠminè®¾åˆ°300s
 1555:             target_sec = float(cfg_manager.get("SEMANTIC_TARGET_DURATION") or 240.0)
 1556:             min_clip_duration = max(150.0, target_sec * 0.6)
 1557:             context_extend = float(cfg_manager.get("CLIP_CONTEXT_EXTEND") or 0.0)
 1558:         else:
 1559:             min_clip_duration = float(cfg_manager.get("MIN_CLIP_DURATION") or 60.0)
 1560:             context_extend = float(cfg_manager.get("CLIP_CONTEXT_EXTEND") or 0.0)
 1561:         
 1562:         # è·å–è§†é¢‘æ€»æ—¶é•¿
 1563:         try:
 1564:             probe_cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', video]
 1565:             probe_result = subprocess.run(probe_cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', timeout=30)
 1566:             if probe_result.returncode == 0:
 1567:                 import json
 1568:                 probe_data = json.loads(probe_result.stdout)
 1569:                 video_duration = float(probe_data['format']['duration'])
 1570:             else:
 1571:                 video_duration = 30000  # é»˜è®¤30åˆ†é’Ÿ
 1572:         except:
 1573:             video_duration = 30000  # é»˜è®¤30åˆ†é’Ÿ
 1574:         
 1575:         log_info(f"[pipeline] è§†é¢‘æ€»æ—¶é•¿: {video_duration:.1f}ç§’")
 1576:         log_info(f"[pipeline] åˆ‡ç‰‡é…ç½®: æœ€å°æ—¶é•¿={min_clip_duration}ç§’, å‰åæ–‡æ‰©å±•={context_extend}ç§’")
 1577:         
 1578:         # æ‰©å±•ç‰‡æ®µæ—¶é•¿
 1579:         from acfv.processing.clip_video import ensure_min_duration, extend_segment
 1580:         
 1581:         # æ­¥éª¤1ï¼šæ‰©å±•ç‰‡æ®µå‰åæ–‡
 1582:         if context_extend > 0:
 1583:             log_info(f"[pipeline] æ‰©å±•ç‰‡æ®µå‰åæ–‡ {context_extend}ç§’...")
 1584:             segments_data = [extend_segment(seg, context_extend, video_duration) for seg in segments_data]
 1585:         
 1586:         # æ­¥éª¤2ï¼šç¡®ä¿è¾¾åˆ°æœ€å°æ—¶é•¿
 1587:         log_info(f"[pipeline] ç¡®ä¿åˆ‡ç‰‡è¾¾åˆ°æœ€å°æ—¶é•¿ {min_clip_duration}ç§’...")
 1588:         segments_data = ensure_min_duration(segments_data, min_clip_duration, video_duration)
 1589:         
 1590:         # æ­¥éª¤3ï¼šä»¥è¯„åˆ†ä¼˜å…ˆå®‰æ’ä¸º"ä¸¥æ ¼ä¸é‡å "çš„æ—¶é—´è¡¨ï¼ˆå«å¯é…ç½®ç¼“å†²ï¼‰
 1591:         buffer_sec = 0.0
 1592:         try:
 1593:             buf = cfg_manager.get("NON_OVERLAP_BUFFER_SECONDS")
 1594:             if isinstance(buf, (int, float)):
 1595:                 buffer_sec = max(0.0, float(buf))
 1596:         except Exception:
 1597:             buffer_sec = 0.0
 1598: 
 1599:         if not use_semantic_segment_mode:
 1600:             log_info(f"[pipeline] æŒ‰è¯„åˆ†ä¼˜å…ˆå®‰æ’ç‰‡æ®µï¼Œä¿è¯æ— é‡å ï¼ˆç¼“å†²={buffer_sec:.1f}sï¼‰...")
 1601: 
 1602:             # è¯„åˆ†é«˜â†’ä½æ’åˆ—ï¼Œé€ä¸ªåœ¨æ—¶é—´è½´ä¸Šå®‰æ”¾
 1603:             candidates = sorted(segments_data, key=lambda x: x.get('score', 0.0), reverse=True)
 1604:             # æ ‡è®°åŸå§‹ç´¢å¼•ï¼Œä¾¿äºå›å¡«
 1605:             for _i, _seg in enumerate(candidates):
 1606:                 try:
 1607:                     _seg['__orig_idx'] = _i
 1608:                 except Exception:
 1609:                     pass
 1610:             scheduled = []  # å·²å ç”¨åŒºé—´
 1611:             placed_indices = set()
 1612: 
 1613:             def _windows_from_scheduled():
 1614:                 # ç”±å·²å ç”¨æ„é€ ç©ºé—²çª—å£åˆ—è¡¨
 1615:                 free = []
 1616:                 cursor = 0.0
 1617:                 for occ in sorted(scheduled, key=lambda x: x['start']):
 1618:                     os, oe = float(occ['start']), float(occ['end'])
 1619:                     if os - buffer_sec > cursor:
 1620:                         free.append((cursor, os - buffer_sec))
 1621:                     cursor = max(cursor, oe + buffer_sec)
 1622:                 if cursor < video_duration:
 1623:                     free.append((cursor, video_duration))
 1624:                 return free
 1625: 
 1626:             drops_due_to_space = 0
 1627: 
 1628:             for seg in candidates:
 1629:                 try:
 1630:                     base_s = float(seg.get('start', 0.0))
 1631:                     base_e = float(seg.get('end', 0.0))
 1632:                 except Exception:
 1633:                     continue
 1634:                 if base_e <= base_s:
 1635:                     continue
 1636: 
 1637:                 # å·²ç»åº”ç”¨è¿‡å‰åæ–‡æ‰©å±•ä¸æœ€å°æ—¶é•¿ï¼Œè¿™é‡Œåªç¡®ä¿åœ¨ç©ºçª—å†…è½ä½
 1638:                 desired_s = max(0.0, min(base_s, video_duration))
 1639:                 desired_e = max(0.0, min(base_e, video_duration))
 1640:                 target_len = max(0.0, desired_e - desired_s)
 1641:                 if target_len <= 0.0:
 1642:                     continue
 1643: 
 1644:                 # éå†å½“å‰ç©ºçª—ï¼Œé€‰æ‹©ä¸åŸä¸­å¿ƒæœ€è¿‘çš„å¯æ”¾ç½®çª—å£
 1645:                 free_windows = _windows_from_scheduled()
 1646:                 if not free_windows:
 1647:                     drops_due_to_space += 1
 1648:                     continue
 1649:                 center = (desired_s + desired_e) / 2.0
 1650:                 free_windows.sort(key=lambda w: abs(((w[0] + w[1]) / 2.0) - center))
 1651: 
 1652:                 placed = False
 1653:                 for (L, R) in free_windows:
 1654:                     # åœ¨è¯¥çª—å£å†…å°½é‡ä¿æŒåŸåŒºé—´ï¼Œè‹¥ä¸å¤Ÿåˆ™å¤¹ç´§
 1655:                     s = max(L, desired_s)
 1656:                     e = min(R, desired_e)
 1657:                     if e - s <= 0.0:
 1658:                         continue
 1659:                     # ä¿æŒåŸé•¿åº¦çš„å‰æä¸‹ï¼Œè‹¥çª—å£è¾ƒå¤§ï¼Œå°è¯•å±…ä¸­æ”¾ç½®
 1660:                     length = min(target_len, R - L)
 1661:                     if length <= 0.0:
 1662:                         continue
 1663:                     # è°ƒæ•´ä¸ºä¸åŸä¸­å¿ƒå¯¹é½çš„ç­‰é•¿åŒºé—´
 1664:                     half = length / 2.0
 1665:                     s_candidate = max(L, min(center - half, R - length))
 1666:                     e_candidate = s_candidate + length
 1667:                     if e_candidate - s_candidate > 0.0:
 1668:                         new_seg = dict(seg)
 1669:                         new_seg['start'] = float(s_candidate)
 1670:                         new_seg['end'] = float(e_candidate)
 1671:                         scheduled.append(new_seg)
 1672:                         if '__orig_idx' in seg:
 1673:                             placed_indices.add(seg['__orig_idx'])
 1674:                         placed = True
 1675:                         break
 1676: 
 1677:                 if not placed:
 1678:                     drops_due_to_space += 1
 1679: 
 1680:             # äºŒæ¬¡å›å¡«ï¼šé€æ­¥å‡å°‘ç¼“å†²ã€æŒ‰å¯ç”¨ç©ºçª—å‰ªè£æ”¾å…¥ï¼Œç›´è‡³å‡‘æ»¡Top-N
 1681:             if max_clips > 0 and len(scheduled) < max_clips:
 1682:                 def windows_with_buffer(cur_sched, cur_buf):
 1683:                     free = []
 1684:                     cursor = 0.0
 1685:                     for occ in sorted(cur_sched, key=lambda x: x['start']):
 1686:                         os, oe = float(occ['start']), float(occ['end'])
 1687:                         if os - cur_buf > cursor:
 1688:                             free.append((cursor, os - cur_buf))
 1689:                         cursor = max(cursor, oe + cur_buf)
 1690:                     if cursor < video_duration:
 1691:                         free.append((cursor, video_duration))
 1692:                     return sorted(free, key=lambda w: (w[1]-w[0]), reverse=True)
 1693: 
 1694:                 unplaced = [seg for seg in candidates if seg.get('__orig_idx') not in placed_indices]
 1695:                 relax_buffers = [max(buffer_sec/2.0, 0.0), 0.0]
 1696:                 relax_min = [min_clip_duration, max(min_clip_duration*0.75, 60.0), max(min_clip_duration*0.5, 45.0)]
 1697:                 for rb in relax_buffers:
 1698:                     if len(scheduled) >= max_clips:
 1699:                         break
 1700:                     free_ws = windows_with_buffer(scheduled, rb)
 1701:                     for seg in unplaced:
 1702:                         if len(scheduled) >= max_clips:
 1703:                             break
 1704:                         base_s = float(seg.get('start', 0.0)); base_e = float(seg.get('end', 0.0))
 1705:                         if base_e <= base_s:
 1706:                             continue
 1707:                         orig_len = base_e - base_s
 1708:                         # é€‰æœ€å¤§çš„ç©ºçª—ï¼ŒæŒ‰é•¿åº¦å‰ªè£æ”¾å…¥
 1709:                         for L, R in free_ws:
 1710:                             win_len = max(0.0, R - L)
 1711:                             if win_len <= 0.0:
 1712:                                 continue
 1713:                             # ä¾æ¬¡å°è¯•æ›´ä¸¥æ ¼çš„æœ€çŸ­é•¿åº¦
 1714:                             placed2 = False
 1715:                             for mn in relax_min:
 1716:                                 if win_len < mn:
 1717:                                     continue
 1718:                                 length = min(orig_len, win_len)
 1719:                                 # å±…ä¸­æ‘†æ”¾åˆ°çª—å£
 1720:                                 s_cand = L + max(0.0, (win_len - length)/2.0)
 1721:                                 e_cand = s_cand + length
 1722:                                 if e_cand - s_cand > 0.0:
 1723:                                     new_seg = dict(seg)
 1724:                                     new_seg['start'] = float(s_cand)
 1725:                                     new_seg['end'] = float(e_cand)
 1726:                                     scheduled.append(new_seg)
 1727:                                     placed2 = True
 1728:                                     break
 1729:                             if placed2:
 1730:                                 # é‡æ–°è®¡ç®—ç©ºçª—
 1731:                                 free_ws = windows_with_buffer(scheduled, rb)
 1732:                                 break
 1733: 
 1734:                 # å¦‚ä»ä¸è¶³ï¼Œè®°å½•ä½†ä¸é˜»å¡
 1735:                 if len(scheduled) < max_clips:
 1736:                     remaining = max_clips - len(scheduled)
 1737:                     log_warning(f"[pipeline] ç”±äºæ—¶é—´è½´æ‹¥æŒ¤ï¼Œä»æœ‰ {remaining} ä¸ªæœªèƒ½å®‰æ”¾ï¼ˆå·²å›å¡«åˆ°æœ€å¤§å¯èƒ½ï¼‰")
 1738: 
 1739:             # è¾“å‡ºä¸º"è¯„åˆ†ä¼˜å…ˆ+ä¸¥æ ¼æ— é‡å "çš„åºåˆ—ï¼Œå¹¶è£å‰ªä¸ºTop-N
 1740:             segments_data = sorted(scheduled, key=lambda x: x.get('score', 0), reverse=True)
 1741:             if max_clips > 0 and len(segments_data) > max_clips:
 1742:                 segments_data = segments_data[:max_clips]
 1743:         else:
 1744:             # è¯­ä¹‰åˆ†æ®µæ¨¡å¼ï¼šæŒ‰æ—¶é—´é¡ºåºè¾“å‡ºï¼Œè‹¥æœ‰çŸ­æ®µåˆ™é¡ºåºå¹¶å…¥åç»§ç›´è‡³è¾¾åˆ°æœ€å°æ—¶é•¿
 1745:             segments_data = sorted(segments_data, key=lambda x: float(x.get('start', 0.0)))
 1746:             merged = []
 1747:             i = 0
 1748:             while i < len(segments_data):
 1749:                 s = float(segments_data[i].get('start', 0.0))
 1750:                 e = float(segments_data[i].get('end', 0.0))
 1751:                 txt = segments_data[i].get('text', '')
 1752:                 j = i
 1753:                 while (e - s) < min_clip_duration and (j + 1) < len(segments_data):
 1754:                     j += 1
 1755:                     e = float(segments_data[j].get('end', e))
 1756:                     txt = (txt + ' ' + segments_data[j].get('text', '')).strip()
 1757:                 merged.append({'start': s, 'end': e, 'text': txt})
 1758:                 i = j + 1
 1759:             segments_data = merged
 1760:             # å†æ¬¡ä¿è¯"æ°å¥½Næ®µä¸”ä¸é‡å "ï¼ˆåˆå¹¶åå¯èƒ½å‡å°‘æ•°é‡ï¼‰
 1761:             try:
 1762:                 desired_count = int(cfg_manager.get("MAX_CLIP_COUNT") or 10)
 1763:             except Exception:
 1764:                 desired_count = 10
 1765:             # è£å‰ªè¿‡å¤š
 1766:             if desired_count > 0 and len(segments_data) > desired_count:
 1767:                 pass  # selection handled in normalize step
 1768:             # æ‹†åˆ†ä¸è¶³
 1769:             if desired_count > 0 and len(segments_data) < desired_count:
 1770:                 # åŠ è½½è½¬å½•ä»¥ä¾¿æŒ‰è¾¹ç•Œæ‹†åˆ†
 1771:                 transcription_list = []
 1772:                 try:
 1773:                     if os.path.exists(transcription_output):
 1774:                         with open(transcription_output, 'r', encoding='utf-8') as f:
 1775:                             transcription_list = json.load(f) or []
 1776:                 except Exception:
 1777:                     transcription_list = []
 1778:                 def _split_by_mid(seg, min_child_len):
 1779:                     s0 = float(seg.get('start', 0.0)); e0 = float(seg.get('end', 0.0))
 1780:                     mid = (s0 + e0) / 2.0
 1781:                     base_score = float(seg.get('score', seg.get('interest_score', 0.0)) or 0.0)
 1782:                     dur = max(e0 - s0, 1e-6)
 1783:                     # è¯„åˆ†æŒ‰æ—¶é•¿æ¯”ä¾‹æ‹†åˆ†ï¼Œä¿æŒæ€»é‡å®ˆæ’
 1784:                     left_score = base_score * (mid - s0) / dur
 1785:                     right_score = base_score * (e0 - mid) / dur
 1786:                     left = {'start': s0, 'end': mid, 'text': seg.get('text',''), 'score': left_score}
 1787:                     right = {'start': mid, 'end': e0, 'text': seg.get('text',''), 'score': right_score}
 1788:                     if (right['end']-right['start']) < min_child_len or (left['end']-left['start']) < min_child_len:
 1789:                         return None
 1790:                     return [left, right]
 1791:                 def _split_longest_semantic(segments, need_count, min_child_len):
 1792:                     safety = 0
 1793:                     while len(segments) < need_count and safety < 200:
 1794:                         safety += 1
 1795:                         # é€‰æœ€é•¿è€…
 1796:                         idx = max(range(len(segments)), key=lambda i: float(segments[i].get('end',0.0)) - float(segments[i].get('start',0.0))) if segments else -1
 1797:                         if idx < 0:
 1798:                             break
 1799:                         base = segments[idx]
 1800:                         s0 = float(base.get('start', 0.0)); e0 = float(base.get('end', 0.0))
 1801:                         if (e0 - s0) < (2.0 * min_child_len):
 1802:                             break
 1803:                         # é¦–é€‰åœ¨è½¬å½•è¾¹ç•Œä¸­ç‚¹é™„è¿‘æ‹†åˆ†
 1804:                         try:
 1805:                             candidates = []
 1806:                             for t in transcription_list:
 1807:                                 try:
 1808:                                     ts = float(t.get('start', 0.0)); te = float(t.get('end', 0.0))
 1809:                                 except Exception:
 1810:                                     continue
 1811:                                 if ts <= s0 or te >= e0:
 1812:                                     continue
 1813:                                 mid = (ts + te) / 2.0
 1814:                                 if (mid - s0) >= min_child_len and (e0 - mid) >= min_child_len:
 1815:                                     candidates.append(mid)
 1816:                             if candidates:
 1817:                                 pref = (s0 + e0)/2.0
 1818:                                 split_t = min(candidates, key=lambda x: abs(x - pref))
 1819:                                 base_score = float(base.get('score', base.get('interest_score', 0.0)) or 0.0)
 1820:                                 dur = max(e0 - s0, 1e-6)
 1821:                                 left_score = base_score * (split_t - s0) / dur
 1822:                                 right_score = base_score * (e0 - split_t) / dur
 1823:                                 left = {'start': s0, 'end': split_t, 'text': base.get('text',''), 'score': left_score}
 1824:                                 right = {'start': split_t, 'end': e0, 'text': base.get('text',''), 'score': right_score}
 1825:                                 segments.pop(idx)
 1826:                                 segments.extend([left, right])
 1827:                                 segments.sort(key=lambda x: float(x.get('start', 0.0)))
 1828:                                 continue
 1829:                         except Exception:
 1830:                             pass
 1831:                         # å›é€€ï¼šç”¨ä¸­ç‚¹æ‹†åˆ†
 1832:                         sp = _split_by_mid(base, min_child_len)
 1833:                         if not sp:
 1834:                             break
 1835:                         segments.pop(idx)
 1836:                         segments.extend(sp)
 1837:                         segments.sort(key=lambda x: float(x.get('start', 0.0)))
 1838:                     return segments
 1839:                 min_child = max(min_clip_duration * 0.5, 30.0)
 1840:                 segments_data = _split_longest_semantic(segments_data, desired_count, min_child)
 1841:             # æœ€ç»ˆå»é‡å ï¼ˆå‹ç´§åˆ°ç›¸é‚»ï¼‰
 1842:             segments_data = sorted(segments_data, key=lambda x: float(x.get('start', 0.0)))
 1843:             for i in range(len(segments_data)-1):
 1844:                 try:
 1845:                     if float(segments_data[i]['end']) > float(segments_data[i+1]['start']):
 1846:                         segments_data[i]['end'] = float(segments_data[i+1]['start'])
 1847:                 except Exception:
 1848:                     pass
 1849: 
 1850:         # ç¡®ä¿æ¯ä¸ªç‰‡æ®µéƒ½æœ‰ scoreï¼ˆè¯­ä¹‰æ‹†åˆ†åç»§æ‰¿/ä¼°ç®—ï¼‰
 1851:         for _seg in segments_data:
 1852:             if 'score' not in _seg or _seg['score'] is None:
 1853:                 base_val = float(_seg.get('interest_score', 0.0) or 0.0)
 1854:                 # ç»™ä¸€ä¸ªå¾ˆå°çš„æ­£å€¼é˜²æ­¢éƒ½æ˜¯ 0.000
 1855:                 _seg['score'] = max(base_val, 0.005) if base_val > 0 else 0.005
 1856:         
 1857:         # æ˜¾ç¤ºæœ€ç»ˆçš„è¯„åˆ†é¡ºåº
 1858:         final_scores = [f"{seg.get('score', 0):.3f}" for seg in segments_data[:5]]
 1859:         log_info(f"[pipeline] æœ€ç»ˆç‰‡æ®µé¡ºåºï¼ˆæŒ‰è¯„åˆ†ï¼‰: {final_scores}")
 1860:         
 1861:         log_info(f"[pipeline] åˆ‡ç‰‡æ—¶é•¿æ‰©å±•å®Œæˆï¼Œå…± {len(segments_data)} ä¸ªç‰‡æ®µ")
 1862: 
 1863:         # æœ€åä¿é™©ï¼šæ¸…æ´—ç‰‡æ®µæ—¶é—´ï¼Œé¿å…å‡ºç° end < start æˆ–æŒç»­æ—¶é—´ä¸ºéæ­£å¯¼è‡´ -t è´Ÿæ•°
 1864:         try:
 1865:             cleaned_segments = []
 1866:             auto_fixed = 0
 1867:             for _seg in segments_data:
 1868:                 try:
 1869:                     s = float(_seg.get('start', 0.0))
 1870:                     e = float(_seg.get('end', 0.0))
 1871:                 except Exception:
 1872:                     continue
 1873:                 # ä¿®å¤é¢ å€’
 1874:                 if e < s:
 1875:                     s, e = e, s
 1876:                     auto_fixed += 1
 1877:                 # çº¦æŸåˆ°è§†é¢‘èŒƒå›´
 1878:                 s = max(0.0, min(s, video_duration))
 1879:                 e = max(0.0, min(e, video_duration))
 1880:                 # ç¡®ä¿æœ€å°æ­£æ—¶é•¿
 1881:                 if e <= s:
 1882:                     e = min(video_duration, s + 1.0)
 1883:                 if e <= s:
 1884:                     continue
 1885:                 _seg['start'] = s
 1886:                 _seg['end'] = e
 1887:                 cleaned_segments.append(_seg)
 1888:             if auto_fixed > 0:
 1889:                 log_warning(f"[pipeline] ç‰‡æ®µæ—¶é—´å­˜åœ¨é¢ å€’ï¼Œå·²è‡ªåŠ¨ä¿®å¤ {auto_fixed} ä¸ª")
 1890:             if len(cleaned_segments) != len(segments_data):
 1891:                 log_warning(f"[pipeline] æ¸…æ´—åç‰‡æ®µæ•°é‡: {len(cleaned_segments)}/{len(segments_data)}")
 1892:             segments_data = cleaned_segments
 1893:         except Exception as _e:
 1894:             log_warning(f"[pipeline] ç‰‡æ®µæ—¶é—´æ¸…æ´—å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸç‰‡æ®µ: {_e}")
 1895:     
 1896:     log_info(f"[pipeline] Clipping video directly to: {output_clips_dir}")
 1897:     os.makedirs(output_clips_dir, exist_ok=True)
 1898:     clip_files = []
 1899:     
 1900:     if segments_data:
 1901:         def sequential_clip_generation(segments, video_path, output_dir, audio_source=None, progress_callback=None):
 1902:             """ä¸²è¡Œåˆ‡ç‰‡ç”Ÿæˆ"""
 1903:             # éªŒè¯è¾“å…¥å‚æ•°
 1904:             if not segments:
 1905:                 log_error("[pipeline] æ²¡æœ‰ç‰‡æ®µæ•°æ®ï¼Œæ— æ³•ç”Ÿæˆåˆ‡ç‰‡")
 1906:                 return []
 1907:             
 1908:             if not os.path.exists(video_path):
 1909:                 log_error(f"[pipeline] è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
 1910:                 return []
 1911:             
 1912:             log_info(f"[pipeline] å¼€å§‹ä¸²è¡Œåˆ‡ç‰‡ç”Ÿæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")
 1913:             
 1914:             clip_files = []
 1915:             video_base = _sanitize_component(Path(video_path).stem)
 1916:             
 1917:             # é¢„å…ˆæ¢æµ‹ä¸€æ¬¡è§†é¢‘æ—¶é•¿ï¼Œé¿å…æ¯ä¸ªç‰‡æ®µé‡å¤ffprobe
 1918:             try:
 1919:                 _probe_cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', video_path]
 1920:                 _probe_result = subprocess.run(_probe_cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', timeout=30)
 1921:                 if _probe_result.returncode == 0:
 1922:                     import json as _json
 1923:                     _probe_data = _json.loads(_probe_result.stdout)
 1924:                     video_duration_global = float(_probe_data['format']['duration'])
 1925:                 else:
 1926:                     video_duration_global = 30000.0
 1927:             except Exception:
 1928:                 video_duration_global = 30000.0
 1929: 
 1930:             # ç»Ÿè®¡æ€»è¾“å‡ºç§’æ•°ç”¨äº"åˆ‡ç‰‡ç”Ÿæˆ"é˜¶æ®µè¿›åº¦ä¼°è®¡
 1931:             try:
 1932:                 total_output_seconds = sum(max(0.0, float(seg['end']) - float(seg['start'])) for seg in segments)
 1933:             except Exception:
 1934:                 total_output_seconds = float(len(segments)) * 60.0
 1935:             processed_output_seconds = 0.0
 1936: 
 1937:             def generate_single_clip(segment, index):
 1938:                 """ç”Ÿæˆå•ä¸ªåˆ‡ç‰‡"""
 1939:                 try:
 1940:                     start_time = segment['start']
 1941:                     end_time = segment['end']
 1942:                     duration = end_time - start_time
 1943:                     # ä¿é™©ï¼šè‹¥å¤–å±‚å­˜åœ¨å¼‚å¸¸ï¼Œé˜²æ­¢å‡ºç°éæ­£æ—¶é•¿
 1944:                     if duration <= 0:
 1945:                         end_time = min(video_duration_global, start_time + 1.0)
 1946:                         duration = max(0.5, end_time - start_time)
 1947:                     
 1948:                     # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å - ç¡®ä¿ç´¢å¼•æ­£ç¡®
 1949:                     segment_index = index + 1  # ç¡®ä¿ä»1å¼€å§‹
 1950:                     clip_filename = f"{video_base}__clip_{segment_index:03d}_{start_time:.1f}s-{end_time:.1f}s.mp4"
 1951:                     output_path = os.path.join(output_dir, clip_filename)
 1952:                     
 1953:                     # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§æ–‡ä»¶
 1954:                     if os.path.exists(output_path):
 1955:                         try:
 1956:                             os.remove(output_path)
 1957:                             log_info(f"[pipeline] æ¸…ç†æ—§æ–‡ä»¶: {output_path}")
 1958:                         except Exception as e:
 1959:                             log_warning(f"[pipeline] æ¸…ç†æ—§æ–‡ä»¶å¤±è´¥: {e}")
 1960:                     
 1961:                     log_info(f"[pipeline] ç”Ÿæˆåˆ‡ç‰‡ {index+1}/{len(segments)}: {clip_filename} ({duration:.1f}s)")
 1962:                     
 1963:                     # ä½¿ç”¨é¢„å…ˆæ¢æµ‹çš„è§†é¢‘æ—¶é•¿
 1964:                     video_duration = video_duration_global
 1965:                     use_fast_seek = start_time > video_duration_global * 0.5
 1966:                     
 1967:                     # ä½¿ç”¨å¿«é€Ÿåˆ‡ç‰‡æ–¹æ³•ï¼ˆç›´æ¥å¤åˆ¶æµï¼Œä¸é‡æ–°ç¼–ç ï¼‰
 1968:                     def cut_video_ffmpeg_fast(input_path, output_path, start_time, duration):
 1969:                         """ä½¿ç”¨FFmpegå¿«é€Ÿåˆ‡ç‰‡ï¼šå¤åˆ¶è§†é¢‘æµï¼ŒéŸ³é¢‘è½¬AACï¼Œé¿å…æ— å£°/ä¸å…¼å®¹å®¹å™¨"""
 1970:                         cmd = [
 1971:                             "ffmpeg", "-y",
 1972:                             "-hide_banner", "-loglevel", "error", "-nostdin",
 1973:                             "-ss", str(start_time),         # èµ·å§‹æ—¶é—´ï¼ˆè¾“å…¥å¯»å€ï¼Œå¿«ï¼‰
 1974:                             "-i", input_path,               # è¾“å…¥è§†é¢‘
 1975:                             "-t", str(duration),            # ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
 1976:                             "-map", "0:v:0",               # æ˜ç¡®æ˜ å°„è§†é¢‘
 1977:                             "-map", "0:a?",                # å¯é€‰æ˜ å°„éŸ³é¢‘
 1978:                             "-c:v", "copy",                # å¤åˆ¶è§†é¢‘
 1979:                             "-c:a", "aac",                 # ç»Ÿä¸€AACéŸ³é¢‘
 1980:                             "-b:a", "160k",
 1981:                             "-movflags", "+faststart",     # å¿«é€Ÿå¯åŠ¨
 1982:                             output_path                     # è¾“å‡ºæ–‡ä»¶è·¯å¾„
 1983:                         ]
 1984:                         subprocess.run(cmd, check=True)
 1985:                     
 1986:                     # æ„å»ºFFmpegå‘½ä»¤ - ä½¿ç”¨å¿«é€Ÿåˆ‡ç‰‡
 1987:                     if audio_source and os.path.exists(audio_source):
 1988:                         # å¦‚æœæœ‰éŸ³é¢‘æºï¼Œå°½é‡å¤åˆ¶è§†é¢‘æµï¼Œä»…ç¼–ç éŸ³é¢‘ï¼ŒåŠ é€Ÿè¾“å‡º
 1989:                         if use_fast_seek:
 1990:                             cmd = [
 1991:                                 'ffmpeg', '-y',
 1992:                                 '-hide_banner', '-loglevel', 'error', '-nostdin',
 1993:                                 '-ss', str(start_time),
 1994:                                 '-i', str(video_path),
 1995:                                 '-i', str(audio_source),
 1996:                                 '-map', '0:v',
 1997:                                 '-map', '1:a',
 1998:                                 '-t', str(duration),
 1999:                                 '-c:v', 'copy',              # å¤åˆ¶è§†é¢‘ï¼Œé¿å…é‡ç¼–ç 
 2000:                                 '-c:a', 'aac',
 2001:                                 '-preset', 'veryfast',
 2002:                                 '-avoid_negative_ts', 'make_zero',
 2003:                                 '-movflags', '+faststart',
 2004:                                 '-threads', '0',
 2005:                                 '-max_muxing_queue_size', '1024',
 2006:                                 str(output_path)
 2007:                             ]
 2008:                         else:
 2009:                             cmd = [
 2010:                                 'ffmpeg', '-y',
 2011:                                 '-hide_banner', '-loglevel', 'error', '-nostdin',
 2012:                                 '-i', str(video_path),
 2013:                                 '-i', str(audio_source),
 2014:                                 '-map', '0:v',
 2015:                                 '-map', '1:a',
 2016:                                 '-ss', str(start_time),
 2017:                                 '-t', str(duration),
 2018:                                 '-c:v', 'copy',              # å¤åˆ¶è§†é¢‘ï¼Œé¿å…é‡ç¼–ç 
 2019:                                 '-c:a', 'aac',
 2020:                                 '-preset', 'veryfast',
 2021:                                 '-movflags', '+faststart',
 2022:                                 '-threads', '0',
 2023:                                 '-max_muxing_queue_size', '1024',
 2024:                                 str(output_path)
 2025:                             ]
 2026:                     else:
 2027:                         # æ²¡æœ‰éŸ³é¢‘æºï¼Œä½¿ç”¨å¿«é€Ÿåˆ‡ç‰‡ï¼›è‹¥è¾“å‡ºå¼‚å¸¸ï¼ˆ0ç§’/æ— è§†é¢‘æµï¼‰ï¼Œå›é€€åˆ°ç¼–ç æ¨¡å¼
 2028:                         try:
 2029:                             cut_video_ffmpeg_fast(str(video_path), str(output_path), start_time, duration)
 2030:                             # å…ˆä¸è¿”å›ï¼Œåšä¸€æ¬¡å®Œæ•´æ€§æ£€æŸ¥
 2031:                             try:
 2032:                                 probe_cmd = [
 2033:                                     'ffprobe', '-v', 'quiet', '-print_format', 'json',
 2034:                                     '-show_format', '-show_streams', str(output_path)
 2035:                                 ]
 2036:                                 probe_result_fast = subprocess.run(
 2037:                                     probe_cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', timeout=15
 2038:                                 )
 2039:                                 need_fallback = True
 2040:                                 if probe_result_fast.returncode == 0:
 2041:                                     import json as _json
 2042:                                     pdata = _json.loads(probe_result_fast.stdout or '{}')
 2043:                                     streams = pdata.get('streams', []) or []
 2044:                                     has_video_stream = any(s.get('codec_type') == 'video' for s in streams)
 2045:                                     duration_val = 0.0
 2046:                                     try:
 2047:                                         duration_val = float((pdata.get('format') or {}).get('duration') or 0.0)
 2048:                                     except Exception:
 2049:                                         duration_val = 0.0
 2050:                                     need_fallback = (not has_video_stream) or (duration_val <= 0.5)
 2051:                                 if need_fallback:
 2052:                                     # æ„å»ºå›é€€ç¼–ç å‘½ä»¤
 2053:                                     if use_fast_seek:
 2054:                                         cmd = [
 2055:                                             'ffmpeg', '-y',
 2056:                                             '-hide_banner', '-loglevel', 'error', '-nostdin',
 2057:                                             '-ss', str(start_time),
 2058:                                             '-i', str(video_path),
 2059:                                             '-t', str(duration),
 2060:                                             '-c:v', 'libx264',
 2061:                                             '-c:a', 'aac',
 2062:                                             '-preset', 'veryfast',
 2063:                                             '-crf', '23',
 2064:                                             '-avoid_negative_ts', 'make_zero',
 2065:                                             '-movflags', '+faststart',
 2066:                                             '-threads', '0',
 2067:                                             '-max_muxing_queue_size', '1024',
 2068:                                             str(output_path)
 2069:                                         ]
 2070:                                     else:
 2071:                                         cmd = [
 2072:                                             'ffmpeg', '-y',
 2073:                                             '-hide_banner', '-loglevel', 'error', '-nostdin',
 2074:                                             '-i', str(video_path),
 2075:                                             '-ss', str(start_time),
 2076:                                             '-t', str(duration),
 2077:                                             '-c:v', 'libx264',
 2078:                                             '-c:a', 'aac',
 2079:                                             '-preset', 'veryfast',
 2080:                                             '-crf', '23',
 2081:                                             '-threads', '0',
 2082:                                             '-max_muxing_queue_size', '1024',
 2083:                                             str(output_path)
 2084:                                         ]
 2085:                                 # å¦‚æœ need_fallback ä¸º Falseï¼Œåˆ™ä¸å®šä¹‰ cmdï¼Œè®©åç»­éªŒè¯ç›´æ¥é€šè¿‡
 2086:                             except Exception:
 2087:                                 # æ¢æµ‹å¤±è´¥æ—¶ä¿æŒç°çŠ¶ï¼Œç”±åç»­å¤§å°/æ¢æµ‹æ£€æŸ¥å…œåº•
 2088:                                 pass
 2089:                         except subprocess.CalledProcessError as e:
 2090:                             log_warning(f"[pipeline] å¿«é€Ÿåˆ‡ç‰‡å¤±è´¥ï¼Œå›é€€åˆ°ç¼–ç æ¨¡å¼: {e}")
 2091:                             # å›é€€åˆ°ç¼–ç æ¨¡å¼
 2092:                             if use_fast_seek:
 2093:                                 cmd = [
 2094:                                     'ffmpeg', '-y',
 2095:                                     '-hide_banner', '-loglevel', 'error', '-nostdin',
 2096:                                     '-ss', str(start_time),
 2097:                                     '-i', str(video_path),
 2098:                                     '-t', str(duration),
 2099:                                     '-c:v', 'libx264',
 2100:                                     '-c:a', 'aac',
 2101:                                     '-preset', 'veryfast',
 2102:                                     '-crf', '23',
 2103:                                     '-avoid_negative_ts', 'make_zero',
 2104:                                     '-movflags', '+faststart',
 2105:                                     '-threads', '0',
 2106:                                     '-max_muxing_queue_size', '1024',
 2107:                                     str(output_path)
 2108:                                 ]
 2109:                             else:
 2110:                                 cmd = [
 2111:                                     'ffmpeg', '-y',
 2112:                                     '-hide_banner', '-loglevel', 'error', '-nostdin',
 2113:                                     '-i', str(video_path),
 2114:                                     '-ss', str(start_time),
 2115:                                     '-t', str(duration),
 2116:                                     '-c:v', 'libx264',
 2117:                                     '-c:a', 'aac',
 2118:                                     '-preset', 'veryfast',
 2119:                                     '-crf', '23',
 2120:                                     '-threads', '0',
 2121:                                     '-max_muxing_queue_size', '1024',
 2122:                                     str(output_path)
 2123:                                 ]
 2124:                     
 2125:                     # åŠ¨æ€è¶…æ—¶æ—¶é—´ - åŸºäºåˆ‡ç‰‡æ—¶é•¿å’Œä½ç½®
 2126:                     base_timeout = 1800  # å¢åŠ åˆ°30åˆ†é’Ÿ
 2127:                     safe_duration = max(float(duration), 1.0)
 2128:                     duration_factor = min(safe_duration / 10.0, 3.0)  # åŸºäºåˆ‡ç‰‡æ—¶é•¿ï¼Œæœ€å¤§3å€
 2129:                     position_factor = 1.0
 2130:                     if start_time > video_duration * 0.8:
 2131:                         position_factor = 2.0  # è§†é¢‘æœ«å°¾éœ€è¦æ›´å¤šæ—¶é—´
 2132:                     elif start_time > video_duration * 0.6:
 2133:                         position_factor = 1.5
 2134:                     
 2135:                     timeout = int(base_timeout * duration_factor * position_factor)
 2136:                     log_info(f"[pipeline] åˆ‡ç‰‡ {index+1} è¶…æ—¶è®¾ç½®: {timeout}s (æ—¶é•¿:{duration:.1f}s, ä½ç½®:{start_time:.1f}s)")
 2137:                     
 2138:                     # æ‰§è¡ŒFFmpegå‘½ä»¤ï¼ˆåªæœ‰åœ¨éœ€è¦ç¼–ç æ—¶æ‰æ‰§è¡Œï¼‰
 2139:                     if 'cmd' in locals():
 2140:                         result = subprocess.run(
 2141:                             cmd, 
 2142:                             capture_output=True, 
 2143:                             text=True, 
 2144:                             encoding='utf-8',
 2145:                             errors='ignore',
 2146:                             timeout=timeout
 2147:                         )
 2148:                     
 2149:                     # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
 2150:                     if os.path.exists(output_path):
 2151:                         file_size = os.path.getsize(output_path)
 2152:                         if file_size > 1024 * 1024:  # è‡³å°‘1MB
 2153:                             # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ - æ”¹è¿›æ£€æŸ¥é€»è¾‘
 2154:                             try:
 2155:                                 probe_cmd = [
 2156:                                     'ffprobe', '-v', 'quiet', '-print_format', 'json',
 2157:                                     '-show_format', '-show_streams', output_path
 2158:                                 ]
 2159:                                 probe_result = subprocess.run(probe_cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', timeout=30)
 2160:                                 
 2161:                                 if probe_result.returncode == 0:
 2162:                                     # æ£€æŸ¥æ˜¯å¦æœ‰è§†é¢‘æµ
 2163:                                     import json
 2164:                                     probe_data = json.loads(probe_result.stdout)
 2165:                                     streams = probe_data.get('streams', [])
 2166:                                     has_video_stream = any(stream.get('codec_type') == 'video' for stream in streams)
 2167:                                     has_audio_stream = any(stream.get('codec_type') == 'audio' for stream in streams)
 2168:                                     
 2169:                                     if has_video_stream:
 2170:                                         if not has_audio_stream:
 2171:                                             log_warning(f"[pipeline] åˆ‡ç‰‡ {index+1} ç¼ºå°‘éŸ³é¢‘æµ: {output_path}")
 2172:                                         log_info(f"[pipeline] åˆ‡ç‰‡ {index+1} ç”ŸæˆæˆåŠŸ: {output_path} ({file_size} bytes)")
 2173:                                         # æ›´æ–°åˆ‡ç‰‡é˜¶æ®µè¿›åº¦ï¼ˆåŸºäºç´¯è®¡è¾“å‡ºç§’æ•°ï¼‰
 2174:                                         try:
 2175:                                             nonlocal processed_output_seconds
 2176:                                             processed_output_seconds += max(0.0, float(end_time) - float(start_time))
 2177:                                             if 'smart_predictor' in locals() and smart_predictor and total_output_seconds > 0:
 2178:                                                 progress_ratio = min(max(processed_output_seconds / total_output_seconds, 0.0), 1.0)
 2179:                                                 smart_predictor.update_stage_progress("åˆ‡ç‰‡ç”Ÿæˆ", progress_ratio)
 2180:                                         except Exception:
 2181:                                             pass
 2182:                                         return output_path
 2183:                                     else:
 2184:                                         log_error(f"[pipeline] åˆ‡ç‰‡ {index+1} ç¼ºå°‘è§†é¢‘æµ")
 2185:                                         if os.path.exists(output_path):
 2186:                                             os.remove(output_path)
 2187:                                         return None
 2188:                                 else:
 2189:                                     log_error(f"[pipeline] åˆ‡ç‰‡ {index+1} æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {probe_result.stderr}")
 2190:                                     if os.path.exists(output_path):
 2191:                                         os.remove(output_path)
 2192:                                     return None
 2193:                             except Exception as e:
 2194:                                 log_error(f"[pipeline] åˆ‡ç‰‡ {index+1} æ–‡ä»¶æ£€æŸ¥å¼‚å¸¸: {e}")
 2195:                                 # å¦‚æœæ–‡ä»¶è¶³å¤Ÿå¤§ï¼Œå¯èƒ½æ˜¯æ£€æŸ¥å·¥å…·é—®é¢˜ï¼Œä¿ç•™æ–‡ä»¶
 2196:                                 if file_size > 1024 * 1024:  # å¤§äº1MB
 2197:                                     log_info(f"[pipeline] åˆ‡ç‰‡ {index+1} æ–‡ä»¶è¾ƒå¤§ï¼Œä¿ç•™: {output_path} ({file_size} bytes)")
 2198:                                     return output_path
 2199:                                 else:
 2200:                                     if os.path.exists(output_path):
 2201:                                         os.remove(output_path)
 2202:                                     return None
 2203:                         else:
 2204:                             log_error(f"[pipeline] åˆ‡ç‰‡ {index+1} æ–‡ä»¶å¤ªå°: {file_size} bytes (éœ€è¦è‡³å°‘1MB)")
 2205:                             if os.path.exists(output_path):
 2206:                                 os.remove(output_path)
 2207:                             return None
 2208:                     else:
 2209:                         log_error(f"[pipeline] åˆ‡ç‰‡ {index+1} è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
 2210:                         return None
 2211: 
 2212:                         
 2213:                 except Exception as e:
 2214:                     log_error(f"[pipeline] åˆ‡ç‰‡ {index+1} å¼‚å¸¸: {e}")
 2215:                     if os.path.exists(output_path):
 2216:                         try:
 2217:                             os.remove(output_path)
 2218:                         except:
 2219:                             pass
 2220:                     return None
 2221:             
 2222:             # ä¸²è¡Œæ‰§è¡Œåˆ‡ç‰‡ç”Ÿæˆ
 2223:             successful_clips = []
 2224:             
 2225:             for i, segment in enumerate(segments):
 2226:                 try:
 2227:                     clip_path = generate_single_clip(segment, i)
 2228:                     if clip_path:
 2229:                         successful_clips.append(clip_path)
 2230:                         log_info(f"[pipeline] åˆ‡ç‰‡ {i+1} å®Œæˆï¼Œå½“å‰æˆåŠŸ: {len(successful_clips)}/{len(segments)}")
 2231:                     
 2232:                     if progress_callback:
 2233:                         progress_callback(i + 1, len(segments))
 2234:                         
 2235:                 except Exception as e:
 2236:                     log_error(f"[pipeline] åˆ‡ç‰‡ {i+1} ä»»åŠ¡å¼‚å¸¸: {e}")
 2237:                     if progress_callback:
 2238:                         progress_callback(i + 1, len(segments))
 2239:             
 2240:             log_info(f"[pipeline] ä¸²è¡Œåˆ‡ç‰‡ç”Ÿæˆå®Œæˆï¼ŒæˆåŠŸç”Ÿæˆ {len(successful_clips)} ä¸ªåˆ‡ç‰‡")
 2241:             return successful_clips
 2242:         
 2243:         def clip_progress_callback(current, total):
 2244:             emit_progress("ä¸²è¡Œè§†é¢‘åˆ‡ç‰‡", current_step, total_steps, f"æ­£åœ¨ç”Ÿæˆç¬¬{current}/{total}ä¸ªåˆ‡ç‰‡...")
 2245:         
 2246:         try:
 2247:             # ä½¿ç”¨ä¸²è¡Œåˆ‡ç‰‡ç”Ÿæˆ
 2248:             clip_files = sequential_clip_generation(
 2249:                 segments_data, video, output_clips_dir, 
 2250:                 audio_source=host_audio_path, 
 2251:                 progress_callback=clip_progress_callback
 2252:             )
 2253:         except Exception as e:
 2254:             log_error(f"[pipeline] ä¸²è¡Œåˆ‡ç‰‡å¤±è´¥: {e}")
 2255:             # é™çº§åˆ°clip_videoå‡½æ•°
 2256:             try:
 2257:                 import inspect
 2258:                 clip_sig = inspect.signature(clip_video)
 2259:                 if 'progress_callback' in clip_sig.parameters:
 2260:                     clip_video(video_path=video, analysis_file=analysis_output, output_dir=output_clips_dir, 
 2261:                               progress_callback=clip_progress_callback, audio_source=host_audio_path)
 2262:                 else:
 2263:                     clip_video(video_path=video, analysis_file=analysis_output, output_dir=output_clips_dir, 
 2264:                               audio_source=host_audio_path)
 2265:             except Exception as e2:
 2266:                 log_error(f"[pipeline] é™çº§åˆ‡ç‰‡ä¹Ÿå¤±è´¥: {e2}")
 2267:         
 2268:         # æ£€æŸ¥æœ€ç»ˆç›®å½•ä¸­çš„åˆ‡ç‰‡æ–‡ä»¶
 2269:         final_clips = []
 2270:         for file in os.listdir(output_clips_dir):
 2271:             if file.lower().endswith('.mp4'):
 2272:                 clip_path = os.path.join(output_clips_dir, file)
 2273:                 if os.path.isfile(clip_path) and os.path.getsize(clip_path) > 1024:  # è‡³å°‘1KB
 2274:                     final_clips.append(clip_path)
 2275:         
 2276:         log_info(f"[pipeline] æœ€ç»ˆåˆ‡ç‰‡ç»Ÿè®¡: æˆåŠŸç”Ÿæˆ {len(final_clips)} ä¸ªæœ‰æ•ˆåˆ‡ç‰‡")
 2277:         if len(final_clips) != len(segments_data):
 2278:             log_warning(f"[pipeline] åˆ‡ç‰‡æ•°é‡ä¸åŒ¹é…: æœŸæœ› {len(segments_data)} ä¸ªï¼Œå®é™… {len(final_clips)} ä¸ª")
 2279:         
 2280:         # å°†æœ€ç»ˆåˆ‡ç‰‡æ·»åŠ åˆ°clip_filesåˆ—è¡¨
 2281:         for clip_path in final_clips:
 2282:             if clip_path not in clip_files:
 2283:                 clip_files.append(clip_path)
 2284:                 log_info(f"[pipeline] Found clip: {clip_path}")
 2285:         
 2286:         log_info(f"[pipeline] Successfully generated {len(clip_files)} clip files")
 2287:         
 2288:         # æ›´æ–°æ™ºèƒ½è¿›åº¦é¢„æµ‹
 2289:         if smart_predictor:
 2290:             smart_predictor.finish_stage("åˆ‡ç‰‡ç”Ÿæˆ")
 2291:             
 2292:     else:
 2293:         log_error("[pipeline] No segments to clip")
 2294: 
 2295:     emit_progress("å®Œæˆ", total_steps, total_steps, f"å¤„ç†å®Œæˆï¼ç”Ÿæˆäº†{len(clip_files)}ä¸ªåˆ‡ç‰‡")
 2296:     
 2297:     # ç”Ÿæˆæ¯ä¸ªåˆ‡ç‰‡çš„è¯­ä¹‰å­—å¹•ï¼ˆSRTï¼‰
 2298:     try:
 2299:         from acfv.processing.subtitle_generator import generate_semantic_subtitles_for_clips
 2300:         transcription_output = os.path.join(os.path.dirname(analysis_output), "transcription.json")
 2301:         if os.path.exists(transcription_output) and clip_files:
 2302:             count = generate_semantic_subtitles_for_clips(output_clips_dir, transcription_output, cfg_manager, clip_files)
 2303:             log_info(f"[pipeline] å·²ä¸º {count} ä¸ªåˆ‡ç‰‡ç”Ÿæˆè¯­ä¹‰å­—å¹•")
 2304:         else:
 2305:             log_info("[pipeline] è·³è¿‡å­—å¹•ç”Ÿæˆï¼ˆæ— è½¬å½•æˆ–æ— åˆ‡ç‰‡ï¼‰")
 2306:     except Exception as e:
 2307:         log_error(f"[pipeline] è¯­ä¹‰å­—å¹•ç”Ÿæˆå¤±è´¥: {e}")
 2308: 
 2309:     # ç»“æŸæ™ºèƒ½ä¼šè¯è®°å½•
 2310:     try:
 2311:         if 'smart_predictor' in locals() and smart_predictor:
 2312:             smart_predictor.end_session(success=True)
 2313:     except Exception:
 2314:         pass
 2315: 
 2316:     return output_clips_dir, clip_files, has_chat
 2317: 
 2318: 
 2319: def generate_content_indexes(cfg_manager):
 2320:     """Generate semantic indexes for rated clips.
 2321:     ä½¿ç”¨åˆ‡ç‰‡æ–‡æœ¬ä¸è¯„åˆ†æ„å»ºRAGç´¢å¼•ï¼Œä¼˜å…ˆä½¿ç”¨æœ€è¿‘ä¸€æ¬¡è¿è¡Œï¼ˆruns/latestï¼‰ã€‚
 2322:     """
 2323:     log_info("[generate_content_indexes] Starting to generate content indexes")
 2324: 
 2325:     clips_base_dir = cfg_manager.get("CLIPS_BASE_DIR")
 2326:     if not os.path.exists(clips_base_dir):
 2327:         log_info("[generate_content_indexes] Clips base dir doesn't exist")
 2328:         return "ç´¢å¼•ç”Ÿæˆå®Œæˆï¼ˆæ— éœ€å¤„ç†ï¼‰"
 2329: 
 2330:     processed_count = 0
 2331:     for video_dir in os.listdir(clips_base_dir):
 2332:         video_path = os.path.join(clips_base_dir, video_dir)
 2333:         if not os.path.isdir(video_path):
 2334:             continue
 2335: 
 2336:         # æ”¯æŒæ–°ç»“æ„ï¼šruns/<run_xxx>/ratings.json ä¼˜å…ˆæœ€æ–°ä¸€æ¬¡
 2337:         ratings_path = os.path.join(video_path, "ratings.json")
 2338:         runs_dir = os.path.join(video_path, "runs")
 2339:         latest_run_dir = None
 2340:         if os.path.isdir(runs_dir):
 2341:             run_names = sorted([d for d in os.listdir(runs_dir) if os.path.isdir(os.path.join(runs_dir, d))])
 2342:             if run_names:
 2343:                 latest_run_dir = os.path.join(runs_dir, run_names[-1])
 2344:                 candidate = os.path.join(latest_run_dir, "ratings.json")
 2345:                 if os.path.exists(candidate):
 2346:                     ratings_path = candidate
 2347: 
 2348:         if not os.path.exists(ratings_path):
 2349:             continue
 2350: 
 2351:         # å¦‚æœç´¢å¼•å·²å­˜åœ¨åˆ™è·³è¿‡ï¼ˆè§†é¢‘ç›®å½•çº§åˆ«æˆ–æœ€æ–°runçº§åˆ«ä»»ä¸€å­˜åœ¨å³å¯ï¼‰
 2352:         index_dir = os.path.join(video_path, "index")
 2353:         index_file = os.path.join(index_dir, "content_index.faiss")
 2354:         run_index_dir = os.path.join(latest_run_dir, "index") if latest_run_dir else None
 2355:         run_index_file = os.path.join(run_index_dir, "content_index.faiss") if run_index_dir else None
 2356:         if (index_file and os.path.exists(index_file)) or (run_index_file and os.path.exists(run_index_file)):
 2357:             continue
 2358: 
 2359:         try:
 2360:             with open(ratings_path, "r", encoding="utf-8") as f:
 2361:                 ratings = json.load(f)
 2362:             if not ratings:
 2363:                 continue
 2364: 
 2365:             log_info(f"[generate_content_indexes] Generating index for {video_dir}")
 2366: 
 2367:             # è¯»å–è½¬å½•æ–‡ä»¶ï¼ˆlegacy æˆ– mappingï¼‰ï¼Œä½†æˆ‘ä»¬åªéœ€è¦æ¯ä¸ªåˆ‡ç‰‡çš„æ–‡æœ¬
 2368:             # ä» ratings.json é‡Œä¼˜å…ˆå– 'text' å­—æ®µ
 2369:             segments = []
 2370:             weights = []
 2371:             for clip_filename, data in ratings.items():
 2372:                 text = data.get("text", "")
 2373:                 rating = float(data.get("rating", 0.0))
 2374:                 if text and text.strip():
 2375:                     segments.append({"text": text})
 2376:                     weights.append(rating)
 2377: 
 2378:             if not segments:
 2379:                 log_info(f"[generate_content_indexes] No clip texts in ratings for {video_dir}")
 2380:                 continue
 2381: 
 2382:             if not FAISS_AVAILABLE:
 2383:                 log_info(f"[generate_content_indexes] Skipping index generation for {video_dir} (faiss not available)")
 2384:                 continue
 2385: 
 2386:             index, vectorizer, _ = build_content_index(segments, weights=weights)
 2387:             if index and vectorizer:
 2388:                 # ä¿å­˜åˆ°è§†é¢‘ç›®å½•çº§åˆ«
 2389:                 os.makedirs(index_dir, exist_ok=True)
 2390:                 faiss.write_index(index, index_file)
 2391:                 with open(os.path.join(index_dir, "vectorizer.pkl"), "wb") as f:
 2392:                     pickle.dump(vectorizer, f)
 2393:                 # åŒæ—¶ä¿å­˜åˆ°æœ€æ–°runç›®å½•ï¼Œä¾¿äºæŒ‰runè°ƒè¯•
 2394:                 if latest_run_dir:
 2395:                     os.makedirs(run_index_dir, exist_ok=True)
 2396:                     faiss.write_index(index, run_index_file)
 2397:                     with open(os.path.join(run_index_dir, "vectorizer.pkl"), "wb") as f:
 2398:                         pickle.dump(vectorizer, f)
 2399:                 log_info(f"[generate_content_indexes] Successfully generated index for {video_dir}")
 2400:                 processed_count += 1
 2401:         except Exception as e:
 2402:             log_error(f"[generate_content_indexes] Error processing {video_dir}: {e}")
 2403: 
 2404:     log_info("[generate_content_indexes] Finished generating content indexes")
 2405:     return f"ç´¢å¼•ç”Ÿæˆå®Œæˆï¼Œå¤„ç†äº† {processed_count} ä¸ªè§†é¢‘ç›®å½•"
